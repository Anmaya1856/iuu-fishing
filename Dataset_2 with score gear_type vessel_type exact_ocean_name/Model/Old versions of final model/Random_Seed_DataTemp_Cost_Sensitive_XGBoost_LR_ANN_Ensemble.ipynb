{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3dKmFb1fDL-"
      },
      "source": [
        "# Importing Dataset and pre processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "W0XR2-q8fDMD",
        "outputId": "9295fa1b-3617-4374-c205-1a42ce349bd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gap_hours  iuu_caught  spherical_distances  eez_check  \\\n",
              "0  13.016667           0           207.942845          0   \n",
              "1  13.850000           0             9.704232          0   \n",
              "2  33.733333           0            10.789069          1   \n",
              "3  30.650000           0            11.695860          1   \n",
              "4  50.283333           0            93.113335          1   \n",
              "\n",
              "  exact _name new from diff Oceans      gear type      speed  \\\n",
              "0             North Atlantic Ocean  pole_and_line  15.975123   \n",
              "1             South Atlantic Ocean        fishing   0.700667   \n",
              "2             North Atlantic Ocean  pole_and_line   0.319834   \n",
              "3             North Atlantic Ocean  pole_and_line   0.381594   \n",
              "4             North Atlantic Ocean  pole_and_line   1.851773   \n",
              "\n",
              "  ais_disable_time_division  \n",
              "0                   Morning  \n",
              "1                      Dawn  \n",
              "2                      Dawn  \n",
              "3                 Afternoon  \n",
              "4                 Afternoon  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93f1a1f6-ed33-4159-ba71-2b706f798654\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gap_hours</th>\n",
              "      <th>iuu_caught</th>\n",
              "      <th>spherical_distances</th>\n",
              "      <th>eez_check</th>\n",
              "      <th>exact _name new from diff Oceans</th>\n",
              "      <th>gear type</th>\n",
              "      <th>speed</th>\n",
              "      <th>ais_disable_time_division</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13.016667</td>\n",
              "      <td>0</td>\n",
              "      <td>207.942845</td>\n",
              "      <td>0</td>\n",
              "      <td>North Atlantic Ocean</td>\n",
              "      <td>pole_and_line</td>\n",
              "      <td>15.975123</td>\n",
              "      <td>Morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.850000</td>\n",
              "      <td>0</td>\n",
              "      <td>9.704232</td>\n",
              "      <td>0</td>\n",
              "      <td>South Atlantic Ocean</td>\n",
              "      <td>fishing</td>\n",
              "      <td>0.700667</td>\n",
              "      <td>Dawn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33.733333</td>\n",
              "      <td>0</td>\n",
              "      <td>10.789069</td>\n",
              "      <td>1</td>\n",
              "      <td>North Atlantic Ocean</td>\n",
              "      <td>pole_and_line</td>\n",
              "      <td>0.319834</td>\n",
              "      <td>Dawn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30.650000</td>\n",
              "      <td>0</td>\n",
              "      <td>11.695860</td>\n",
              "      <td>1</td>\n",
              "      <td>North Atlantic Ocean</td>\n",
              "      <td>pole_and_line</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>Afternoon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50.283333</td>\n",
              "      <td>0</td>\n",
              "      <td>93.113335</td>\n",
              "      <td>1</td>\n",
              "      <td>North Atlantic Ocean</td>\n",
              "      <td>pole_and_line</td>\n",
              "      <td>1.851773</td>\n",
              "      <td>Afternoon</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93f1a1f6-ed33-4159-ba71-2b706f798654')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93f1a1f6-ed33-4159-ba71-2b706f798654 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93f1a1f6-ed33-4159-ba71-2b706f798654');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('ais_disabling_events_test.csv')\n",
        "df = df.drop('score', axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV4xM8xNfDMF",
        "outputId": "d1dc91ea-619b-4a8c-c3b7-bba71be8462a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55368, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u57ZoDMefDMG",
        "outputId": "42be2796-9f9c-4115-d891-2fe0adb57203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    55129\n",
              "1      239\n",
              "Name: iuu_caught, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "df['iuu_caught'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.lmplot(x='gap_hours', y='spherical_distances', hue='iuu_caught', \n",
        "           markers=['x', 'o'],\n",
        "           fit_reg=False, data=df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AIugNCCN1Zxz",
        "outputId": "4b115ff0-a258-4eef-becf-737e8fc14327"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f8227210c40>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 423.25x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAFgCAYAAACCD78cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9e3yUZ5nw/71mJjM5c0qgEA7hZGvVUlpasIRq62G7q4B7eF1pta1Q2F3t6rqHn933dXVX3d9W9+BrrXa3Adqipequ60I9VKuthUBLpeVgaw9ACIEESAiEnCfJzPX+8TwzTEImmUlmkpnk+n4+85l57ucw90zy3NdcZ1FVDMMwDCNdeMZ6AoZhGMb4xgSNYRiGkVZM0BiGYRhpxQSNYRiGkVZM0BiGYRhpxTfWExgLbrvtNn3qqafGehqGYYxPZKwnkGlMSI3m3LlzYz0FwzCMCcOEFDSGYRjG6JFWQSMic0TkWRH5rYi8KiKfdsenisjTInLEfZ7ijouIPCAiR0XksIhcF3Otu9zjj4jIXTHj14vIb9xzHhARU1sNwzAyiHRrNL3AX6nq1cAK4JMicjVwH/BLVV0M/NLdBvhdYLH72AQ8BI5gAr4ALAduBL4QEU7uMRtjzrstzZ/JMAzDSIK0ChpVPa2qL7uvW4HXgDJgLfCYe9hjwIfc12uBberwAjBZRGYCvwM8rarnVfUC8DRwm7uvWFVfUKeWzraYaxmGYRgZwKj5aESkHFgK7ANmqOppd9cZYIb7ugw4GXPaKXdssPFTA4wP9P6bRGS/iOxvbGwc0WcxDMMwEmdUBI2IFAI/AP5CVVti97maSNore6rqw6q6TFWXlZaWpvvtDMMwDJe0CxoRycERMo+r6n+7w2ddsxfuc4M7XgfMiTl9tjs22PjsAcYNwzCMDCHdUWcCbAFeU9V/i9m1E4hEjt0F7IgZv9ONPlsBXHRNbD8D3i8iU9wggPcDP3P3tYjICve97oy5lmEYhpEBpLsywErgY8BvROSgO/a/gfuB74vIBuAE8GF330+A3wOOAh3AxwFU9byIfAn4tXvcF1X1vPv6E8CjQB7wU/eRMlSV2Ijp/tvG4Nj3ZxiGTMTGZ8uWLdP9+/cPedz2fbW0B3u5Z9V8RARVZfPu4xQEfNy+fO4ozDS7iff95fu93LFiXvQ4Ez7GOMP+mfthlQHioKq0B3vZeaiezbuPRxfJnYfqaQ/2MhEFdDLE+/4e3VvDM683EA6Ho8dt3n2c7ftqx3jGhmGkiwlZVDMRRIR7Vs0HYOehenYeqgdgzZJZ0V/oRnwG+v5UlauuKKKhtYstVTXcs2p+VHivWTLLNJsJgJlSJyam0QyCiLChorzP2IaKcrsxEiRW2ES2K++8njVLyhzh8uCeqJAx4T3+2b6vNqrdgmmzEwkTNIPw+Asn2LjtJS6l+Sgbt73E4y+cGMtpZQ2RhSSWLVU1lwlvEzLjHzNFT2zMdBaHcDjMM683sPdYEzctnEblndezcdtL7D3WBMC6G+fg8ZicjkfsQhLRWDbvPs6Og3W8UN2EI7wd4bJ593ETNuMcM0VPbGyljIPH4+HWt07npoXTONvSxdpv7uVsSxc3LZzGrW+dbkJmCESEgoCvz0KyoaKcGcW5vH6m1TGf3buSNUtm9fmVa4xf+ptSgT4RibHY/8L4wjSaQbhj+Tw+smw2H/rW84Bzozz8sevwer1JXWeiOkBvXz63z2eNCO8VC6ZFF5jIwlMQ8E2I72QiM5ApdfPu4+QHvHQEQ5ZGMI4xQTMIj+87wTOvnSUcDuPxeFANs+nbL3HrVdO5Y0V5XIERO759Xy1twR42rlowIW+i/t/PHcvn9fl+IsLGhMz4ZjBT6oziXBpauwAsEnGcYoImDuFwmG8/f4I3z7ayoKSAu945h8eeP8Fzb57jcF0Lqkpnj14mMGKTFAHagj1srarhQG0z37rjOruJuFz4TMTvYKIxkCk1co/k+710dIfMdzOOMUETBxFBUASoaergqz9/k87uEKGw0tLZzbNvNHK2Jcjaa8uiAiM2sgacX2eRgLUDtc2sebAKkFG9iSaq2c7IPPqbUmO1WVWN3jdgkYjjDfNoD0J5SSEBnxBWpS3YS29YXbkhnLnYxdpry/rcEJEbJ+LgXvPgHp48fJr1K8spLfITibJK5U00mBPV8haMTGMgbTae78YCAsYPJmgG4do5k/B6vIQVYv/nJ+V64/oW+kfWqOpllY827z4eLcEyEgYTJJa3YGQD/X03Fok4PjHT2SBInNp4HT3h6A3SX9jE/jpTVc61dfPgM0e5oXwKlXcuY0tVDTsPObkkTlDBvAHfYygGMtPF3rCRMbC8BSNzGcx3Y5GI4wcTNIPwcu0Fgr0hADwCYQWvgEeEKyblsuOg02Otf1hmbGTNJ77zMlVHz/FKXQubq45zT8V8Xqhu4vUzraxYMG3YPpNEE+DuWTXfbN9GRjOY78YYH5jpLAGKAj5mFAcoyvWR6/Mwc1Iut141nbXXlvX51TXQr7NvffQ67r1lIdfNm8KTh05HEz/vvql8xDfTYAlwED9vwcwRRqZhkYjjG9NoBkFEmFoQ4OMr57Hp5oVU7qpm654a5pcUcPvyedFjYhno19mmdy0EYM2De6JjqfjFFk+QRITPQHkLsaY2u5kNwxgNTNDEQURYtbiUpXMnR5MtN968AAQKAzmDLtID7YsnEIa72MdLgIsVJGb7NgwjE7AOm0Mw0jyUwQTCSB3ziXQAtTwawxh17Abrh2k0QzBS23EqomriCYtEnKhm+zYMY6wxjWaUGK5mkYjWYhhGRmG/5vphUWejxGBCJp6wt6RLwzDGA2Y6G2WS0VCsWZRhGOMB02hGkeFoKEPlyhiGYWQ6ptGMIsPRUAbLlTFhYxhGNmAazSiTjIZiBQcNwxgPmKAZJfpXWI4VEvGERrzQ6DVLZlnSpWEYWYOZzkaBSADAhopytlTVRNvX3vrW6XQEQ4OWhbGCg4ZhZDtpFTQishX4INCgqm93x74HXOkeMhloVtVrRaQceA14w933gqr+qXvO9cCjQB7wE+DTqqoiMhX4HlAO1AAfVtUL6fxMQ9E/dDkcDvcp55/v90Z7pHcEQ2yoKAcGT960pEvDMLKZtCZsisjNQBuwLSJo+u3/V+Ciqn7RFTQ/inPci8CngH04guYBVf2piHwVOK+q94vIfcAUVf3sUPNKV8JmvNDl2J7oDsqaJWV9jjPhYRjjBruZ+5FWH42q7gLOD7RPnJX1w8ATg11DRGYCxar6gjpScRvwIXf3WuAx9/VjMeMpZ7CWyZHteKHLHd2XNBeHvuYvEzKGYYxnxtJHswo4q6pHYsbmi8gBoAX4nKruBsqAUzHHnHLHAGao6mn39RlgRrw3E5FNwCaAuXOTK92SSJLlYKHLEd9MLBaibBjGRGEso87W0VebOQ3MVdWlwF8C20WkONGLudpOXDugqj6sqstUdVlpaWnCk0wmyXKg0OWIkLEQZcMwJipjotGIiA/4A+D6yJiqBoGg+/olETkGvAWoA2bHnD7bHQM4KyIzVfW0a2JrSMNcE06yHCi5cktVDfkBr/WFMQxjwjJWGs17gddVNWoSE5FSEfG6rxcAi4Fq1zTWIiIrXL/OncAO97SdwF3u67tixlNKIkmWsZrO6iUz+2gukdDm/iHKVn3ZMIyJQFoFjYg8ATwPXCkip0Rkg7vrI1weBHAzcFhEDgL/BfypqkYCCT4BbAaOAseAn7rj9wPvE5EjOMLr/nR8jnhlYPqbzQoCPmZPyYsa8O5ZNZ/VS2ZyoLaZ7/76VJ/zTZMxDGOikFbTmaquizN+9wBjPwB+EOf4/cBlYc+q2gS8Z2SzHJxEWiZHhMa6G+fQ1tXDk4dPX9KCFE5d6Iz6c4ZqF2ACyDCM8YZVBhiCZDpkiggbb16AiAzpz7GGZoZhTBRM0CRAMmVgIvsuJWcO7M+JrRYQqyWtWTLLNBvDMMYVJmgSJNEyMImU9beGZoZhTCSsenMKSaasvzU0MwxjomCCJoUkU9Y/kUg2wzCM8YCZzlJMIv6cZCLZDMMwsh0TNGlgKH9OMpFshmEY2U5a2wRkKulqE5AslkdjGOMSu4n7YT6aMcQamhmGMREwQWMYhmGkFRM0hmEYRloxQWMYhmGkFRM0hmEYRloxQWMYhmGkFRM0hmEYRloxQTPO6J8XNRHzpAzDyCxM0Iwjtu+r7VMvLVLqZvu+2jGemWEYExkTNOOESI+bHQfrosJm8+7j7DhYF+3uaRiGMRZYrbNxgoiQH/AyoziXHQfr2HmoHlVlRnEu+QGvVR0wDGPMMEEzTlBVOoIhGlq7ONfWTUmhn3Nt3YhARzBkddQMwxgzzHQ2ThARNlSUM70ol4udPRxrbOdiZw/Ti3LZUFFuQsYwjDHDBM04QVXZUlXD2ZYuJuXlsGh6AZPycjjb0sWWqhrz0RiGMWaY6WyMSVWrABEh3+/4aJzThdIiP9OLcsn3m4/GMIyxwzSaMSSV4ciqSke346NZs6SMnfeuZM2SMhpau+joDplGYxjGmGEazRgRCUeObd8c2945Wc3mUtfOMuvaaRhGRmEdNseQiAYTETZAn/bOw72mde00jDHFbrh+mOksAdJV1iVW64gwEiETueZg24ZhGKNNWgWNiGwVkQYReSVm7O9FpE5EDrqP34vZ97ciclRE3hCR34kZv80dOyoi98WMzxeRfe7490TEn+rPkM6yLpFrxRL7XoZhGOOBdGs0jwK3DTD+NVW91n38BEBErgY+ArzNPedbIuIVES/wTeB3gauBde6xAF9xr7UIuABsSOXkY/0osWVddh6qH3FZl9hrrVkyy3Xez+rzXoleZ7BtwzCMsSatwQCquktEyhM8fC3wXVUNAsdF5Chwo7vvqKpWA4jId4G1IvIacCtwu3vMY8DfAw+lZvZ9TVs7D9VHfSkj9aNEru0472cN23m/fV8t7cHe6PkR4VUQ8HH78rnDnpthGEYqGSsfzb0ictg1rU1xx8qAkzHHnHLH4o1PA5pVtbff+ICIyCYR2S8i+xsbGxOeaDr8KBFuXz63z7Ui75WIkEintmUYhpFKxkLQPAQsBK4FTgP/OhpvqqoPq+oyVV1WWlqazHlp9aMM13kfEUoRc9uaB/dEzXCpEoSGYRipYNQFjaqeVdWQqoaBSi6Zx+qAOTGHznbH4o03AZNFxNdvPJVzTciPMlZ+knRqW4ZhGKli1AWNiMyM2fx9IBKRthP4iIgERGQ+sBh4Efg1sNiNMPPjBAzsVGc1fxb4I/f8u4AdKZ7rgH6UNUtmRf0o8aLSHn/hRJ9rpUP4WNSaYRjZQFqDAUTkCeDdQImInAK+ALxbRK4FFKgB/gRAVV8Vke8DvwV6gU+qasi9zr3AzwAvsFVVX3Xf4rPAd0Xky8ABYEuqP8Pty+f2SXqMCJuI832g7P5H99Zw1RVFrLtxDh6PJy1O+v7aVmxlgchcTLMxDCMTsMoAI6R/dn+k2Vik5lj/0jKpFAAWdWYYGYn9wuuHCZoUoKqseXBPdHvHJ29iS1VNSkvLDPbeVnLGMDIKuwH7YSVoRshAfpItVTVsqCjvM5YuU5aVnDEMI9MxQTMC4kWl7ThYx8ZtL+G4oRzMSW8YxkTFBM0IGCgqbUNFOTOKc3n9TGtMX5jkS8sYl2PldgwjO7F+NCOkf1Sax+Ph1rdOZ8WCadYXJoVY4INhZC8maFJAf+Fxx/J5cUOijeRJdZM4wzBGFxM0acKc9KkjncVNDcNIP+ajMbICK7djGNmLCRojK7ByO4aRvZjpzMh4rNyOYWQ3JmiMjCcVTeIMwxg7rASNkTVYuR0jS7B/yn6Yj8bIGiySzzCyExM0CWAZ6YZhGMPHBM0QbN9XS+Wu6j6NzSp3VbN9X+0Yz8wwDCM7MEEzCKrKrjcb2LqnJipsHn7uGFv31LD7SKNpNoZhGAlgUWeDsP3FWnpCYVSVrXtq2HGwjtrznYjA0rmTx3p6hmEYWYFpNHFQVTqCIRpag7y9rJjmjm7eONtGW3cvN5RP4Z4Ky90wDMNIBNNo4hDJ1VCUrVU1BENhALwi3Fg+1YSMYRhGgpigGQINK+fagnhFyPEKxbk5PLL3BCLCxpsXmMAxDMMYAjOdDYKq8sODTpmTksIAi6YX8vayYlSVAyebx3h2xkixsHXDGB1M0MRBVdlSVUNrVy/veksJe++7hTVLyqI+m4pFJabNZDHb99X2KcoZqadmYeuGkXrMdBaHSH2tu28qZ0NFOR6PJ1pfKz/g5Y7l88Z4hsZwsUZqhjG6WK2zIbD6WuOT2IrQEayRmpEi7B+oHwmbzkTkf4lIkfv6cyLy3yJyXfqmlhlYfa3xiTVSM4zRIxkfzd+paquIVADvBbYAD6VnWoaRXqyRmmGMHskImpD7/AHgYVX9MeBP/ZQMI730b6S2896VzvOhehM2hpEGkhE0dSLyH8AfAz8RkcBQ54vIVhFpEJFXYsb+WUReF5HDIvJDEZnsjpeLSKeIHHQf/x5zzvUi8hsROSoiD4hr3xCRqSLytIgccZ+nJPPhjYlJvEZqa5bMskZqhpEGEg4GEJF84DbgN6p6RERmAu9Q1Z8Pcs7NQBuwTVXf7o69H3hGVXtF5CsAqvpZESkHfhQ5rt91XgQ+BewDfgI8oKo/FZGvAudV9X4RuQ+YoqqfHeqzWOOzS0zkYIeJ/NmNtGL/RP1IWKNR1Q6gAahwh3qBI0Ocsws432/s56ra626+AMwe7BquQCtW1RfUkYrbgA+5u9cCj7mvH4sZNxJgoueSWKCHYYwOyUSdfQH4LPC37lAO8J0Rvv964Kcx2/NF5ICIPCciq9yxMuBUzDGn3DGAGap62n19BpgxyPw3ich+Ednf2Ng4wmlnP7G5JBFhE/FbtAd7zU8xTrDqB0YmkEzC5u8DS4GXAVS1PhLuPBxE5P/gaEWPu0Ongbmq2iQi1wP/IyJvS/R6qqoiEvcuUtWHgYfBMZ0NZ87jydQSG96781B9NJ/EcknGD9v31dIe7I3+PSM/JgoCPm5fPnesp2dMIJIJBuh2TVcKICIFw31TEbkb+CBwh3tNVDWoqk3u65eAY8BbgDr6mtdmu2MAZ13TWsTE1jDcOQ3FeDQzWS7J+MU0ViOTSEbQfN+NOpssIhuBXwCVyb6hiNwG/H/AGtfvExkvFRGv+3oBsBiodk1jLSKywo02uxPY4Z62E7jLfX1XzHhKiXfT7jhY1+emzbab13JJxi+xkXQ7D9Wz5sE90XBu+zFhjDYJm85U9V9E5H1AC3Al8HlVfXqwc0TkCeDdQImInAK+gOPjCQBPu//sL6jqnwI3A18UkR4gDPypqkYCCT4BPArk4fh0In6d+3EE4AbgBPDhRD9PMgxkZjrf3s1VVxSxoaI8K80S/XNJYut9gWk244HI/21smR37uxpjQcKCRkTmA7sjwkVE8kSkXFVr4p2jqusGGN4S59gfAD+Is28/cFnYs2tqe8/Qsx85sTetqhIKKw2tXWypqsnKoozxckkAyyUZJ8TTWE3YGKNNMnk0+4GbVLXb3fYDe1T1hjTOLy0MJ4+mfxFGVWVGcS4NrV1EwuZXL5nJxlWXmqFlg8AZTwEOxiUG01jNfJZ27IvtRzI+Gl9EyAC4rydECZqBSpasvbaMsy1dNLZ2A8r59m43TKLvOZkeLGC5JOMTq35gZBLJhDc3isgaVd0JICJrgXPpmVZmMdBNu6GinBeqm7jQ0QNAKKxs3VMDwMabF2SdKc0Yf9y+fG6f/72IsLH/RWO0ScZ0thAn52UWjmp4ErhTVY+mb3rpYbglaCI37SUNp441S8q4Z9V8KndXs7WqBoCSQj8iYiYKw5iY2A3fj2Sizo4BK0Sk0N1uS9usMpTYX4aOhlMWFSQbVy0A4LG9J6LHmZAxDMNILuosAPwhUA74YhzeX0zLzDKc/mYJABSmFlxyW1mEj2EYRnI+mh3AReAlIJie6WQXsdFlm3cf58nDpy0nxTAMox/JCJrZqnpb2maSxVhOimEYRnySETR7ReQdqvqbtM0mi7EIH8MwjIFJRtBUAHeLyHEc05ngFE2+Ji0zy0IsJ8UwDONykhE0v5u2WRhDYhn8hmFkK8l02DyhqieATpwc+GjLgPHOWDePGo8tCgzDmDgk02FzjYgcAY4DzwE19O2OOS4Z60Xe+ooYhpHtJGM6+xKwAviFqi4VkVuAj6ZnWplB7CIPjEmVZuuEaRhGtpOMoOlx2yx7RMSjqs+KyP9N28wygExZ5K2viGEY2Uwy1Zub3fIzu4DHReTrQHt6ppU5ZEK7Y+uEaYwGY+2LNMYvyQiatUAH8BngKeAY8MF0TCqTGOtFfqAWBZH2vCZsjFQx1r5IY3yTjKD5vKqGVbVXVR9T1QeAz6ZrYplAJizy1lfESDcWcGKkm2TaBLysqtf1GzucjQmbybQJ2L6vlvZgLxsqyvF4PNGbMN/v5Y4V84DRyXGxPBojnfTvIAsWcDIC7Avrx5AajYj8mYj8BrhKRA7HPI4Dh9M/xbHl9uVzyQ942VJVE13cN1SU09EdYvu+2lEzOVjVASOdZIIv0hi/JGI62w6sxqnevDrmcb2qjuvwZnAER0cw1MessKWqhp2H6mkL9tDW1WMmByPrGWtfpDG+GTK8WVUvAhdF5HPAGVUNisi7gWtEZJuqNqd7kmPJUCHOkWMsx8XIVvr7Iq3NhZFqkgkG+AEQEpFFwMPAHBxtZ9wzmFnBTA5GtmMBJ0a6SUbQhFW1F/gD4Buq+jfAzPRMK7MYzKxgJgdjPHD78rl9fiBFhM3ty+eO8cyM8UBSlQFEZB1wJ46PBiAn9VPKLFSVyl3VfbpnVu6qZuehesIaRpDovg0V5VH/DZhmY2QXFnBipItkNJqPA+8E/lFVj4vIfODb6ZlW5vDEiyc5cLKZ1dfM5J5V8x1NRSCsysGTF8n3e/sImfyAN6NNDpb9bRjGaJNMm4DfquqnVPUJd/u4qn5lsHNEZKuINIjIKzFjU0XkaRE54j5PccdFRB4QkaNu+PR1Mefc5R5/RETuihm/XkR+457zgKR4ZY8ksp260AkC21+sZeO2l9hxoI4rigOcPN/Os280ku/3RDWZjmCIDRXlGWlysOxvwzDGgkTyaL7vPv+mXx7NYREZKo/mUeC2fmP3Ab9U1cXAL91tcBqrLXYfm4CH3PedCnwBWA7cCHwhIpzcYzbGnNf/vUZExE69eslMdh6s5xu/PMreY01cMSmXhz92PTOK89h77BzfeOYYOw7WRTUbjycZRXF0sOxvwzDGikR8NJ92n5Oua6aqu0SkvN/wWuDd7uvHgF/hlLJZC2xTZ8V7QUQmi8hM99inVfU8gIg8DdwmIr8CilX1BXd8G/AhUtwj54kXT4KCCJQU+gHl1fpWbv7n51AUn8dDSWFONJFzS1UNBQFfxmk0mVKJ2jCMiceQP71V9bT7fGKgxzDec0bkmsAZYIb7ugw4GXPcKXdssPFTA4ynDFWlrauHrXtqaGztRgRU4VxbkFA4TGtXLz2hMOfaelDUMasdrMtYDcFCsQ3DGAsSMZ21ikhLvMdI3tzVXkZlRRaRTSKyX0T2NzY2JnHipZfhsNLRHSKsyoWOHnpCYWZPyWdqvo+ac+3sOtLIjOJcNlSUZ+TibaHYhmGMBYloNEWqWgx8HcefUgbMxjF3Dafx2VnXJIb73OCO1+EkgUaY7Y4NNj57gPF4n+NhVV2mqstKS0sTmqiIUBjIYX1FOdMKcmhq76EnHGZaYQBUmT05j9wcD7UXOukIhvCIcOtVpRnroxnrStSGMZERkb1jPYdkEJHy2ECufvvuFpFZiV4rmRVxjap+S1VbVbVFVR/C8asky04gEjl2F04Ntcj4nW702Qrgomti+xnwfhGZ4gYBvB/4mbuvRURWuNFmd8ZcK2Wsu3EOKHg8HrweYXJeDm+fWUggx8vp5k5qmtrp6A7h8Qg+D+w+ci4jF23L/jaMsUVVbxrrOaSQu4G0CJp2EblDRLzitHO+gyE6bIrIE8DzwJUickpENgD3A+8TkSPAe91tgJ8A1cBRoBL4BIAbBPAl4Nfu44uRwAD3mM3uOcdIcSBARAuIJGRWffYW1q+cT0NrN9OL/LT3hGlzNZmb31JCYSCHgycvUrmrOiOFjWV/G8bYISJt7vO7ReRHMeMPisjd7usaESlxXy9zg57iXa9QRB6JiQj+Q3f8IddN8KqI/EPM8QNeW0RK3VSTV0Vks4iciBwHeEWk0t33cxHJE5E/ApbhdFo+KCJ5Q332ZCoD3I5jPvs6jl9ljzsWF1VdF2fXewY4VoFPxrnOVmDrAOP7gbcPOusRMJAWsPHmBQC8fOIC1ec6CCuEVHm1roX1FeUIQmFuTsZqCP3nlanzNAxjSP4Ox/LzDoCYtI//o6rnRcQL/FJErlHVwVJRvgA8o6r/JCK3ARti9i0G1qnqRjfV5Q9V9Tsici/w1+4aPCQJCxpVrWEQU5mI/K2q/lOi18sWbl8+9/KmYygHT11kelEuzZ3d9IaUpvZuwIniykQfjWEY4473Ah+JbKjqBfflh0VkE876PhO4msF7h1UAv+9e4ykRuRCz77iqHnRfvwSUD2eiqVwR/1cKr5VR9P/Vf/DkRQDeNquIhSUFbn4N/PBAfUaazAzDyCh66bv25sbZFzueEOKUBvtr4D1u9+Mfx1xnONcOxrwOkZwVLEoqBc2EsMGICBWLS3jbrCJeO93KFZPy2PPZW3jXW0po6exh07df5vF9w0kvMgxjgnACuFpEAiIymb6uhBrgevf1Hw5xnaeJcTe4prNiHN/5RRGZgVNxZahr7wE+7F7j/cAUhqYVKErgOCC1gmbC/JS/Y/k8brlyOm+dWUxDaxdb95zg4Y9dz1tnFvP6mVY6giHTbAzDGBBVPQl8H3jFfT4Qs/sfgK+LyH4cDWIwvgxMEZFXROQQcIuqHnKv9zpOv7A9CVz7H3Aie1/BsUydwREkg/Eo8O+JBgNIqhZEETmgqktTcrE0s2zZMt2/PyEf1oBEfDbhcNgtplmHo9Apa5aUWba9YUxssurmF5EAEFLVXhF5J/CQql6byvdIpUbznym8VsYSWwHZ4/GwfuU8Glu7Ofrq/fkAACAASURBVN/eDUi0KoCV4zcMI0uYC/za1YoewClUnFKGdOyIyDcYxCymqp9yn///FM4rY4iNOFNV2oI9PHnIKdWWmyM8treWi53dTMrzo+rUOysM+Hh72aSoZhPJx8nEYpuGYWQ2IvJxLhU3jrBHVQdMB0kWVT0CpNUalUgEwfBtTFnO9n21tAd7+5rCFGZPyWPrnmrOt/fQHQqzsKSQpz69ktu+voddRxqZN7WAI2edMnD3rJrP5t3H2XGwjrXXll0WKm0YhjEYqvoI8MhYz2MkDCloVPWx0ZhIphHbvwUuCYwnD5/mg++4ggO1zYRU8Xs9BHxQ8dXnaO7oZt7UAt42q4i2YIgdB+vYecgJeZ5RnEt+wDsuhMxleUUmPA3DGISEY6JFpBSnkObVxMRgq+qtaZjXmBNbUj+2f8vqa2Zy4GQzACUFAS50BHnjbDuqSkHAx1OfXskje2vZeaiOc21BSgoDnGtzWgxE2gdk66Ksqjzx4smolhfBzIKGYQxGMsEAjwOvAfNxwuFqcGqPjVtihQ1ccugfqHUEzd3vnIvf66E3rIQU8nK8bN17gvUr59ETUs61dXO0sY2LnT1MLwpEF+psZPu+Wip3VdMW7GHnoXoqd1dTuauaTzz+snXpNAxjUJIRNNNUdQvQo6rPqep6YFxqMxH6928REQ6cbGb9ynLufudcvvmralqDITwCRQEfby8rZuehejZue4kL7U5C7eQ8P5PycnilroVH9pygLdiTdQtyxIz45OHToLB6yUy2VtXwtV8c4UBtM6uXzLSQbsMYJcrv+7EMtj0cROQ2EXlDRI6KyH0jvV5/khE0Pe7zaRH5gIgsBaamekKZQrz+LacudEZDm7t6QxQFfFw1o5A/f88izrYEmVGUS2GuE3VWUhjgYmcPFzu76egOce2cSWxctSDrFuTYlgJPHj7NzoP1XOzsYVJeDqVF/qz8TIaRjZTf9+NNwF9GhIv7/Jfu+LBwi29+E6eKwNXAOhG5OhXzjZCMoPmyiEwC/gqnls5m4DOpnEwmMVj/lsLcHF6uvcC0ggBzp+bh9XrRsLLm2lnccmUp7yibTENrkPUV5SwsLWBSnp/ecJjr5iVS2SEziXx+VcckCFBa5AfEGqcZxijgCpUiYB2XhM1futtFI9BsbgSOqmq1qnYD32V4vcbikkz15kj/hIvALamcRKbSv3KziJOQ+cntBzh4spmP31TOpnctpHJXNVv3HGfpnCl866PX8cSLJ1m9ZBaoc06k6GbEt5ONqCqVu6o519Yd1WZWXzMLhD6ReabZGEZ6qLn/A1p+34//zd1c5z4AngD+reb+Dwz3114ZEOs8PgUsH+a1BiRhjUZEHnMLwEW2p4jIZT1ixhsD9W+pPd9Be3ffMkTt3SFOnHf6wEW6ckYapj355xWsX1nOqQudWfnrP7YB3NK5k/nM+xazfmV5H5+Ndek0jPTjCpN/6zc8EiEzKiRT8vkaVY3+JFfVC66fZsKxdsksHnz2KA8+e4wnD9dzrq2H/BwPMyflsv3FWu5YPo/C3JzLGqZFzHHZtiD3NyP2H19345ys+0yGkY3EmMti+cvy+348EmFTB8yJ2Z7tjqWMhItqunVw3h1priMiU4HnIt3dsomRFtUMh8Pcs20/z77RiFcEn0e4adE0GluDrFlSFq13BlxW9yy2nE22JT1m45wNYwxIy03RzyfzBI5m02d7OMJGRHzAmzjtCupw0lZuV9VXUzT1pIIB/hV4XkS+JCJfBvYCX03VRLKJJ148Cap4RQipEgyF+XXNBWZPzic/4OWT2w9QubsauOTb+MTjL0dzaGILc0aO2bz7ONv31Y7ZZ0oEawNtGGOHK0Ra6StU/s3dbh2uRqOqvcC9wM9wciW/n0ohA8kFA2xz+xhEcmf+QFV/m8rJZAPhcJhnXj/LriNN5Po89KrS3RumtauXrp4e2jp7OFDbfMnxr7B1Tw0AS+dOJhwOD1jaJhJGbVqCYRjxqLn/Aw+X3/djiQiVSIDASH00qvoT4CcpmeQADGk6E5FiVW1xTWWXoarn0zKzNDIS05mq8sFvVHHkTCt+V9D0hpRQWJleHGDvZ29hS1UNW/fUcLHTST2alJfD+oryaL5JbI5OhFh/jmEYWY3dxP1IxHS23X1+CaeSc+QR2R7XDNRXZs6UPPw5Hrp6w0zOy2FaQQ4FAS+d3SG27KnhnlXzoyHNwGVJjf1L24CFBhuGMX4ZUtCo6gfFWQHfpaoLYh7zVXXBKMxxzBjIl7KlqoaKRSXMnuJ0L23u6KGlK8SN5VO495ZFFPh9bN59PJrUCNDY2k3l7urLfDKxZGPYs2EYRiIk5KNRVRWRHwNZF2E2XOK1CdhxsI7SQj8+jzCtwM/04gANLUEaWrujjdEe2XMCgM+8b3HUR7O1qsa5TsV8t/1zfdRcFmtGM83GMIzxRjJ5NC+LyA2qOq4rNkeI1yZAgfqLXZRNzo36Wzq6Q5xrC1KYm4OIsHTuZJbOnczGVZcUvgMnmykM5ODxeAYsbQMklGNjIcaGYWQbyeTRvA4sAk4A7TgOL1XVa9I3vfSQTDCAqrLmwT2AE3E2Y1Iuz73RSL7fx723LuTF4+f5Vcz2ppsXRs/zeDzR17HbkbFkBUb/jp/WItowMhL75dePZDSa30nbLDKU/r4Uj8eD3+thamGA821BvvaLI6Awv6SARdMLKcr1IyIDtoDeUlXTRyAkm5MSz5RnYdGGYYwUt5zYB4EGVX17qq+fTB7NCRGpABar6iNux83C4bypiFwJfC9maAHweWAysBFodMf/txvfjYj8LbABCAGfUtWfueO3AV8HvMBmVb1/OHPqT/82Afesmu8Wz6zBK65gUOgNK7l+L9fNm8K6G+ekTSDEM+VZWLRhTDD+ftJtwN/gNKE8Dvwzf3/xqRFe9VHgQWDbCK8zIMmYzr4ALAOuVNW3iMgs4D9VdeWIJuD0QqjDqRb6caBNVf+l3zFX42S/3gjMAn4BvMXd/SbwPpyKo78G1g2VSJqo6Wz7vlraunqidcpUlX9/9ghbn6/lXFswetzCkkJ+9hcVeL1egLTmycSa8gB23rvShIxhZBbpuyEdIfNNIAh0APlAAPjkSIWNiJQDP0qHRpNMCZrfB9bg+GdQ1Xqc3ggj5T3AMVU9Mcgxa4HvqmpQVY8DR3GETtr7KMT+y4TDYX5woJ4L7d0UBny8bVYxhQEfpy50sOnbLxMOh51T0pQnY2HRhjHh+RsuCRnc56A7nrEkI2i61VnRFEBEClI0h4/gaCsR7hWRwyKyVUQincIG6pdQNsj4ZYjIJhHZLyL7GxsbBzqkD9H2xYdORxfzrXtO0NjWzaS8HOZOzUMQ5k3LZ/aUfAoDvj7O/1QLhHgdP3ceqjdhYxgTh/lcEjIROtzxjCWZYIDvi8h/AJNFZCOwHqgcyZuLiB9HS/pbd+gh4Es4wuxLOIU814/kPSKo6sPAw+CYzhKY2wA+EWXZvCmcaenkQ9fOjvpf/ufgKd5eNim62Ffuqo72oklVnky8jp+QWFi0YRjjguPATPoKm3x3PGNJJhjgX0TkfUALcCXweVV9eoTv/7vAy6p61n2Ps5EdIlIJRLp6DtYvIW19FCKL+SVfi3DrVdPp6A5FF/v8gJcrivPI93ujfpwDJ5uZPSUv5QJhoI6fFghgGBOKf8bx0UBfH80/j9mMEiAZ0xmq+rSq/o2q/nUKhAxc6qMAgIjMjNn3+8Ar7uudwEdEJCAi84HFwIs4zv/FIjLf1Y4+4h6bEgYygXV0h6L9ZlSVjmCIhtYuOrpD0eNPXehk6dxoM9KoQEhFrouV6jeMCYzj8P8kcBqY6j6nIhDgCeB54EoROSUiG0Y81xgS1mhE5A+ArwDTcVzkkYTN4uG8sevjeR/wJzHDXxWRa3FMZzWRfar6qoh8H/gt0At8UlVD7nUifRS8wNZU9VG45BOpY82SshgTmKMw9ddWhgo5Hk2BYNUDDGMc4wiVkYYz90FV16Xyev1JxkfzVWC1qr6WijdW1XZgWr+xjw1y/D8C/zjAeFr6KIgIr9a3ML0ol/Ur5yEibKgo54XqJl6pv9jnuHtWzWfHwbroYn7Pqvljtrhb9QDDMDKNZExnZ1MlZLIBVeVts4p57XRLNHR5S1UNZ1s6eeNMK3/2nZcIh8OX+tM0tNHk5tZU7qrmnsf28xffPXjZNQfbTsWcI8mikUi0SCBCe7A3IyPT0v2dZAP2HRjjnSE1GtdkBrBfRL4H/A9O3DYAqvrfaZrbmCIirF85jxeqm9h7rImb7n+WkiI/pUUBflvfSt2FTu557NfcUD6Fow1tBHvDdPWEKJucyzeePUpnd4ibF5cQDofxeDyjomlkW/WAx/edoCN4KbAiIswnkvaVTRqomWSN4ZKI6Wx1zOsO4P0x2wqMS0ETWQAe/th1rPzKr2ju7OZsSxc5XuGWt5Rw7FwHe4+dZ9ebTXg9Sl6Oh/MdPTz927OICIumF7L5rmV4PJ5RrVN2eaRcZrYeePyFEzzzegMNrV0AbKgoZ+O2l3j9TCt331Q+IRaxbKpfl00C0cg8hhQ0qvrx0ZhIJhFZAHYcrOOF6iZKivycawuiQHdIOXaunYDPS09ICanSG4JcD3gEfB5BRPjxn6+MJnCOpqYRL1k0k4RNpLXC2ZYuZhTnsvNQHVuqjnOxs4ebFk6LRvWNd7JFA80mgWhkJsnUOluAU7xyBY4m8zzwF25JmKwikVpn4XCYjdteYu+xc/g8HnpCYXweoaMnRFjdkLuY4wXI8YLX40VRyibl8fGKcj66ohy4ZHe/VKdM2XlvRVqEzEBN1TJx8Yo0kjvW2A7ApLwc9t53S592ChOBbKhfl876feMQ+0L6kcwdvR34Pk5W6izgP3Fqi41LPB4Pt15VGhUyk/P9HPrC+8jLccvMuMfl+i5te0Q4/Pn3UDYpj2Pn2vn6L44SCoXYvq+Wyl3VVO6uds9SGlu7+cTjL6fU8RupHrD6mpl9wq9XXzMz46oHRKL4Yltelxb52VJVM6Gc4dlSvy5d9fuMiUEygiZfVb+tqr3u4ztAbromNtY45p0wRbk+JuXlUFrk588ef4lgb98FoKs3HH0d7FWu+/IztAV7CPg8TC8OICK0dfVE2zmvXjKT1dfMAuBAbTOVu6tTv6j0v/czcC2IaIwXO3uYlJfDwtICphc5ZrRUL7SZGtWVTfXrskUgGplJMnk0PxWR+3C0GAX+GPiJiEwFUNXzaZjfmBC7ACyZM5mlcyYTCoX4v788Sm944Bur0O+lrTtEe3cvHd3wvqtn8NBHr0dE2HjzAg6cbOZAbTM7D9a7EW3lIFAYyEnZr8LYQqCCRE1nTx46nVG2dFVlS1UNr59p5aaF06i883q2VNWw42AdM4pzyQ94UzbPTHZiZ0v9usFMsmCajTE0yQiaD7vPf8Ily5HglH1RnOZl44JYExQCTx46zewpeUzKy6G9O0SwN9xH4HgEesLqlkoAFejuDUcXdhHhW3dcx+pvVEVvyI03L4i+VyrnnQ3O5cj3e/dN5WyoKMfj8UTnne/3csfyeSl5n2xwYmdD/bpsEYhG5pJMMMCHgadUtUVE/g64DviSqr6czgmmg0Qbn6mq82uu6jhbq2poag/iRelRCIUHPsfnEfL8Xgr8XtavnB8VKKlypCaSy5ANzmUYnbwMc2KnDsujSRj7UvqRjI/mc66QqQBuBTbjlPUftzzx4km2VNVwT8V8phXmIEBX6JKQ8fT7d/J7hcWl+fz5LYsA4cDJZkKhUMrs8Nv31fY5J7KIbt9XGz1mMFt6pvkqRqNAqDmxU4cVdDWGSzKms5D7/AGgUlV/LCJfTsOcMoLYXJofvHyK821dlx3T313THVJeb2hnf00TH185j8KAjz/5zgGa2rpHbHZIxAwExLWlv1x7gaVzJvdpS50pvop0kg15RYYx3klG0NSJ0/jsfcBXRCRAkm0GsolI+O3zx86x68g5Zwy9LH+mP6rwqzfPEewNcaalm9rzndy0cFq0MGfk2skudJH5QN9GbJHK0pFrDWRLV5QDtc08efh0dCzTfBXpwJzYhpEZJBsMcBvwL6ra7PaOyeg+1SPF4/Hwnqtn8Gr9RZrauulJwNKU6xOCvcpzR87jEbjlylIq77z+siTEZBe4SPTUhoryqJBpbO2ONlyLMJBzeeOqvn6iTA0SSDWZ4MQ2v4ZhJNdhs4OYumaqehqn6c64JdLYbFqBn8aYxMLB6OqNjUYTHv7Y5UJmOPNo6+ph56F6XqhuIiJkLnb28MzrDay7cU6f94hnS8+GGmipZiyjujI5tNowRpNxa/oaKbFml7XXlrGotCCp830eIccrbPq2005gJDzx4kkUZUZxgL3HmmhsDaKqzJuWT0NrV0LZ9BM54W4snNjZ2LLBMNJFMqazCUVsLo2inL54eTDAYPzVexfx6xPNPPfmOX7vgSp+8qmKYWk2kQXrR4fPuLk8PlShpauX9W7xyaHMQOarGH2yJafJMEYDEzSDEDG7bN9Xy7LyKew6ci5u/kwsHuDR52spDHjwegSvW9F5OMQ69LdW1dDc0YOIMCkvx8n+r5g/pADLBF/FRCRbWjYYRroxQTMEIsK6G+fw9KunExIyAD6v0NgWpLEN3vWWErbcdcPIFxeFi509TM73U1rkZ/U1s/pEkQ11/cF8FeawTg8WWm0YDuajSQAR4eWTzUMeF0ng7HXL0RQGfGy564Zo87NYu/xACZSDceBkc7S4JwgISVdlHshXkUgSqJE82VQw0zDSjWk0CRAOh/ElsJj7PU7lAFXw53iYOzWPLVU15Pu9VB09F02YBKjcVc2Bk82sWlx6mbbR/3XlrmpOXehkfUU5G1ctiC5gq5fMZN2Nc4b9ubKhFli2YuZKw7iECZoE8Hg8LF8wjadePTtosmaXWzvB7xUWTMunq0d5ZO9x3npFEa/UtXCg1tGKDtQ2U3XsHAV+L0vnTCYcDrOlqoaCgPPniA2JBUebmT0lj42rFqR0wTKHdXrJhoKZhjEamOksAUSEw6cu4k/g2xLgnQumEFbhVHMHeT4vt1xZygZ3Qf/aL97k6dfO0tkd4uqZxdyzaj5bqmrYeaietq4e2oI9l4XEnrrQydK5k/vM555V81OSi2G1wNKL1QczDNNoEuI7z9dwoaOb4CDBADkep/aZKlQdO09JYS43LZiK3+fF4/GycVU5Tx6q52JnDzleKM7NoaE1yNpv7gUuaREAggypYaSyh405rA3DSCem0QyBqtLe3UtoCN9tTxhCCmEcraakMIcVC0qoa+6iLdjDw7uO0dgaqS4giBBNvIRLWsRoahjmsDYMYzQwQTMEIsKmmxeyaHoh3gTX+t4wHDnbxtY9NU7CpyqP7DkBKJ9572I+897FtHeHaGrvjgqb2FL+qcjgT6QlQDyH9Zols8xhbRhGyjDTWQKICH+8rIzP72wZ8tgcD+Tm+BCBhtYuXj5xnlVvmc7SOZMJ9oYoCHhpD4Yo8Hspm5zHx945j45giJ2H6h1h4Hb0HEkGfzI1tsxhbRhGuhkzQSMiNUArTp+bXlVdJiJTge8B5UAN8GFVvSDOqvd14PeADuDuSGdPEbkL+Jx72S+r6mOpnKeq0tvbyxd2vpbQ8QU5XrrCYVQdn83uo02sXFTC0rmTefJwPR3dYQoCPtavnM89q+ZHc2yAaNTZSEJihxOybA7r9GCJsIbhkHAr55S/sSNolqnquZixrwLnVfV+EbkPmKKqnxWR3wP+HEfQLAe+rqrLXcG0H1iG0ybmJeB6Vb0w2Hsn2sp5+75a2oI9vHT8PD97rSHhz5bjgZKiAN09yvmObgoDPuZNy2PttbP7+F/6L0KRsciC1P85Uax98dhjlZsnNHaT9SPTfDRrgYhG8hjwoZjxberwAjDZ7YfzO8DTqnreFS5P4/TMGTGxmsHe6qaEzon8d4UULrT3MKPYj9/nQaRvGPHm3cd54sWTfc594sWTUV9M7MK0fV9t0sJhtAIKMq01dKZglZsNoy9jKWgU+LmIvCQim9yxGW6fG4AzwAz3dRkQuzKfcsfijV+GiGwSkf0isr+xsXHIyYkI+X4v0wsDkOAC7REoCnjxepwSMScvdDIp10dPyOkfU7m7mspd1ZctOKlemEajJYCVrolPbFDFzkP1rHlwT5/K2aZVGhONsQwGqFDVOhGZDjwtIq/H7lRVFZGUrYyq+jDwMDimswSOp6M7RENrkAK/l9au3iHfwyvCsnmTaWjtpvZ8B63BEAGfh0+/ZyGP7q3la08foTjXx4aK+X0WnFRm6I9GSwArXTM0VrnZMC4xZhqNqta5zw3AD4EbgbOuSQz3OeIYqQNii3rNdsfijY8YEWFDRTkzinO50DF0d02/V1CU355uY+3SMlYuLMEr0OrWpSkpzKEo4KWzJ0RBrm9AJ/Elc5cC2mdhSlQbGW7IcjJmMPvFPjQTudGcYfRnTASNiBSISFHkNfB+4BVgJ3CXe9hdwA739U7gTnFYAVx0TWw/A94vIlNEZIp7nZ+lYo6qypaqGs62dtE7VLYmkOMRJuX76egOseNAHYfrLlI+LZ8pBTn88EA9qtDZE6KzJ8Qvf3s22nXzOy/UULmrmnA47CxEKCeaOjjR1EHl7uo+uTUDmaUGEhC3L587oMYUzwk9HDOYla6JjyXCGkZfxsp0NgP4obso+YDtqvqUiPwa+L6IbABOAB92j/8JTsTZUZzw5o8DqOp5EfkS8Gv3uC+q6vlUTFBEyA94KS3w80oC60JXr1KUJwRRzrUFASHX7wXgWGM7Po8QUsXv9fBq/UUqd1VTEPDxyJ4aGlq7+MHLp8jxeejqDrkLkbC1qgYADSs/+s2ZqFkqMr9kIpsG02SGYwaz0jXxscrNhtGXMQtvHksSCW+OLKT/c+AUTW1BzrTGN58JTrxAjsdDKBzG5xUm5fm5emYhv3qzCQV8HiHX56Eg4OViZy/zpuUza1Iuu482OcEDKKrgEWHlomncUD6FR/fW0tUTIjfHy/qV5dEWA5t3Hyc/4I0meq6+ZiYbb45pH+BuJ7qgJRsOPZgfKN55EzGnZKDPDJeHtY/372ECYn/QfmRaeHPGICK8Wt/CjOJc3l5WNOixilNMszccJqROw7P27l6edYUMOF03y0sLeNusYnxe4c2GNnYfbSIvx4vfKwR7lbDCpLwcKu9cxp+8axHTCnLIzfFysbMn+q8bWdA7giE2VJQze0qeU+rmG1VRIYNwWfj0UJ81GTNYsn6giRqh1v97iA1hh4nzPRiGlaCJg6rytlnF7DhUx7S8ob8mxV1YVDnX3tNnX2HAy7yp+cwoyuVsaxcFfi9dPWFCqvSEw/T0hvF5BJ9HKC0KULm7GhHB4/FQUugHYGtVDU8eqgekT6XnpXMn86s3nHDtkkJ/nxI2if5aHo4ZLNHSNRah5mDfgzGRMUETh8jCGQ6HeeCZI4Mfi5ND0xu+3Azp9wr33rIQj3jYeaiOzu4wnT2OeS3Uq3T1OEEB0wtymDEpl9KiAN/45VE8HuHeWxexcdUCKndV87VfOHMoLfL38cngakEXO3u42NnD1qoa1leUJ+wrGUk4dCKla0YSuj2ezG2pDGE3jGzDTGeDICJsetdCQgMIkOgx4FR1jnPI7Mm5/Oiwk4NaWhigsS1Ivt/HyoXTKHCDBQCK8nx84B1X8Nv6VnrCysxJudxTMT/6JpPyclxfjrB59/FolNqTh0+zfmU5i6YXRAXOoG1AB/iM6a7gPJwItfFobrNIPWOiYhrNIKgqDz93jO7e+Cu3AgPtvqI4QHswRO2FLuZNzSc/4OW9V19Bbo6P7lCIsy1BVi0upau7h1fqW6k938mje0+gCrdeOZ1v3rEUEUeoPHnoNOsrytm4akEfbSPf7436ZEAoLXLMbC/X9i31NpQmkO4Kzsma5sarmcki9YyJigmaOERNSofr8XogPEh3zf4sLMknz+/l6lm5/LrmArl+L3csn4eIcPvyudGw5I03L4jmydx0/7N4PR6m5OfwrY9eF114BguTXXfjHCp3V/dpK/CJx1/mQG0zlbuq+0SpDVXMMREz2HAYyjS3oaIcj8fT5/jxaGYajYoNhpGpmKCJQ8SktPbaMv7rxRrePNc15Dl5XvD6vCwoyeeGBSUU+H2smD+NgoC3j7YATt+ZyKJauasaidmO/ZU7lLZRGMi5LDjgQG0zB042A4y5JjBYTsmr9S1sqaqJmwc0nkq4WG6NMZGxPJohCIfDVO6u5p9++saQxwowLd9HSXEeH10xl4+uKOfbzx/nV280cutbZ3DH8nl85/kaHt1bQ2NbN8vmTeaGeVP45q8cQXND+RR8HqH+YrCP8BhqEYoVIKoa1XIiZIIm0F/IhcNhtlTVxM3F2VBRHt0fIRM+x0gZTwEORlzsD9oP02iGQEQIh8MM4u93jnP3n+vo5XxHK8++3sBHls3mgWeO0dQWBOAjy2bz7BsNHD/XTq7fy55jTew52kRvWCmfls9rp1t468xiPviOK6JN0AYyew22OIkIG1ct6CNoxmJxHmoB9Xg8cc1jsUJmvJmZ0mWiNIxMxqLOhkBVeXTPiSEDuWL35/o9vHa6lYqv/ooL7d3keDy8UtfCh761l1frW8n3+yjI8dAbUoIhx/kT8AlvnTmJhtYg4hHW3ThnwFYBQ0VjZUIxx0QjxuJFYXk8nrRHwhmGMXqYRpMATQlUb44gQEd3mI5ux6dTnOvj+rmTqDp2nha31YDTNuBENJcmxys0tfew897r2LrnRPQXvvRLzhwqGmswc1Tk+HQv0slEjA0WhZXuSDjDMEYPEzRDEA6H8YgHSCzsrL/eEFbYf6KZcFjB40SY/ddLdTR39pDj8YDXOeZcWzebvv0SD3/seh7Ze5zWrl6Kcn19unIWBHwDmJuUNUvKootwfsA7pg7nRCPGhhOFZULGMLITEzRD4PV6WViaNcLjNgAAIABJREFUx2tn2od1fndviN6wUuD3MndqHrXnu6g+186UfD9XFPuZUZzHq/UXae7s5cXj59m47SVau3ppCzraT+WuagCePOyEMAPRaKzz7d2EwsqGivJo1FZHMES+3xvdjtUERsvxHHnPwSLGLArLMCYO5qNJgDlT8vtsv8tzkO05X2aX/9Nsz/ky7/IcHPA8v1foDik5Hg8rF5Xwo0/dzMpF0yjw+5hRHGDttbPZfNcyNlQs4N2LSwBh99FzFPi9vHtxCQV+L1/7xRG27qnhg++4oo92A0oorFzs7GHjtpeilQJ2HqqnozvE4/tORP0ksaHDo5FZn6ifKNm+OYZhZCcmaIYgHA5T3dga3X6X5yBf9D1KqTTTTAGl0swXfY8OKGxUFZ9HKM71cu2cSWx/sZaHPno99966kDtWzIs6vjfevICHPnY9xXk+phUE8IiwYuE0phX4mZSXg0dAPML2F2tjzE1l7L3vFm5aOI29x5q46f5n2XGwLhq1FWkhEFngBwosGIxkOm72Py6Zpl9mHjOM8Y/l0QzC9n21XGzv4qs/PxL1vWzP+TKl0kwngehxeQRp1Mnc3vO5y67h8wged+2sWDSNzXfdADi/8A/UNrPqLaWoKs+83kBDaxfhsNLU3s2Fjh4CPg9zpuTR5FaDXl9RToHfR0d3KKoJhMNht6qAMLXAz857V/bRYIaTh5JMQ7V0nG8YWY79WuqH+WjiEBs9FSuKZ0sjIYQFcp4ceunBR6MWM1saB7yOV5xeNF09YfYdPx81KW2pqqajJ0xvqJcwwt5j57lp4TT+/Y5rue3rezjT4uTe9BEKSnShjizgW6pqKCn0R4+LrSownMz6VNQZs4gxwzBiMUETh8jiuL+midfOXgoEaCOPRVJHGA8hPPgIUSZNHNWyAa9TPjWXlu4wpQVw4kKQf/rp6/h9QjisKMLxpk7uvmkeqnCmpZPr/vEZenrDLJiWT1cojIhTLHP1NbMozM0ZMGpr7bVlA9YQ2+K2go6QSAHHeFFjq5fMvCxqbKjrDLadLJZRbxjZi/lohiDcv5pm1NSoMY/Y8b682djJ2YtBTjYHo0cHe5WeMHg8cKq5k+/sO8mN86dyoqmDtmAvXg/MK8lHYjVwgXU3zrm0OUh5/3y/t08+zVB+koHMp7GJlOfbu/vEbY92yf7x2DLAMCYSJmgGQVU5XNfSZ6xQujil0+jBhxelBx+ndBqFMnDRTcXJwAkNIIfmTM7jnfOncLShjfufeoO2YIgcgd6QsvtIE1ddUcj/fOKdTC/K5bG9Jy4TEvGitu5YMS/hzPqBFvHK3dV84vGXo58gFFa27qmhclf1sAILRkKsKW+4gQ2GYYwtZjqLg6pSuauas619qwKc0lJKpZnjOjM6lkeQMzo56fc4fbGTP7qujF1HmqJjUwsDNLQGyfF4uKF8Cpt3H+dsSxdXXVFIfkwV6AgDbatqHz9J/3ya2M/Y3x9Tubuara7Jbf3KcjbevCA6tnWPoyWJyKgVuByPLQPGK2beNOJhgiYOEdPU1Dwv5ztD0fH/CH2QL/oeBaATP3l046eX/wh9MKnrl08J0NjWzda9J/B4BMJKSOFCRw8FAR/hUJhtz58grMLSuZO5dvakvqa0fkRu6kjEV6TPy2ARX/EW8aVzJ7N0zmQ23rwgWqQT4LG9J6ILx/9r78zD4yrPQ/97z5lFqy1bkvdFxoYQ0mIbCCG2CQ1tCuHBJuXm9gkQCIsxvYXc5LZpS9omN0nb5za5adLcQBaMXQIXSLokxXbCbUjjALbDEmwBwbHBlld5k2Rrl2Y5571/nDOjo/HMSCPNSJb8/Z5Hj2bOzPnON2ek7/3efSwX+aECG8wCN/6YSENDPozpLA+vHDxNe0DIADzvLuPzyTtp0Rpq6KFFa/h88k6ed5cNe1xb4FhnHFehrSfOBXWV/Nl1FxGxhVjSpTfu0Jdw6exL0tEXJ5502PzG8bNMRZmFNh3HoSeW5JnGZu59/LV00mbKzJTpbxrcZGxg3G/ddtnZgkRhemUk/XQsC3XmSwA1/pvxx5g3DUNhNJocuK7LnuOdZ1U4u8Zq5D57C/OkhaNaz3edGwsSMuAt6XHfaWMBc2rK+Kfth1hUV8mRM330JxxcoDvuYAFvHu1g7dUXsPbqRWdpLnevXOj/kzfzUlMbH3xXPTOnlLFjfxtvHeukrirCTcvmpgMEMnecFRGbbftaaemK+62ghfUvNoFCVVk4XUU6VQJnrAt15quJpuo1kEu1RJgsLZ9LTbE1QGPeNAyFETQ5EBHWXDqTr/6sKX0sVRUgTmhQVYBCNRo3sMGriNgcPdNLbzxJbzxJMuniKlRHbXriDuVhi7aeOLuOtPPkS4fYureFay+upzfu8kyjL1wurmdGdUC4VHsVBVL5NZlNxFIL8jONzcycEuWtY17lg9WXzgFhkI8G8reTHgsfzVDtrAUxC9wwKZWJa6R5W4bzA1MZIA/xeJyLPv9c+nm2qgC1dFBJP51U5tVwKsNCzAHHVRRfwluCq5oWPBFbuMZq5C42M99q4Yg7MN67ZlYxt6acHU1trLiglvV3XM66J3ayfV8rU8pC1FdHaetJUFcdoaUzRn11FO9/XPJ2rKyI2vTEkqBe4U5VpbU7zvIFNXzrtsvOGT9Itg6dlmWlX1vz0DZSCdmp6giGweTTDkcrnEdTieJcZJR/7xPvA5cYo9HkIdOnsUSOUi6e8z9OiLhaTJNeBAjhYOPk1HB6EkrEgmRqbMB1ddBf5Pt1F38tj5EgxBkd0Ji+4NzFL9uWc7yjn6qIzVvHOrnp4R2A13agoy9BR1+CaZWekGnriTOtMswfLJtL49GOQUmc2Xacqc3G5jeOIyLUVUUGCRkY/5pkmSHZqV05wPoXm2jpiqfL8AwnMfV8pFQmrpG0fDiXMYENxWdcggFEZL6IbBWR3SLyloh8yj/+BRFpFpFG/+eGwDmfFZF9IrJXRK4LHL/eP7ZPRB4s1hxd1+W+/7sr/fwaq5Ep0keEBA5ClDjTpdd7L0IIlzrpJESS++wtWceMB+RW6mFQn7zP3kKcEL1EAaGPKAlC3B/5MTUVEVzXJZZ0aemO0dod40BLD3FXiTlK3FG6+hLUVIQpj9g0n+ln4/aDLJs3ldVLZ1MRtbNWCkgJmaCzXUTGvCvncAk6nte/0DQoHPsT71/I6qWzcyamGnJ3NR2tj2aydEQ1gQ2lYbw0miTwp6q6U0SqgddEJGWj+rqqfjX4ZhG5BPgY8B5gDvAzEbnIf/lh4EPAUeBVEdmkqrtHO0ER4Whbd/r5ffYW2rSaOunEAmxfRAiQwMZFsICp0sM8stc9y4XtRTczT1pop3LQa31EmOWepLYqDChner0Cm6laaBFbWFRXybH2fvoSDvtbeqitDAPCZQunse6axemaaEM51CfCbjRzV366x8tzSuX8AAgy4Ra4sSJfV9PR3K/JUt/OBDaUhnHRaFT1uKru9B93Ab8BshcL87gJ+L6qxlT1ALAPuNL/2aeqTaoaB77vv3fUiAgff39D+vk8aaGNKRzTWpLYCJouKeP4t9FFiJDkqNYXejEiIYujWk85AwmilkC5JDii9bR1x+mJOTiuUh4SwpaXVWNZwkeWzmZhbQW1lRFEoK4qSn11NG3+siwr546zqixMVTQ8oXajwcVgemWEuqpIeu6p14LlegwehbZwKJTxNq8Wi1Jofec74+6jEZEGYDnwMrASeEBE7gB+haf1nMETQi8FTjvKgGA6knH8fTmusw5YB7BgwfDsrB9dPosv/uRtb2C/IkAXFXRpBYvkOFFihFAsXFwEGxcXq+DkTcdVXFf5rjU4GTSqnj/oO8kbae32fBCiSr/jFeUU8fw8D/2iieoym964i6oy//R21lpb6PryaapnLUZWfIpb3/ehvDvOYu9GSxk8kLkrP9PrNX9bf8fl6QABY1M/m6Ei+MxC6lEqre98ZlwTNkWkCvg34NOq2gl8G1gMLAOOA/9QrGup6iOqeoWqXlFfPzyN499ePwl4/pkaumiQEyyRZqrpoVO9opentYoEIcK+kHkoeVNBoc6Cp7ko2ZNBP+cHFiRdJZZ0SagnmCzxet3EHaUn7nCqy0vsvNZ+nc/qRqbrGU7Gy2k/dQR99jPw9nN5d5xBgZPteSGUMokyc1f+zP0ruHhWNTv2t53VadTY1M/m1vctSLf+BtLh70Yge5Ra6ztfGTeNRkTCeELmSVX9IYCqngy8vh5IedWbgaAtZJ5/jDzHR4Wq8vyek4NyZ45oHbOknXnSyjs6j6eT17LC2s08Rpe8Oa3Mpr3fwVV4wV02rDHEFzgpXAUE7mQzCUK4dhnRkI0biiJWEnZ8Ay76UN4xixFtU4x+Nnk/d5Zd+fo7Lufex19jz4kuPxrP2NRzke073rDtoNH+fIzWVxrGRdCI921tAH6jql8LHJ+tqsf9p38A/Np/vAl4SkS+hhcMcCHwCp5CcKGILMITMB8Dbi3WPC9vmM5lh7YQIsl06UyHNZ/RGtq1ioecm3nIuXnU1znd5zC9IsSZ3iRD7ZfsgCaT+eZYUpkXaaHPrsZCKA/buKq0xW1q2w/nXeQzBUQw72bN0jmD8lbyMRbO1EzHs2VZrL/j8rSQgYlnUy+VqTE4jqrSHUuYSgpDMFkCG84lxkujWQncDrwpIo3+sb8EbhGRZXhL6EHgPgBVfUtE/hnYjRexdr+qOgAi8gDwH4ANbFTVt4oxQRFBkjGWyFGmSq/v+HepIEal9FMvHVxjNRaswQSJCMR9YXG6NzmsLC9HQX1NxpKz2w8c1XpmuB2Ew5Wc6fXqqc0qd9DaBXm1ExFh7ax93LDzK8jPD7Fz6wyOVH6UNVfelBY6w931pv4xS5klnmnaGwjd9lS7iWRTL1XeRua4ACjMm1ZuIqqGYLIENpwrjFfU2TZVFVW9VFWX+T8/UdXbVfW3/eNrAtoNqvp3qrpYVd+lqs8Gjv9EVS/yX/u7Is6R/9x9jAhJBIcwSaK4CKkaZS5fCj3GNVbjECPlJhyysIPXHMY5gmcm08DzIN91biSsCRL93cSSDuXEqIkoz075w/x+i7efQ579M+bYHXRQRY17hnXd3+aeWfvSms1wfR75imAWk6dePuzl0rzQxKbXj7F66WxWXzqHeTXlJbWpZ445mmuUKm8j17ib3zjO8vk1BP/ajJAxlJpxjzo7V1FVdp9SiEKIgQz+4L9jnBD32VtGpNUI0JPILNk5/HPDtjC1PExr9+B+OamAgvvsLSywWmizZ/M/kzfz0z1zWb6gPHd5/R3fQK0IrXGbkO2ScMvA7Wfn019k0/S/Z83SucNakMYqSzy1kH7vl4eoLgtx8/K5oJ65bkZ1lHnTyktiUy+29lEqU2OucVdfOtv/Ix4YdyJpf4aJiRE0OVBV+gEUHLEIBeo4p1I1+4gwTwpLzkwhDE+DCWIJVJeF6OlPknD8mmkCCS/nksqITXfc4Xk/oCBqCzWRCBKHtp4Y8aQzqBlacIHU9kO0Jito96sL1FVF2XNcmeWepKUrzt0rFw7LhzBWztRUtNRLTW3s2N/Ghm0HqK+OMnNKGae6+ll96Zyi59KUKtChVKbGzHEnWnKuYfJg+tHkIGWySEgYF0kbzVK6jQLlxAtPzvTJpcuE8vyfq0J3f5KkQnnEZsUF01lYV4nlnxNLDu6dk3CVU90xWrvjlIVsft3cmdM8IzULCWssLWRau2NUWnFOWDPpTzise2JnuvbbUOHKuVpMFzuqKRUEMLU8TGd/kv0tPZzq6mfN0rnppm3FJJjMuun1Y6x5aHtRC1IGKYbZL3NcEWHX4XZWL509YZJzDZMDI2hykPqne8edS6tOJU4IAcQXNSFcFssxLrEO8lT4b0flqwmS6dwPov7rEVu4oK6SA219lIVtLqjzytakLHFVEYtF08tQIGJbzJgS5YFrFyMibNx+kNXf3Hb2ArniU9RElLqIQ2tXP309XdRElOUf+zyXL5xWcJ7KWDhTU6G5dVUDDdlauuKD8kSKTbGzxkuVt5Fr3KNn+gap0qXaBBgMQYygycGTLx8CPOd6khCntRonS1xYBX0slBOjDgxIkW1ZsTIuu2RGJa3dcRSvpH9Z2KK6LIQtYFueJhMNh6iKhKitjFBbGUVEuGvlQq+6gL8oDlogL/oQfPirSPVMyp0u7Cmzqb75H7HfdR3r77icFYtr03kqI9nFF9OBnjp/oKdOGUtmVDK1PExHXyItEEtBsbWPXKbG0WoZ+catKgtnTdY1GEqF6UeTBVXlvide5ae7Pf/LNVYjD4e/QSWxgff4vwWv1tlJreGQzuLWxF+XcObe9crCFklXqa2MYllQEbbp7EvQ0Z/wJyZEwxZ//DuLue+axf7OtpkZ1VFOdsbSC0s+YZHpb3Bdd1CeSiE9X0oVvvvkS4f4+Z5TaXPZPasa0ombd65oKLrPIV+gQzHMZ6XOoynmuIa8mBucgQkGyMElM8r5qV8D+reliYqAkIHBf0mW3yIgnO42UzxCFiT9zXllxKI/4XKls5M/Cm3hQqeNFpnFV05fz3aWMX9aORfNnMK2fa24qrzc1EZ1eTjtNA8uwJlOYMi9s02ZqIIMN1KplJUCbrtqIQj0xpxBVQJSOT+l8NGUKtChVKZGkw9iOBcwGk0ONj6/ly89u49rrEYeDX9lSImcquK8NvGZUSVx5iIsXgDBKmnkb8KPoVaYXo1SRgxbE3zRuYvtLGPlkjreu3Aaj24/SNJR7v/gEtZevYgnXzpEX8JN+y9SwqMi6mXyBBfroMZxy5XzR72LD2oCKYqZJDjWu3ajJRiGwPwxZGA0miyoKh29ngbzJXvjsIQMeH9dmR02r7Eauc/ewjwprB6a5Y+bGjvpJ2neF9pCUsJY4QrcmEOXRihHWWtt5tDUFZzo6OexXx6iJ5ZkxeI67lnVwNOvHKEv4VIWEu5/ahfL5k9FRKgI23T3JfhR4zG6+j1tLFOQAKPexZe6UsBY79qNlmAwFIYRNDmIx7xEyHlW25DvDebEpDpsPu8uG1SQs52B1szZWj1nkunK9mtmes3R3EroHyhZE5coC6SVsrDN/pZuQJhaHuGR271+ND2xJP+040Dal7PtnVYqozZV0RAnO/upiIT4rblT2PR6c9aEwdHWfjJl1w2G8xsTdZaDnUfaAdIlZ4bCEzYuddLBEssrIJ1qzdwXaM2cqiZQKJZAfVWYZgaao6WET4XEOUo975zqJuEoSdelrirMuid28tTLh7lnVQPvnjWF5vY++pIufQmHU10x9rX0AMLdqxpYf8cVBDX+TCEw0l28KbtuMBiMoMmCiHBpfRiA5KBqZLlRwPIX6oh67ZbnSQt9RAa9byTVBKqjIT7ze0tQhO8kbyRCknJigHo+GjfBBudGYkkXx1WiIYuTnXG272vl53tOoap+YmOEpOPiqOKqVwl6YW059159QVZnfzGEQL4w24qIfZavYzwpdgi2wWDwMKazLKgqJ09384D9Q2yc7O/hbI+f+Efj/m09qvUslBNMkd50i4FOreCQzipsPigbf3mY1u44zzNQyyzo93nBXZrOo+lPuPQn4jTUVlARsdiw7SC7fA0tnnQJrp+H2nq59/Ffcaorlq5nVuyyJNlMbxVRm95Y7pI4Y01mCHYqMbWqLJyef2ruBoOhMIygyYKI8E4LfMn+CUlsLJysN0p9g5lXMcCLOmvVKWlBssO9hPeG9uAiOFhESDBD2nnaubag+fTEHLpjAwLvcM1VfLLvMtr6Bjw5Ip56alkW08rCiMB75kyhO5bk0Rf305dQYkknXXlAgJBt4aryyoEzXLloWjoibShn/0iirjLf3xtzStYcrVAyQ7ArojZP/PIQZ3ri3LNqkSd0th1g1+F2rr6w3mTRGwwFYgRNFlSVqiRUWf24aFbjmVf/zCKEk/binNQaQjjUSDcvRD7FFHro0ErKJEGYJAnCdGgFK6zdBTVMCxpwrrEaua/L12bCnjbzoi7DVXAE1FFqq8II0B1z+M2JLhTBcZNeszTwNR8hGrK4YmENkZDN1RfWpxub5XP2FyP5slQVi0dKcD7PNDbT6teHKw/bKMqj2w6w0TctLp9fY8KZDYYCMT6aLIgIdQlIqEU40CIgiIUS8s1qCiSw6NBKRCBMknYqqZQY1dJLi05lr86nSWfTxpRh+WjmVZ/91aSi2OqlfVAU29V+7zhXIekqJztiJF1l97EOykMWZ3oT9CWUkCWIQMgWpldGuP93FnPtxTP49scv95IfM+5BJsPpnTJcP0exa4Zlu1YhPpagcK2rilJXFaEyGuIff7aPrz/3DgB3r2woSbHObHM1/iHDZMIImhwcAM8elQdFSGDjYvHN5M20U02HVqajzPrxAgrqpSN9znArPjd3nV2ra6gotoqIhS3Q1pvgQGsv75pZiW0Jjuu1FEi6iiqEbYu6qgiKsnVvC//jB6/n/5wB/8Taqxex+tLZWasXP/3KkUFBBPmqPBe7ZthTLx8e9rVzfcbUfFLCxn8FgLqqSMmEzGjnbjCc6xhBk4NmIEIi5+uCp9WEcXCwuMF6eVCUWRW92DhEcKikn3fLIZZIM1Olh+86Nw55/WzLba4otvnSggC9cRdH/WRPVV473MG+lp6z5KXrutRXR/n6z/axdW8LXf3xnEUoMxfB1Ic/3TPQcC2lmQy3U2SxQ55H26Uycz7P3L+CmVO8VgkJx0ubbe2Os/6FpqJrGqpKdywxaO7rX2wadYfNyYrR/CYmxkeTBVWli6GlsIsQI4SFcqHVzDvuXMoljo3DXGlDcNMCw8bFYXDEV6Ec1Xrqpd3XaDzKiXNE6wdVJ7Asr2VAIuZgCSyqreBUV4yeuIMq9CWUrXtbAaivjvLI7Zen/TOZ9yGzTtn6F5vS/oqUryKVfDlcv0uxa4aN1ueTms/qpbO5Z1UDj247wFvHuigP26xcUstlC6excdtBNm73PncxNZunXzkCCquXzvbn3kxLV5zlC2pMQmsGpSrOaig9RtBkYbj/3E463gwShECECEnqpd3rfukv/wm/GXQSm04qR9z++bvOjXwp9BjgaTLlxImQHKQheSYy/3PgOf5PdcX45LUX4rouD/9iP11+BJst8NKDH8S2s+cKnb2Ae4sgDPgrMkOhvVIzzen7kumHSTHaagO55jqqMjfqjVMVDbN8QQ2xRHJQlNmuw+2DSuyPtuZZSpBvfuO412IZpaUrTkdfguXza4Y/7/OAUhZnNZQeI2hGgdfe2UERTuo0qujjc8m7+G74636DNCWBjePrRmGSo2r//LybPYcml9CqjNokki6xpMvOQ2d46NZlfPPn+9Kvh0MW657Yyfo7sms0kLmAC7YlfOL9C9O7+qAmAvDHT+6kpStOfXUEENa/2ARKOh8lc+x8zwthNGVuggt+6jN19cfZ/PpxeuOeUF67yhsnNVYxo+9UlY3bD9LR55lqp5aHTVnGDM61SEVDYRhBMwoECOMQJ0SEJId0Fs+7y9jpXki9tDNLTqdbB1goCUKjav8MnrAZrjYkApGQjaqL4zhc/41t9CZdqiI2DXUV9CeU7ftbuffx13IKm8wFfHrlYB+RiKTzb9a/2MSuw15i6OpL54CQNrPdvbKhZLvOoI9l9aWzB2laqjqkqStzEXtsx0EcV7l7VUP6+IZtB6mI2Nx21cLA7torNVTI7jqbFoRAR1+CqeVh6qoirFk2h82vH0cYnZY32Sh1cVZD6TCCJguFdmeMkGSOnCakCV6IfIpuLWOq9NCpFdRJZ7q6QIdWn2XqKgYh8ao7Z9LV71AVsZhTU86RjhiHTvdSHrb5i+svoj8J/954lMpIiNbuWF4hk1pA71nVwP1P7fJ8FTKwy0/1f6mKhrl7VQMobH7jeNpRu3xBTckitmDAxzJvWnlaE0hpCruOtPP0K0eG1DIGFrFmHFc97cK/p4++eIDHdhzk4lnV3HLlfCzLSvf4eWzHwWHvrnNpQc+8fiwtZEQk7bMpRU+diYwpzjpxMYImC1u3bh3RefVWFwe1nLB4TvcOqghr0is/I2EO6axhtwkohJSQmVZuU1cVYV9LXzo4oDvucrwjhghMiYbo7E/wi7fbeOT2y3ipqY3T3XFuvDT7LjzotK+I2Dz64gGWzZ/KrsPt7DrczqMvHmDXkXaOnulLL7IpUmaouqoI37rtspIvBLdcOZ/uWGKQJoDA0TN96eitfHMYWMTEN/vBxu0DQuTiWdWc6upnw7aDrL16ERu2HeRkZz+Om2rmkF/7yBpY8UJTOsDgrpULWfeBxYM0s1uunF+s2zPhydfdFIxmc65jGp9loeHBHwNwIHprwWM7WBzWehxsWrSm5K2dwdvEL6otpzuWRMSiMmLR1NY36PUZ1RFUlelVZX7iprejvmnZ3EH/pNlMO6kmaakFUFH+afuhtLnn7lUN3Hv1BYN26bmanJWyadhIG6xlW8TWv9jE1597J61pbHpgZfoepM6ZOaWMU139pNSooa6VbX7zppV7Gl/G/TORVGczgaLOjMTLwGg0Ofhq6OGCz/EqOLvMlTaadfqInf6FEgkJf3jFfF4/2smBth4slMqwRW/SBb9hWk/MwVFl7dVz0wtdZqRXtsKSKbNYyhSVMomlhEx9dSSrkMm266yI2PTGs3fyLMZCMRobfjDcWtW7aVPLw9i+UN6w7SD3rGpI+31au+OIUFAh0mzz+9Ztl6VfC77H7M7PptiRioaxwwiaHHzE3l7wOYLXsEyBWdJOo7uk2NM6i5nVEX5r7lS2vHmCNUvnsGLxdLbubeF0b4JYd5ykr7H2JhzqqyK81DS4kVvKxg2cVVjy5785xcnOfm5aNjfttG7rjuH6SnAqsixoJ8+VH5Oq1lzK8NSR2PCDwjU1xr2Pv8aeE12DQrifaWz27503T9sSZlSXDbsQ6VDzC2IWztwUM1LRMHZMCkEjItcD3wBs4FFV/fvRjjm8LjT4V8E+AAAMNUlEQVS5CZfA6Z+NO1csZEpFlN6YQ0XEpieWZPfxTkD4wIV1PP92i6dpiVAVDbFjfxsrl9Sx/o7LB5mCggmXXmFJL59jxeLadBLjxm0H6YklSTguNRWRdGRZcIx8u86UmbYU4akjseFn85ts2HaQPSe6uHhWdfqclON/z4ku7lzRkB77mcbmtM9mqN218TEYzmcmvKARERt4GPgQcBR4VUQ2qeru8ZiPBbhYNOmcojv9s/HKgdNsuPPKdI7HUy8fZvmCaSyfX8POw2eory5DVelLOJSFQ6xYXMu1756BZVlZd+Ep005dlecQP9XVz00Pb08naqYy5VORZasvnX1WhFSuXWcpw1NHUm0gV27GnSsauGdVQzoSz7Isrn33DK66oDbv2EOFUBezGoLBMJGY8MEAIvJ+4Auqep3//LMAqvq/cp0znGCAQgMBNP1bOKr1fD55Z0kFTW1FiJBtE7Kt9C47tVilmnZtfuM4q5fOZu2qRQPP/TyTbM7/TGd1yhdRXx3hdE8inaiZIuVfueXK+cNaKEfqrC+EkQQbqCprHhowlW56YGXWc4oRyFDKYAjDOYP5QjOY8BoNMBc4Enh+FHhf5ptEZB2wDmDBguJGqAwEuEISKbmQsQT6ky6f/MAFWGKdtSO2LIuqsvCgRTwlXDLfm03IpHJm7n38Nfa39AC+P0YGn1OIgBgr01GhNvxC/DrF8A8YH4PhfGQyCJphoaqPAI+Ap9EUe/xeytJtmkcrZMIC86eX09zRTzyQiTm9Mux1xXSVM70J/r3xOD/+5MqstcoKjdAJmnbuWdXAhm0HOdXV75naLp5Bb9xz5Aez1QtZJM9F05HxmxgMY8NkEDTNQDCzbZ5/bFT0uRbl1tAVAlzgkM7A8cvQjCYAoK4yzOULa2g80klP3KWhtpKG2nLKwiG6YknW3+458CuiNlv3nKK6LJKzICYUvnsOCidPKMxN+ypSJtbRCIVzLTz1XBR+BsNkZDL4aELA28Dv4gmYV4FbVfWtXOcM5aMBz0+zO/zxvMKmQys4prVUSf+QBS7DArYFc6ZG+cSKBj7+/kWs/d6r7D7eSW1llJuWz2XtqkVYlsX6F5rYdaSdVUvquPV9C9I5LakFP/i8lJwv/oTz5XMaxgzzx5PBhBc0ACJyA/CPeFHJG1X17/K9fziCBgYqBAAsBA4FXqsB/vQ9cMkls5gxYwYVFRVYlkU0GsW2bSzLSof0WpaFZVm4rouIpAVE6nngcwCDO1oaDIYJh/nHzWBSCJpCGa6gMRgMhhFgBE0GppWzwWAwGEqKETQGg8FgKClG0BgMBoOhpBhBYzAYDIaSYgSNwWAwGEqKETQGg8FgKClG0BgMBoOhpBhBYzAYDIaScl4mbIpIC4MT/YeiDmgt0XRGipnT8DBzGh5mTsNjOHNqVdXrx2IyE4XzUtAUioj8SlWvGO95BDFzGh5mTsPDzGl4nItzmggY05nBYDAYSooRNAaDwWAoKUbQDI9HxnsCWTBzGh5mTsPDzGl4nItzOucxPhqDwWAwlBSj0RgMBoOhpBhBYzAYDIaSYgTNEIjI9SKyV0T2iciDJbzOfBHZKiK7ReQtEfmUf/wLItIsIo3+zw2Bcz7rz2uviFxXqjmLyEERedO//q/8Y9NF5DkRecf/Pc0/LiLyf/xrvyEilwXG+YT//ndE5BMjnMu7AveiUUQ6ReTT43GfRGSjiJwSkV8HjhXtvojI5f593+efO2RDrRxz+t8isse/7o9EpMY/3iAifYF79p2hrp3r841gTkX7vkRkkYi87B//gYhERjinHwTmc1BEGsfyPk1qVNX85PjBaw29H7gAiACvA5eU6Fqzgcv8x9XA28AlwBeAz2R5/yX+fKLAIn+edinmDBwE6jKOfQV40H/8IPBl//ENwLN4XQavAl72j08Hmvzf0/zH04rw/ZzA67Q95vcJ+ABwGfDrUtwX4BX/veKf++ERzun3gZD/+MuBOTUE35cxTtZr5/p8I5hT0b4v4J+Bj/mPvwP8t5HMKeP1fwA+P5b3aTL/GI0mP1cC+1S1SVXjwPeBm0pxIVU9rqo7/cddwG+AuXlOuQn4vqrGVPUAsM+f71jN+Sbge/7j7wEfCRx/XD1eAmpEZDZwHfCcqp5W1TPAc8Bos6d/F9ivqvmqPJTsPqnqC8DpLNcb9X3xX5uiqi+pt1o9HhiroDmp6k9VNek/fQmYl2+MIa6d6/MVNKc8FPR9+RrEtcC/FmtO/ph/CDydb4xi36fJjBE0+ZkLHAk8P0r+xb8oiEgDsBx42T/0gG/22BhQwXPNrRRzVuCnIvKaiKzzj81U1eP+4xPAzHGY18cYvBiM932C4t2Xuf7jYs/vbrydd4pFIrJLRJ4XkasDc8117VyfbyQU4/uqBdoDgrQY9+lq4KSqvhM4Np73acJjBM05hohUAf8GfFpVO4FvA4uBZcBxPJV+rFmlqpcBHwbuF5EPBF/0d3NjGifv2+HXAP/iHzoX7tMgxuO+5ENE/gpIAk/6h44DC1R1OfAnwFMiMmW4443y851z31eAWxi8gRnP+zQpMIImP83A/MDzef6xkiAiYTwh86Sq/hBAVU+qqqOqLrAez4SQb25Fn7OqNvu/TwE/8udw0jcdpEwIp8Z4Xh8GdqrqSX9u436ffIp1X5oZbOIa1fxE5E7gRuA2f+HDN0+1+Y9fw/OBXDTEtXN9voIo4vfVhmeGDGWZa8H449wM/CAw13G7T5MFI2jy8ypwoR/VEsEz1WwqxYV8u/AG4Deq+rXA8dmBt/0BkIqS2QR8TESiIrIIuBDPMVnUOYtIpYhUpx7jOZZ/7Y+ZipD6BPBMYF53iMdVQIdvQvgP4PdFZJpvJvl9/9hIGbTrHO/7FKAo98V/rVNErvL/Nu4IjFUQInI98OfAGlXtDRyvFxHbf3wB3r1pGuLauT5foXMqyvflC82twEdHOyef3wP2qGraJDae92nSMN7RCOf6D1600Nt4u5i/KuF1VuGp128Ajf7PDcATwJv+8U3A7MA5f+XPay+BiKRizhkvyud1/+et1Hh4tvH/BN4BfgZM948L8LB/7TeBKwJj3Y3n3N0H3DWKOVXi7WSnBo6N+X3CE3THgQSeff6eYt4X4Aq8BXg/8BB+JY8RzGkfnn8j9Xf1Hf+9/8X/ThuBncDqoa6d6/ONYE5F+778v9FX/M/5L0B0JHPyjz8G/FHGe8fkPk3mH1OCxmAwGAwlxZjODAaDwVBSjKAxGAwGQ0kxgsZgMBgMJcUIGoPBYDCUFCNoDAaDwVBSjKAxGAwGQ0kxgsZgyIKI3CkiD433PAyGyYARNAbDGBIolWIwnDeYP3rDhEZEPgd8HGjBy35/DegA1uH1LdkH3K6qvSLyGNCPl809BfgTVd2SZ/g5IvL/8Io//khV/9y/5i3AX+Jl+/9YVf/CP96tqlX+448CN6rqnYHrLge2i8gzwDf8ayjwAfVaQxgMkxIjaAwTFhF5L155kKVAGK88yGvAD1V1vf+ev8UrefJN/7QGvAKOi4GtIrJEVftzXGIZnnCIAXtF5JuAg9c87HLgDF77hI+o6r8PMd15wApVdURkM3C/qm73q3Xnur7BMCkwpjPDRGYl8Iyq9vsawWb/+G+JyIsi8iZwG/CewDn/rKquer1GmoCL84z/n6ra4Qui3XidPN8L/EJVW9TrgfIkXrfGofgXVXX8x9uBr4nIfwdqdKCXisEwKTGCxjAZeQx4QFV/G/giUBZ4LbO4X75if7HAY4ehLQDBscoyXutJv0n174G1QDmeKS2fsDMYJjxG0BgmMtuB1SJS5pugbvSPVwPH/f4+t2Wc819FxBKRxXhVf/cWeM1XgGtEpM4vHX8L8Lz/2kkRebeIWHil77MiIotV9U1V/TJe+XsjaAyTGuOjMUxYVPVVEdmEV2r+JF7Z+Q7gc3htsFv839WB0w7jCYspeOXgC/KPqOpxEXkQrwdKKhgg1WvkQWCLf91fAVU5hvm0iHwQcPHKzz+b430Gw6TAtAkwTGhEpEpVu0WkAngBWKeqO3O89zFgi6r+61jO0WA43zEajWGi84iIXILnE/leLiFjMBjGD6PRGM5rROQ6vHDlIAdUNaePxWAwFIYRNAaDwWAoKSbqzGAwGAwlxQgag8FgMJQUI2gMBoPBUFKMoDEYDAZDSfn/w0e5Af/SCQ8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_names = df[df['gap_hours'] >= 5000].index\n",
        "df.drop(index_names, inplace = True)\n",
        "\n",
        "index_names = df[df['spherical_distances'] >= 7000].index\n",
        "df.drop(index_names, inplace = True)"
      ],
      "metadata": {
        "id": "_lPooqKfCSqZ"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.lmplot(x='gap_hours', y='spherical_distances', hue='iuu_caught', \n",
        "           markers=['x', 'o'],\n",
        "           fit_reg=False, data=df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OhSSdRauCqaU",
        "outputId": "75c5f273-eb03-49c9-bcd1-1a0bb882ced8"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f822bfdcb50>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 423.25x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# run correlation matrix and plot\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool),\n",
        "            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
        "            square=True, ax=ax)\n",
        "\n",
        "\n",
        "matrix = df.corr()\n",
        "print(\"Correlation matrix is : \")\n",
        "print(matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xWst-loT9bUO",
        "outputId": "6a628583-4a99-4061-ea5e-ff5d664ad091"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-131-d755c1f20fae>:9: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation matrix is : \n",
            "                     gap_hours  iuu_caught  spherical_distances  eez_check  \\\n",
            "gap_hours             1.000000    0.026771             0.432375   0.036147   \n",
            "iuu_caught            0.026771    1.000000             0.021905  -0.013338   \n",
            "spherical_distances   0.432375    0.021905             1.000000   0.065051   \n",
            "eez_check             0.036147   -0.013338             0.065051   1.000000   \n",
            "speed                -0.124339   -0.003477             0.357743   0.083598   \n",
            "\n",
            "                        speed  \n",
            "gap_hours           -0.124339  \n",
            "iuu_caught          -0.003477  \n",
            "spherical_distances  0.357743  \n",
            "eez_check            0.083598  \n",
            "speed                1.000000  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding\n"
      ],
      "metadata": {
        "id": "vbqkc3pmydxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['gear type'].unique())\n",
        "print(df['exact _name new from diff Oceans'].unique())\n",
        "print(df['ais_disable_time_division'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyMFweZYi5-T",
        "outputId": "5236baf7-2531-4d94-91ca-2010470cd1de"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pole_and_line' 'fishing' 'set_longlines' 'fixed_gear' 'set_gillnets'\n",
            " 'pots_and_traps' 'seiners' 'other_purse_seines' 'purse_seines' 'trollers'\n",
            " 'dredge_fishing' 'drifting_longlines' 'other' 'trawlers' 'other_seines'\n",
            " 'squid_jigger' 'tuna_purse_seines']\n",
            "['North Atlantic Ocean' 'South Atlantic Ocean' 'Celtic Sea'\n",
            " 'Southern Ocean' 'Mediterranean Sea - Eastern Basin' 'Norwegian Sea'\n",
            " 'Barentsz Sea' 'Sea of Okhotsk' 'Japan Sea' 'Bering Sea' 'Gulf of Alaska'\n",
            " 'Labrador Sea' 'Davis Strait' 'North Pacific Ocean' 'South Pacific Ocean'\n",
            " 'Arafura Sea' 'Arabian Sea' 'Indian Ocean' 'Tasman Sea' 'Bismarck Sea'\n",
            " 'Gulf of Guinea' 'Coral Sea' 'Bay of Bengal' 'Great Australian Bight'\n",
            " 'Mozambique Channel' 'Caribbean Sea' 'Philippine Sea' 'Timor Sea'\n",
            " 'Greenland Sea' 'North Sea' 'Laccadive Sea' 'Bass Strait'\n",
            " 'Gulf of St. Lawrence' 'Baffin Bay' 'Gulf of Mexico' 'Solomon Sea']\n",
            "['Morning' 'Dawn' 'Afternoon' 'Night' 'Twilight' 'Evening']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['gear type'].value_counts())\n",
        "print(df['exact _name new from diff Oceans'].value_counts())\n",
        "print(df['ais_disable_time_division'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMZkweLBkgix",
        "outputId": "6475c4f5-324a-4666-8974-85eb33dfe20e"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drifting_longlines    18602\n",
            "squid_jigger          15450\n",
            "tuna_purse_seines      8596\n",
            "trawlers               7887\n",
            "fishing                1906\n",
            "set_longlines          1317\n",
            "pole_and_line           597\n",
            "pots_and_traps          386\n",
            "fixed_gear              180\n",
            "set_gillnets             81\n",
            "purse_seines             75\n",
            "trollers                 72\n",
            "other                    34\n",
            "other_purse_seines       30\n",
            "dredge_fishing           24\n",
            "seiners                   2\n",
            "other_seines              2\n",
            "Name: gear type, dtype: int64\n",
            "North Pacific Ocean                  16068\n",
            "South Pacific Ocean                  13352\n",
            "South Atlantic Ocean                 11070\n",
            "Indian Ocean                          5737\n",
            "North Atlantic Ocean                  4741\n",
            "Bering Sea                            1169\n",
            "Coral Sea                              398\n",
            "Sea of Okhotsk                         374\n",
            "Barentsz Sea                           331\n",
            "Gulf of Guinea                         287\n",
            "Celtic Sea                             276\n",
            "Arabian Sea                            225\n",
            "Philippine Sea                         208\n",
            "Tasman Sea                             146\n",
            "Solomon Sea                            120\n",
            "Norwegian Sea                          119\n",
            "Southern Ocean                         114\n",
            "Gulf of Alaska                          95\n",
            "Great Australian Bight                  79\n",
            "Mozambique Channel                      78\n",
            "Japan Sea                               55\n",
            "Bismarck Sea                            48\n",
            "Davis Strait                            40\n",
            "Labrador Sea                            27\n",
            "Arafura Sea                             20\n",
            "Caribbean Sea                           16\n",
            "Timor Sea                               15\n",
            "Mediterranean Sea - Eastern Basin       11\n",
            "Greenland Sea                            8\n",
            "North Sea                                5\n",
            "Bass Strait                              3\n",
            "Gulf of Mexico                           2\n",
            "Bay of Bengal                            1\n",
            "Laccadive Sea                            1\n",
            "Gulf of St. Lawrence                     1\n",
            "Baffin Bay                               1\n",
            "Name: exact _name new from diff Oceans, dtype: int64\n",
            "Dawn         12123\n",
            "Twilight     10956\n",
            "Night         8855\n",
            "Evening       8689\n",
            "Morning       7568\n",
            "Afternoon     7050\n",
            "Name: ais_disable_time_division, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoded_data = pd.get_dummies(df, columns = ['gear type', 'exact _name new from diff Oceans','ais_disable_time_division'])\n",
        "print(one_hot_encoded_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-65OpmWAkvdY",
        "outputId": "800ea32b-51f2-4a62-a809-c92cc3f9c11c"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   gap_hours  iuu_caught  spherical_distances  eez_check      speed  \\\n",
            "0  13.016667           0           207.942845          0  15.975123   \n",
            "1  13.850000           0             9.704232          0   0.700667   \n",
            "2  33.733333           0            10.789069          1   0.319834   \n",
            "3  30.650000           0            11.695860          1   0.381594   \n",
            "4  50.283333           0            93.113335          1   1.851773   \n",
            "\n",
            "   gear type_dredge_fishing  gear type_drifting_longlines  gear type_fishing  \\\n",
            "0                         0                             0                  0   \n",
            "1                         0                             0                  1   \n",
            "2                         0                             0                  0   \n",
            "3                         0                             0                  0   \n",
            "4                         0                             0                  0   \n",
            "\n",
            "   gear type_fixed_gear  gear type_other  ...  \\\n",
            "0                     0                0  ...   \n",
            "1                     0                0  ...   \n",
            "2                     0                0  ...   \n",
            "3                     0                0  ...   \n",
            "4                     0                0  ...   \n",
            "\n",
            "   exact _name new from diff Oceans_South Pacific Ocean  \\\n",
            "0                                                  0      \n",
            "1                                                  0      \n",
            "2                                                  0      \n",
            "3                                                  0      \n",
            "4                                                  0      \n",
            "\n",
            "   exact _name new from diff Oceans_Southern Ocean  \\\n",
            "0                                                0   \n",
            "1                                                0   \n",
            "2                                                0   \n",
            "3                                                0   \n",
            "4                                                0   \n",
            "\n",
            "   exact _name new from diff Oceans_Tasman Sea  \\\n",
            "0                                            0   \n",
            "1                                            0   \n",
            "2                                            0   \n",
            "3                                            0   \n",
            "4                                            0   \n",
            "\n",
            "   exact _name new from diff Oceans_Timor Sea  \\\n",
            "0                                           0   \n",
            "1                                           0   \n",
            "2                                           0   \n",
            "3                                           0   \n",
            "4                                           0   \n",
            "\n",
            "   ais_disable_time_division_Afternoon  ais_disable_time_division_Dawn  \\\n",
            "0                                    0                               0   \n",
            "1                                    0                               1   \n",
            "2                                    0                               1   \n",
            "3                                    1                               0   \n",
            "4                                    1                               0   \n",
            "\n",
            "   ais_disable_time_division_Evening  ais_disable_time_division_Morning  \\\n",
            "0                                  0                                  1   \n",
            "1                                  0                                  0   \n",
            "2                                  0                                  0   \n",
            "3                                  0                                  0   \n",
            "4                                  0                                  0   \n",
            "\n",
            "   ais_disable_time_division_Night  ais_disable_time_division_Twilight  \n",
            "0                                0                                   0  \n",
            "1                                0                                   0  \n",
            "2                                0                                   0  \n",
            "3                                0                                   0  \n",
            "4                                0                                   0  \n",
            "\n",
            "[5 rows x 64 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.lmplot(x='gap_hours', y='exact _name new from diff Oceans_South Atlantic Ocean', hue='iuu_caught', \n",
        "           markers=['x', 'o'],\n",
        "           fit_reg=False, data=one_hot_encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GzxkG9jM11UG",
        "outputId": "183afec5-b726-44be-85a9-459453b79071"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f822c038d30>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 423.25x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Train Split after One Hot Encoding"
      ],
      "metadata": {
        "id": "EC73sw2Xywmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Independent and Dependent Features\n",
        "X=one_hot_encoded_data.drop(\"iuu_caught\",axis=1)\n",
        "y=one_hot_encoded_data.iuu_caught"
      ],
      "metadata": {
        "id": "pMpzCAHKlyKv"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=15, stratify=y)"
      ],
      "metadata": {
        "id": "B0ezzV76WDHT"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVfhw2PdWIa9",
        "outputId": "a8cb083f-9e48-4056-930a-039117426027"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    33001\n",
              "1      143\n",
              "Name: iuu_caught, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normal ANN"
      ],
      "metadata": {
        "id": "UgjboMmxy12d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X.columns))\n",
        "n_inputs=len(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdsdny-FWiPD",
        "outputId": "75c5e7f8-4b7b-43a0-bfbd-a6d5013964cf"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "# define model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_normal = keras.Sequential([\n",
        "        keras.layers.Dense(50, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'),\n",
        "        keras.layers.Dense(15, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "# model = Sequential()\n",
        "# # define first hidden layer and visible layer\n",
        "# model.add(Dense(50, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "# # define output layer\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# define loss and optimizer\n",
        "model_normal.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "model_normal.fit(X_train,y_train,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9CEcXWhWkr4",
        "outputId": "80fdf4ac-3c93-444a-f3d0-4a884deeda01"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 0.1719\n",
            "Epoch 2/10\n",
            "1036/1036 [==============================] - 1s 1ms/step - loss: 0.0723\n",
            "Epoch 3/10\n",
            "1036/1036 [==============================] - 1s 1ms/step - loss: 0.1101\n",
            "Epoch 4/10\n",
            "1036/1036 [==============================] - 1s 1ms/step - loss: 0.0857\n",
            "Epoch 5/10\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 0.0487\n",
            "Epoch 6/10\n",
            "1036/1036 [==============================] - 1s 1ms/step - loss: 0.0534\n",
            "Epoch 7/10\n",
            "1036/1036 [==============================] - 1s 1ms/step - loss: 0.0431\n",
            "Epoch 8/10\n",
            "1036/1036 [==============================] - 1s 1ms/step - loss: 0.0487\n",
            "Epoch 9/10\n",
            "1036/1036 [==============================] - 1s 1ms/step - loss: 0.0424\n",
            "Epoch 10/10\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 0.0379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f822745d910>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_pred1=model_normal.predict(X_test)\n",
        "\n",
        "print(roc_auc_score(y_test,y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYVyaTSFWr75",
        "outputId": "360c2c1f-ce12-4525-f8e6-eb686774a309"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "691/691 [==============================] - 1s 860us/step\n",
            "0.688177052558217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKJUvxklcE9d",
        "outputId": "79182120-b387-4023-93bb-a6be1cddb3f4"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.2062335e-03],\n",
              "       [6.4238920e-10],\n",
              "       [8.9180795e-04],\n",
              "       ...,\n",
              "       [1.4182478e-03],\n",
              "       [7.7149216e-06],\n",
              "       [1.0941484e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Compute false positive rate (FPR) and true positive rate (TPR)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
        "\n",
        "# Compute the area under the curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Find the index of the threshold that minimizes the Euclidean distance from (0,1)\n",
        "idx = np.argmin((1-tpr)**2 + fpr**2)\n",
        "\n",
        "# Retrieve the optimal threshold\n",
        "optimal_threshold = thresholds[idx]\n",
        "\n",
        "print(optimal_threshold)"
      ],
      "metadata": {
        "id": "ensosqWs5fYh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e087bac6-e4ab-4610-a887-4f0cfc1e2a3f"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0014454914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred1_rounded = np.where(y_pred1 > 0.0024554702, 1, 0)\n",
        "print(classification_report(y_test, y_pred1_rounded))\n",
        "\n",
        "# Print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred1_rounded)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "KtHrme5y5iv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561230ec-6b33-4a7a-d350-2585d837e98f"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.79      0.88     22001\n",
            "           1       0.01      0.57      0.02        96\n",
            "\n",
            "    accuracy                           0.79     22097\n",
            "   macro avg       0.50      0.68      0.45     22097\n",
            "weighted avg       0.99      0.79      0.88     22097\n",
            "\n",
            "[[17403  4598]\n",
            " [   41    55]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cost Sensitive Learning "
      ],
      "metadata": {
        "id": "v6R_6hPIXQSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights_assigned={0:1,1:550}"
      ],
      "metadata": {
        "id": "tujfYHLBXQoo"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "# define model\n",
        "model = Sequential()\n",
        "# define first hidden layer and visible layer\n",
        "model.add(Dense(n_inputs, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(30, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(10, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "# define output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# define loss and optimizer\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "model.fit(X_train,y_train,class_weight=weights_assigned,epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jbHM0lmXVWJ",
        "outputId": "9c6f1690-283d-484f-b64f-2f33d52ad739"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 17.6140\n",
            "Epoch 2/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 8.6265\n",
            "Epoch 3/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 3.6106\n",
            "Epoch 4/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.6801\n",
            "Epoch 5/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2593\n",
            "Epoch 6/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9944\n",
            "Epoch 7/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9011\n",
            "Epoch 8/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8379\n",
            "Epoch 9/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8129\n",
            "Epoch 10/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7982\n",
            "Epoch 11/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0488\n",
            "Epoch 12/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8424\n",
            "Epoch 13/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.6234\n",
            "Epoch 14/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7843\n",
            "Epoch 15/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7150\n",
            "Epoch 16/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7575\n",
            "Epoch 17/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7281\n",
            "Epoch 18/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0683\n",
            "Epoch 19/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.4315\n",
            "Epoch 20/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6528\n",
            "Epoch 21/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6429\n",
            "Epoch 22/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5842\n",
            "Epoch 23/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7787\n",
            "Epoch 24/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8425\n",
            "Epoch 25/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.3955\n",
            "Epoch 26/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6671\n",
            "Epoch 27/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5383\n",
            "Epoch 28/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6814\n",
            "Epoch 29/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5445\n",
            "Epoch 30/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5429\n",
            "Epoch 31/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5435\n",
            "Epoch 32/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4989\n",
            "Epoch 33/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2795\n",
            "Epoch 34/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4360\n",
            "Epoch 35/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5524\n",
            "Epoch 36/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8142\n",
            "Epoch 37/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5011\n",
            "Epoch 38/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4769\n",
            "Epoch 39/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5896\n",
            "Epoch 40/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5935\n",
            "Epoch 41/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7405\n",
            "Epoch 42/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6490\n",
            "Epoch 43/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5912\n",
            "Epoch 44/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5602\n",
            "Epoch 45/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6876\n",
            "Epoch 46/50\n",
            "1036/1036 [==============================] - 3s 3ms/step - loss: 1.5249\n",
            "Epoch 47/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8422\n",
            "Epoch 48/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5542\n",
            "Epoch 49/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5622\n",
            "Epoch 50/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6239\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8226b09370>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI-IHreEXWv-",
        "outputId": "3d9980e7-101f-4800-f555-5841808e0edb"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "691/691 [==============================] - 1s 904us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KyJn6YpIb48",
        "outputId": "bb6937e3-991f-4230-e017-2970bb5b5ef7"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48516023"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBJS-_LjXXfA",
        "outputId": "56b1bb13-e041-4647-b034-ab5d53fdcb3a"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7809114737208914"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Compute false positive rate (FPR) and true positive rate (TPR)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "# Compute the area under the curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Find the index of the threshold that minimizes the Euclidean distance from (0,1)\n",
        "idx = np.argmin((1-tpr)**2 + fpr**2)\n",
        "\n",
        "# Retrieve the optimal threshold\n",
        "optimal_threshold = thresholds[idx]\n",
        "\n",
        "print(optimal_threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "dOvoQpgNwx0N",
        "outputId": "ddd80d51-3efa-44c2-bb0e-a1df22c5d389"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7110104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rounded = np.where(y_pred > optimal_threshold, 1, 0)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_rounded))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_rounded)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oIOA7NOFeMQ",
        "outputId": "11c77d5a-c8c7-400a-beab-7120a46d4b83"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.77      0.87     22001\n",
            "           1       0.01      0.70      0.03        96\n",
            "\n",
            "    accuracy                           0.77     22097\n",
            "   macro avg       0.51      0.73      0.45     22097\n",
            "weighted avg       0.99      0.77      0.86     22097\n",
            "\n",
            "[[16896  5105]\n",
            " [   29    67]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "results = []\n",
        "seeds = [0, 42, 123, 456, 789, 1024]\n",
        "\n",
        "for seed in seeds:\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    \n",
        "    model_test = Sequential()\n",
        "    # define first hidden layer and visible layer\n",
        "    model_test.add(Dense(n_inputs, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model_test.add(Dense(30, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model_test.add(Dense(10, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "    # define output layer\n",
        "    model_test.add(Dense(1, activation='sigmoid'))\n",
        "    # define loss and optimizer\n",
        "    model_test.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    model_test.fit(X_train,y_train,class_weight=weights_assigned,epochs=50)\n",
        "    \n",
        "    # Make predictions on the validation set\n",
        "    y_pred_temp=model_test.predict(X_test)\n",
        "    \n",
        "    # # Calculate the ROC AUC score\n",
        "    # fpr, tpr, thresholds = roc_curve(y_test, y_pred_temp)\n",
        "\n",
        "    # # Compute the area under the curve (AUC)\n",
        "    # roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # # Find the index of the threshold that minimizes the Euclidean distance from (0,1)\n",
        "    # idx = np.argmin((1-tpr)**2 + fpr**2)\n",
        "\n",
        "    # # Retrieve the optimal threshold\n",
        "    # optimal_threshold1 = thresholds[idx]\n",
        "\n",
        "    # y_pred_rounded_test = np.where(y_pred_temp > optimal_threshold1, 1, 0)\n",
        "\n",
        "    score = roc_auc_score(y_test, y_pred_temp)\n",
        "    print(score)\n",
        "    results.append(score)\n",
        "\n",
        "# Find the seed that results in the highest ROC AUC score\n",
        "best_seed = seeds[np.argmax(results)]\n",
        "print(\"Best seed:\", best_seed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtkstl-hCh7I",
        "outputId": "86245663-741a-475f-9762-2474fecd89b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 17.3610\n",
            "Epoch 2/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 8.4860\n",
            "Epoch 3/50\n",
            "1036/1036 [==============================] - 3s 3ms/step - loss: 2.2644\n",
            "Epoch 4/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.7406\n",
            "Epoch 5/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 4.9643\n",
            "Epoch 6/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0746\n",
            "Epoch 7/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0606\n",
            "Epoch 8/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0537\n",
            "Epoch 9/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0502\n",
            "Epoch 10/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0478\n",
            "Epoch 11/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0466\n",
            "Epoch 12/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0464\n",
            "Epoch 13/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0460\n",
            "Epoch 14/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0460\n",
            "Epoch 15/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0460\n",
            "Epoch 16/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0461\n",
            "Epoch 17/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0457\n",
            "Epoch 18/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0458\n",
            "Epoch 19/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0462\n",
            "Epoch 20/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0460\n",
            "Epoch 21/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0461\n",
            "Epoch 22/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0458\n",
            "Epoch 23/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0458\n",
            "Epoch 24/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 25/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0460\n",
            "Epoch 26/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0458\n",
            "Epoch 27/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0460\n",
            "Epoch 28/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0458\n",
            "Epoch 29/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0458\n",
            "Epoch 30/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 31/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 32/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 33/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 34/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 35/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 36/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0458\n",
            "Epoch 37/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 38/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 39/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 40/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0458\n",
            "Epoch 41/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 42/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0457\n",
            "Epoch 43/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0460\n",
            "Epoch 44/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0461\n",
            "Epoch 45/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0456\n",
            "Epoch 46/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 47/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0458\n",
            "Epoch 48/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0459\n",
            "Epoch 49/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0460\n",
            "Epoch 50/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0460\n",
            "691/691 [==============================] - 1s 1ms/step\n",
            "0.5\n",
            "Epoch 1/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 17.6140\n",
            "Epoch 2/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 8.6265\n",
            "Epoch 3/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 3.6106\n",
            "Epoch 4/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.6801\n",
            "Epoch 5/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2593\n",
            "Epoch 6/50\n",
            "1036/1036 [==============================] - 3s 3ms/step - loss: 1.9944\n",
            "Epoch 7/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9011\n",
            "Epoch 8/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8379\n",
            "Epoch 9/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8129\n",
            "Epoch 10/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7982\n",
            "Epoch 11/50\n",
            "1036/1036 [==============================] - 3s 3ms/step - loss: 2.0488\n",
            "Epoch 12/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8424\n",
            "Epoch 13/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.6234\n",
            "Epoch 14/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7843\n",
            "Epoch 15/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7150\n",
            "Epoch 16/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7575\n",
            "Epoch 17/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7281\n",
            "Epoch 18/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0683\n",
            "Epoch 19/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.4315\n",
            "Epoch 20/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6528\n",
            "Epoch 21/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6429\n",
            "Epoch 22/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5842\n",
            "Epoch 23/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7787\n",
            "Epoch 24/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8425\n",
            "Epoch 25/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.3955\n",
            "Epoch 26/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6671\n",
            "Epoch 27/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5383\n",
            "Epoch 28/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6814\n",
            "Epoch 29/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5445\n",
            "Epoch 30/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5429\n",
            "Epoch 31/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5435\n",
            "Epoch 32/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4989\n",
            "Epoch 33/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2795\n",
            "Epoch 34/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4360\n",
            "Epoch 35/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5524\n",
            "Epoch 36/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8142\n",
            "Epoch 37/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5011\n",
            "Epoch 38/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4769\n",
            "Epoch 39/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5896\n",
            "Epoch 40/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5935\n",
            "Epoch 41/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7405\n",
            "Epoch 42/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6490\n",
            "Epoch 43/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5912\n",
            "Epoch 44/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5602\n",
            "Epoch 45/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6876\n",
            "Epoch 46/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5249\n",
            "Epoch 47/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8422\n",
            "Epoch 48/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5542\n",
            "Epoch 49/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5622\n",
            "Epoch 50/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6239\n",
            "691/691 [==============================] - 1s 946us/step\n",
            "0.7809114737208914\n",
            "Epoch 1/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 15.0965\n",
            "Epoch 2/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2585\n",
            "Epoch 3/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2116\n",
            "Epoch 4/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2444\n",
            "Epoch 5/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.3456\n",
            "Epoch 6/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 3.1156\n",
            "Epoch 7/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0202\n",
            "Epoch 8/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9163\n",
            "Epoch 9/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.4694\n",
            "Epoch 10/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8832\n",
            "Epoch 11/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8539\n",
            "Epoch 12/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9064\n",
            "Epoch 13/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8611\n",
            "Epoch 14/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.8370\n",
            "Epoch 15/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8533\n",
            "Epoch 16/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8096\n",
            "Epoch 17/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8231\n",
            "Epoch 18/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7245\n",
            "Epoch 19/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9288\n",
            "Epoch 20/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7134\n",
            "Epoch 21/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 3.8274\n",
            "Epoch 22/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 3.4916\n",
            "Epoch 23/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2476\n",
            "Epoch 24/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0606\n",
            "Epoch 25/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7029\n",
            "Epoch 26/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7178\n",
            "Epoch 27/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7829\n",
            "Epoch 28/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7898\n",
            "Epoch 29/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8475\n",
            "Epoch 30/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0056\n",
            "Epoch 31/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7025\n",
            "Epoch 32/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6067\n",
            "Epoch 33/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6393\n",
            "Epoch 34/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5699\n",
            "Epoch 35/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.4453\n",
            "Epoch 36/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5767\n",
            "Epoch 37/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8102\n",
            "Epoch 38/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7339\n",
            "Epoch 39/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6309\n",
            "Epoch 40/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8527\n",
            "Epoch 41/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6380\n",
            "Epoch 42/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6250\n",
            "Epoch 43/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6404\n",
            "Epoch 44/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2380\n",
            "Epoch 45/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0636\n",
            "Epoch 46/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.4197\n",
            "Epoch 47/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8157\n",
            "Epoch 48/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6350\n",
            "Epoch 49/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5523\n",
            "Epoch 50/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6964\n",
            "691/691 [==============================] - 1s 836us/step\n",
            "0.7093557773889065\n",
            "Epoch 1/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 11.2316\n",
            "Epoch 2/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2480\n",
            "Epoch 3/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.1370\n",
            "Epoch 4/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0785\n",
            "Epoch 5/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9908\n",
            "Epoch 6/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0814\n",
            "Epoch 7/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0918\n",
            "Epoch 8/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8587\n",
            "Epoch 9/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.8421\n",
            "Epoch 10/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 4.0764\n",
            "Epoch 11/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9719\n",
            "Epoch 12/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8586\n",
            "Epoch 13/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7333\n",
            "Epoch 14/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7262\n",
            "Epoch 15/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7742\n",
            "Epoch 16/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6816\n",
            "Epoch 17/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7394\n",
            "Epoch 18/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7080\n",
            "Epoch 19/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7082\n",
            "Epoch 20/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7017\n",
            "Epoch 21/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6080\n",
            "Epoch 22/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6231\n",
            "Epoch 23/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6192\n",
            "Epoch 24/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9285\n",
            "Epoch 25/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6771\n",
            "Epoch 26/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6626\n",
            "Epoch 27/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6101\n",
            "Epoch 28/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 4.9145\n",
            "Epoch 29/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8858\n",
            "Epoch 30/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0095\n",
            "Epoch 31/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.8952\n",
            "Epoch 32/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8157\n",
            "Epoch 33/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.5007\n",
            "Epoch 34/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7125\n",
            "Epoch 35/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6960\n",
            "Epoch 36/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9867\n",
            "Epoch 37/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7347\n",
            "Epoch 38/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8371\n",
            "Epoch 39/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7736\n",
            "Epoch 40/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.9820\n",
            "Epoch 41/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8627\n",
            "Epoch 42/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8815\n",
            "Epoch 43/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0732\n",
            "Epoch 44/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9337\n",
            "Epoch 45/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7715\n",
            "Epoch 46/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0799\n",
            "Epoch 47/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.1428\n",
            "Epoch 48/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.2549\n",
            "Epoch 49/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.3284\n",
            "Epoch 50/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0879\n",
            "691/691 [==============================] - 1s 958us/step\n",
            "0.6192455267184824\n",
            "Epoch 1/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 3.5338\n",
            "Epoch 2/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 6.8713\n",
            "Epoch 3/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.1287\n",
            "Epoch 4/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0904\n",
            "Epoch 5/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 9.3676\n",
            "Epoch 6/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.1508\n",
            "Epoch 7/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0366\n",
            "Epoch 8/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.1403\n",
            "Epoch 9/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9834\n",
            "Epoch 10/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.4746\n",
            "Epoch 11/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9384\n",
            "Epoch 12/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8749\n",
            "Epoch 13/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8726\n",
            "Epoch 14/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0741\n",
            "Epoch 15/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8675\n",
            "Epoch 16/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8876\n",
            "Epoch 17/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9684\n",
            "Epoch 18/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 7.1362\n",
            "Epoch 19/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7565\n",
            "Epoch 20/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9383\n",
            "Epoch 21/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7325\n",
            "Epoch 22/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0123\n",
            "Epoch 23/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.5859\n",
            "Epoch 24/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7503\n",
            "Epoch 25/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8010\n",
            "Epoch 26/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7453\n",
            "Epoch 27/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8180\n",
            "Epoch 28/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7118\n",
            "Epoch 29/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7724\n",
            "Epoch 30/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7587\n",
            "Epoch 31/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 5.5154\n",
            "Epoch 32/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 5.7383\n",
            "Epoch 33/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7145\n",
            "Epoch 34/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7165\n",
            "Epoch 35/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7066\n",
            "Epoch 36/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9479\n",
            "Epoch 37/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6954\n",
            "Epoch 38/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7745\n",
            "Epoch 39/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6531\n",
            "Epoch 40/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7159\n",
            "Epoch 41/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 3.1157\n",
            "Epoch 42/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6927\n",
            "Epoch 43/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6605\n",
            "Epoch 44/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6681\n",
            "Epoch 45/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7788\n",
            "Epoch 46/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9311\n",
            "Epoch 47/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7360\n",
            "Epoch 48/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7138\n",
            "Epoch 49/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.0418\n",
            "Epoch 50/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7584\n",
            "691/691 [==============================] - 1s 904us/step\n",
            "0.5984775313243338\n",
            "Epoch 1/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 23.3761\n",
            "Epoch 2/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 4.8134\n",
            "Epoch 3/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 5.4472\n",
            "Epoch 4/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 3.9444\n",
            "Epoch 5/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 5.0804\n",
            "Epoch 6/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.6303\n",
            "Epoch 7/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 3.4501\n",
            "Epoch 8/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.8351\n",
            "Epoch 9/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.9592\n",
            "Epoch 10/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8873\n",
            "Epoch 11/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7730\n",
            "Epoch 12/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 2.3248\n",
            "Epoch 13/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7984\n",
            "Epoch 14/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6907\n",
            "Epoch 15/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6959\n",
            "Epoch 16/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6920\n",
            "Epoch 17/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8352\n",
            "Epoch 18/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7730\n",
            "Epoch 19/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5673\n",
            "Epoch 20/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5538\n",
            "Epoch 21/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6622\n",
            "Epoch 22/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.8619\n",
            "Epoch 23/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5464\n",
            "Epoch 24/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4675\n",
            "Epoch 25/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5664\n",
            "Epoch 26/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5054\n",
            "Epoch 27/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5356\n",
            "Epoch 28/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5003\n",
            "Epoch 29/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5075\n",
            "Epoch 30/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6892\n",
            "Epoch 31/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5967\n",
            "Epoch 32/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6378\n",
            "Epoch 33/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6625\n",
            "Epoch 34/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6115\n",
            "Epoch 35/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5718\n",
            "Epoch 36/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5197\n",
            "Epoch 37/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5575\n",
            "Epoch 38/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.6080\n",
            "Epoch 39/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4589\n",
            "Epoch 40/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4279\n",
            "Epoch 41/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4360\n",
            "Epoch 42/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4274\n",
            "Epoch 43/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7400\n",
            "Epoch 44/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7238\n",
            "Epoch 45/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7822\n",
            "Epoch 46/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5528\n",
            "Epoch 47/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4765\n",
            "Epoch 48/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.4856\n",
            "Epoch 49/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.5583\n",
            "Epoch 50/50\n",
            "1036/1036 [==============================] - 2s 2ms/step - loss: 1.7251\n",
            "691/691 [==============================] - 1s 984us/step\n",
            "0.738468090465585\n",
            "Best seed: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "Tk4ZOzw-O7oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# estimate a value for the scale_pos_weight xgboost hyperparameter\n",
        "from sklearn.datasets import make_classification\n",
        "from collections import Counter\n",
        "# count examples in each class\n",
        "counter = Counter(y_train)\n",
        "# estimate scale_pos_weight value\n",
        "estimate = counter[0] / counter[1]\n",
        "print('Estimate: %.3f' % estimate)\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMDSLJckPDj6",
        "outputId": "26dc5884-d7ee-416e-d3f8-5324f2a46025"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimate: 230.776\n",
            "Counter({0: 33001, 1: 143})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit balanced xgboost on an imbalanced classification dataset\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "# define model\n",
        "xgb = XGBClassifier(scale_pos_weight=1000)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(xgb, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "# summarize performance\n",
        "print('Mean ROC AUC: %.5f' % mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYdXi-HzO-GZ",
        "outputId": "ebc07627-4e16-4aac-9688-24f0128d3fdc"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC: 0.87897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the classifier on training data\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on test data\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_xgb)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bOMRyfjPb0e",
        "outputId": "e915a043-b807-42a7-d517-29a6e2c95a50"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.86     22001\n",
            "           1       0.01      0.79      0.03        96\n",
            "\n",
            "    accuracy                           0.76     22097\n",
            "   macro avg       0.51      0.77      0.44     22097\n",
            "weighted avg       0.99      0.76      0.86     22097\n",
            "\n",
            "[[16656  5345]\n",
            " [   20    76]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grid search positive class weights with xgboost for imbalance classification\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# define model\n",
        "model_temp = XGBClassifier()\n",
        "# define grid\n",
        "weights = [1, 10, 25, 50, 75, 100, 230, 250, 500, 750, 1000]\n",
        "param_grid = dict(scale_pos_weight=weights)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define grid search\n",
        "grid = GridSearchCV(estimator=model_temp, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='recall')\n",
        "# execute the grid search\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# report the best configuration\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "# report all configurations\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyZvOE0Mcvw3",
        "outputId": "faba7f2e-6d02-4016-e636-186c8e20ccae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.827778 using {'scale_pos_weight': 1000}\n",
            "0.000000 (0.000000) with: {'scale_pos_weight': 1}\n",
            "0.009365 (0.023888) with: {'scale_pos_weight': 10}\n",
            "0.144762 (0.106214) with: {'scale_pos_weight': 25}\n",
            "0.405714 (0.113578) with: {'scale_pos_weight': 50}\n",
            "0.465556 (0.130043) with: {'scale_pos_weight': 75}\n",
            "0.542857 (0.144064) with: {'scale_pos_weight': 100}\n",
            "0.687143 (0.138162) with: {'scale_pos_weight': 230}\n",
            "0.713175 (0.121478) with: {'scale_pos_weight': 250}\n",
            "0.790317 (0.103648) with: {'scale_pos_weight': 500}\n",
            "0.806667 (0.093989) with: {'scale_pos_weight': 750}\n",
            "0.827778 (0.092329) with: {'scale_pos_weight': 1000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "F9UmHIQvf6YG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# weighted logistic regression for class imbalance with heuristic weights\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define model\n",
        "weights_assigned_lr={0:1,1:230}\n",
        "model_lr = LogisticRegression(solver='lbfgs', class_weight=weights_assigned_lr)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model_lr, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "# summarize performance\n",
        "print('Mean ROC AUC: %.3f' % mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ks15oGSf9Oo",
        "outputId": "0a45768c-7f03-4142-960d-15c01379b0da"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC: 0.837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the classifier on training data\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on test data\n",
        "y_pred_lr = model_lr.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_lr)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJouARTIgCuz",
        "outputId": "fd2129ab-6d5d-49b1-a8cd-001c680aa36b"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.74      0.85     22001\n",
            "           1       0.01      0.74      0.02        96\n",
            "\n",
            "    accuracy                           0.74     22097\n",
            "   macro avg       0.51      0.74      0.44     22097\n",
            "weighted avg       0.99      0.74      0.85     22097\n",
            "\n",
            "[[16355  5646]\n",
            " [   25    71]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grid search class weights with logistic regression for imbalance classification\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define model\n",
        "model_lr_gs = LogisticRegression(solver='lbfgs')\n",
        "# define grid\n",
        "balance = [{0:1,1:2}, {0:1,1:10}, {0:1,1:100}, {0:1,1:200}, {0:1,1:230}, {0:1,1:250}, {0:1,1:500}, {0:1,1:750}, {0:1,1:1000}]\n",
        "param_grid = dict(class_weight=balance)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define grid search\n",
        "grid = GridSearchCV(estimator=model_lr_gs, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='recall')\n",
        "# execute the grid search\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# report the best configuration\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "# report all configurations\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0TS56onggbS",
        "outputId": "4c12f9a3-ad3d-4355-c3ae-18be4f8043a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.927937 using {'class_weight': {0: 1, 1: 1000}}\n",
            "0.000000 (0.000000) with: {'class_weight': {0: 1, 1: 2}}\n",
            "0.011905 (0.026620) with: {'class_weight': {0: 1, 1: 10}}\n",
            "0.638413 (0.129438) with: {'class_weight': {0: 1, 1: 100}}\n",
            "0.750476 (0.117125) with: {'class_weight': {0: 1, 1: 200}}\n",
            "0.775873 (0.115842) with: {'class_weight': {0: 1, 1: 230}}\n",
            "0.791429 (0.115027) with: {'class_weight': {0: 1, 1: 250}}\n",
            "0.864127 (0.095228) with: {'class_weight': {0: 1, 1: 500}}\n",
            "0.911429 (0.067809) with: {'class_weight': {0: 1, 1: 750}}\n",
            "0.927937 (0.057967) with: {'class_weight': {0: 1, 1: 1000}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grid search class weights with logistic regression for imbalance classification\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# define model\n",
        "model_lr_gs = LogisticRegression(solver='lbfgs')\n",
        "# define grid\n",
        "balance = [{0:1,1:2}, {0:1,1:10}, {0:1,1:100}, {0:1,1:200}, {0:1,1:230}, {0:1,1:250}, {0:1,1:500}, {0:1,1:750}, {0:1,1:1000}]\n",
        "param_grid = dict(class_weight=balance)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define grid search\n",
        "grid = GridSearchCV(estimator=model_lr_gs, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
        "# execute the grid search\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# report the best configuration\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "# report all configurations\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfCKHzU_iQOM",
        "outputId": "86887d72-b8ee-4f4c-aed2-5a9ac5bd9c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.836852 using {'class_weight': {0: 1, 1: 230}}\n",
            "0.828657 (0.059543) with: {'class_weight': {0: 1, 1: 2}}\n",
            "0.832004 (0.058225) with: {'class_weight': {0: 1, 1: 10}}\n",
            "0.835330 (0.055008) with: {'class_weight': {0: 1, 1: 100}}\n",
            "0.835868 (0.051855) with: {'class_weight': {0: 1, 1: 200}}\n",
            "0.836852 (0.051562) with: {'class_weight': {0: 1, 1: 230}}\n",
            "0.834642 (0.051406) with: {'class_weight': {0: 1, 1: 250}}\n",
            "0.836213 (0.047974) with: {'class_weight': {0: 1, 1: 500}}\n",
            "0.831653 (0.048348) with: {'class_weight': {0: 1, 1: 750}}\n",
            "0.827474 (0.047409) with: {'class_weight': {0: 1, 1: 1000}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble with LR and XGboost"
      ],
      "metadata": {
        "id": "aSzzkMktlI7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the ensemble model\n",
        "ensemble = VotingClassifier(estimators=[('xgb', xgb), ('lr', model_lr)], voting='soft')\n",
        "\n",
        "# Fit the ensemble model on the training data\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on test data\n",
        "y_pred_ensemble = ensemble.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_ensemble))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_ensemble)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFC57SQ_lHxf",
        "outputId": "102e4ddb-3437-4a93-9523-ebd3b23b7068"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.79      0.88     22001\n",
            "           1       0.02      0.76      0.03        96\n",
            "\n",
            "    accuracy                           0.79     22097\n",
            "   macro avg       0.51      0.77      0.46     22097\n",
            "weighted avg       0.99      0.79      0.88     22097\n",
            "\n",
            "[[17328  4673]\n",
            " [   23    73]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking"
      ],
      "metadata": {
        "id": "6P--HzJX4cNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4-soynW9P8Y",
        "outputId": "98263600-138a-4923-b880-798ba48dc871"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (23.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Create the base models\n",
        "# rf = RandomForestClassifier(n_estimators=100)\n",
        "# xgb_clf = xgb.XGBClassifier(n_estimators=200)\n",
        "# ann = MLPClassifier(hidden_layer_sizes=(50,50))\n",
        "\n",
        "# Create the meta-model\n",
        "# meta_model = MLPClassifier(hidden_layer_sizes=(50,50))\n",
        "\n",
        "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "# create model\n",
        "ann_stacking_model = KerasClassifier(model=model, epochs=50, random_state=10, class_weight=weights_assigned, verbose=0)\n",
        "\n",
        "# Create the stacking classifier\n",
        "stacking_clf = StackingClassifier(estimators=[('lr', model_lr), ('ann', ann_stacking_model)], final_estimator=ann_stacking_model)\n",
        "\n",
        "# Train the classifier\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_stacking = stacking_clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred_stacking))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "hkMDMhYP4eER",
        "outputId": "82cf4455-1307-4513-ddee-7751d204b1b8"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-81ba7fe6184a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mstacking_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"final_estimator_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# 'drop' string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_final_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mstack_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_method\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36m_validate_final_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_final_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clone_final_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36m_clone_final_estimator\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_clone_final_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_estimator_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_estimator_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_params\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scikeras/_saving_utils.py\u001b[0m in \u001b[0;36mdeepcopy_model\u001b[0;34m(model, memo)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeepcopy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_bytes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scikeras/_saving_utils.py\u001b[0m in \u001b[0;36munpack_keras_model\u001b[0;34m(packed_keras_model)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    874\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;34m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptimizerV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# Needed to avoid infinite recursion with __setattr__.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'build'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest very bad"
      ],
      "metadata": {
        "id": "_z59aOcTAEhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "weights_assigned1={0:1,1:2}\n",
        "# Initializing Random Forest classifier with class weights\n",
        "clf = RandomForestClassifier(class_weight='balanced')\n",
        "\n",
        "# Fitting the classifier on training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on test data\n",
        "y_pred_clf = clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_clf))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_clf)\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_Ig7hCRC_ez",
        "outputId": "2c32bca9-73c9-4bfe-b8c1-f996ffce8d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       0.00      0.00      0.00        96\n",
            "\n",
            "    accuracy                           1.00     22097\n",
            "   macro avg       0.50      0.50      0.50     22097\n",
            "weighted avg       0.99      1.00      0.99     22097\n",
            "\n",
            "[[21998     3]\n",
            " [   96     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted SVM very bad"
      ],
      "metadata": {
        "id": "6pbIG57lOYmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# svm with class weight on an imbalanced classification dataset\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "# define model\n",
        "model_svm = SVC(gamma='scale', class_weight='balanced')\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model_svm, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "# summarize performance\n",
        "print('Mean ROC AUC: %.3f' % mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "oknnNcb_ObG1",
        "outputId": "3c0013ce-500c-41c8-e62d-e14d2afced59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-785811abb30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_svm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# summarize performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean ROC AUC: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# svm with class weight on an imbalanced classification dataset\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "# define model\n",
        "weights_assigned_svm={0:1,1:230}\n",
        "model_svm = SVC(gamma='scale', class_weight=weights_assigned_svm)\n",
        "\n",
        "# Fitting the classifier on training data\n",
        "model_svm.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on test data\n",
        "y_pred_svm = model_svm.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_svm)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQubmk0WOlq2",
        "outputId": "974aa4f8-1d34-4b25-d752-f5ee9f393a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.81      0.89     22001\n",
            "           1       0.01      0.32      0.01        96\n",
            "\n",
            "    accuracy                           0.80     22097\n",
            "   macro avg       0.50      0.56      0.45     22097\n",
            "weighted avg       0.99      0.80      0.89     22097\n",
            "\n",
            "[[17713  4288]\n",
            " [   65    31]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Trees very bad"
      ],
      "metadata": {
        "id": "8iB41mW-dNvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree with class weight on an imbalanced classification dataset\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# define model\n",
        "weights_assigned_dt={0:1,1:300}\n",
        "model_dt = DecisionTreeClassifier(class_weight=weights_assigned_dt)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model_dt, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "# summarize performance\n",
        "print('Mean ROC AUC: %.3f' % mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_i3PJm3dTFd",
        "outputId": "0a51fd95-b018-44cf-83cf-99ff068664e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean ROC AUC: 0.516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the classifier on training data\n",
        "model_dt.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on test data\n",
        "y_pred_dt = model_dt.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_dt)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGVPz2o7dZOU",
        "outputId": "7536a445-9d34-47c3-afe3-3bfe7af97155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       0.01      0.01      0.01        96\n",
            "\n",
            "    accuracy                           0.99     22097\n",
            "   macro avg       0.50      0.50      0.50     22097\n",
            "weighted avg       0.99      0.99      0.99     22097\n",
            "\n",
            "[[21897   104]\n",
            " [   95     1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking"
      ],
      "metadata": {
        "id": "uYLkAobc1_QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare standalone models for binary classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tmodels['lr'] = LogisticRegression()\n",
        "\tmodels['knn'] = KNeighborsClassifier()\n",
        "\tmodels['cart'] = DecisionTreeClassifier()\n",
        "\tmodels['svm'] = SVC()\n",
        "\treturn models\n",
        "\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(model, X, y, scoring='recall', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\treturn scores\n",
        "\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "CSzf6P2b4p6q",
        "outputId": "049a7ce3-c395-44e4-a3c3-d97bdecc57df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">lr 0.000 (0.000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">knn 0.000 (0.000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">cart 0.250 (0.071)\n",
            ">svm 0.000 (0.000)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction with a stacking ensemble\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# define the base models\n",
        "level0 = list()\n",
        "level0.append(('lr', LogisticRegression()))\n",
        "level0.append(('knn', KNeighborsClassifier()))\n",
        "level0.append(('cart', DecisionTreeClassifier()))\n",
        "level0.append(('svm', SVC()))\n",
        "level0.append(('bayes', GaussianNB()))\n",
        "# define meta learner model\n",
        "level1 = LogisticRegression()\n",
        "# level1 = model\n",
        "# define the stacking ensemble\n",
        "model1 = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
        "# fit the model on all available data\n",
        "model1.fit(X, y)\n",
        "# make a prediction for one example\n",
        "yhat = model.predict(y_test)\n",
        "print('Predicted Class: %d' % (yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EFyjFQzA6I6y",
        "outputId": "5c403b6a-2b86-46fe-c4db-aa72f5ec20a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-3bee4ed4ff91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# make a prediction for one example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Class: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \"\"\"\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_ties\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ovo\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_stacking))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Print the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_stacking)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "eUFWPyJJ2RVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost\n",
        "\n",
        "dtc =  DecisionTreeClassifier()\n",
        "rfc = RandomForestClassifier()\n",
        "xgb = xgboost.XGBClassifier()\n",
        "clf = [('dtc',dtc),('rfc',rfc),('ann',model),('xgb',xgb)] #list of (str, estimator)\n",
        "lr = LogisticRegression()\n",
        "stack_model = StackingClassifier(estimators = clf,final_estimator = lr)\n",
        "\n",
        "y_pred_stacking = stack_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Q1hmsN8d2CEU",
        "outputId": "de6a643b-e55a-4f04-d2cd-371f8b3ac10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-df29b3da21a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mstack_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mestimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my_pred_stacking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: This 'StackingClassifier' has no attribute 'predict'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking 2"
      ],
      "metadata": {
        "id": "h_evFk86tfqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy as cp\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split, PredefinedSplit, GridSearchCV\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from collections.abc import Iterable\n",
        "from more_itertools import powerset\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "RANDOM_STATE : int = 42\n",
        "TARGET_NAME : str = \"target\""
      ],
      "metadata": {
        "id": "ssCkY-2gtoJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2C5ZpXv1hsf",
        "outputId": "da3a0726-a78f-474e-bf08-17ac1be18168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (23.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
        "    model3 = Sequential()\n",
        "    # define first hidden layer and visible layer\n",
        "    model3.add(Dense(n_inputs, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model3.add(Dense(30, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model3.add(Dense(10, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'))\n",
        "    # define output layer\n",
        "    model3.add(Dense(1, activation='sigmoid'))\n",
        "    # define loss and optimizer\n",
        "    model3.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    return model3\n",
        "\n",
        "\n",
        "model4 = KerasClassifier(model=create_model, verbose=0)\n",
        "\n",
        "\n",
        "level_0_classifiers = dict()\n",
        "level_0_classifiers[\"logreg\"] = LogisticRegression(random_state=RANDOM_STATE)\n",
        "level_0_classifiers[\"forest\"] = RandomForestClassifier(random_state=RANDOM_STATE)\n",
        "level_0_classifiers[\"xgboost\"] = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
        "level_0_classifiers[\"xtrees\"] = ExtraTreesClassifier(random_state=RANDOM_STATE)\n",
        "level_0_classifiers[\"ann\"] = model4\n",
        "\n",
        "level_1_classifier = ExtraTreesClassifier(random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "4AxvVnbvuYFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "stacking_model = StackingClassifier(estimators=list(level_0_classifiers.items()), final_estimator=level_1_classifier, passthrough=True, cv=kfold, stack_method=\"predict_proba\")\n"
      ],
      "metadata": {
        "id": "Bwu6WJ-GuhNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "level_0_columns = [f\"{name}_prediction\" for name in level_0_classifiers.keys()]\n",
        "pd.DataFrame(stacking_model.fit_transform(X_train, y_train), columns=level_0_columns + list(X_train.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xd5MsYi-v4en",
        "outputId": "6353bb3e-d161-4b54-982e-061549c24ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       logreg_prediction  forest_prediction  xgboost_prediction  \\\n",
              "0               0.012245               0.00            0.016238   \n",
              "1               0.011749               0.01            0.056839   \n",
              "2               0.030018               0.00            0.011423   \n",
              "3               0.000279               0.00            0.000278   \n",
              "4               0.000289               0.00            0.000463   \n",
              "...                  ...                ...                 ...   \n",
              "33139           0.003355               0.00            0.003381   \n",
              "33140           0.001533               0.00            0.000408   \n",
              "33141           0.001336               0.00            0.000358   \n",
              "33142           0.000402               0.00            0.000402   \n",
              "33143           0.000184               0.00            0.000206   \n",
              "\n",
              "       xtrees_prediction  ann_prediction   gap_hours  spherical_distances  \\\n",
              "0                    0.0    6.276869e-09  461.750000           308.923179   \n",
              "1                    0.0    1.017744e-03   13.716667             2.480992   \n",
              "2                    0.0    3.132713e-14   98.700000           783.791911   \n",
              "3                    0.0    1.296512e-04   12.850000            28.226168   \n",
              "4                    0.0    5.331431e-05   12.983333            58.975136   \n",
              "...                  ...             ...         ...                  ...   \n",
              "33139                0.0    3.022181e-32  489.183333           708.782853   \n",
              "33140                0.0    1.422381e-04   13.133333            43.714577   \n",
              "33141                0.0    1.882824e-04   12.616667            60.341627   \n",
              "33142                0.0    2.286237e-04   16.100000            59.259190   \n",
              "33143                0.0    1.640129e-05   23.033333           123.774836   \n",
              "\n",
              "       eez_check  score     speed  ...  \\\n",
              "0            1.0   91.0  0.669027  ...   \n",
              "1            0.0   89.0  0.180874  ...   \n",
              "2            0.0   94.0  7.941154  ...   \n",
              "3            0.0   89.0  2.196589  ...   \n",
              "4            1.0   98.0  4.542372  ...   \n",
              "...          ...    ...       ...  ...   \n",
              "33139        1.0   91.0  1.448910  ...   \n",
              "33140        0.0   91.0  3.328521  ...   \n",
              "33141        0.0   86.0  4.782692  ...   \n",
              "33142        0.0   89.0  3.680695  ...   \n",
              "33143        0.0   91.0  5.373727  ...   \n",
              "\n",
              "       exact _name new from diff Oceans_South Pacific Ocean  \\\n",
              "0                                                    0.0      \n",
              "1                                                    0.0      \n",
              "2                                                    0.0      \n",
              "3                                                    0.0      \n",
              "4                                                    1.0      \n",
              "...                                                  ...      \n",
              "33139                                                1.0      \n",
              "33140                                                1.0      \n",
              "33141                                                1.0      \n",
              "33142                                                0.0      \n",
              "33143                                                0.0      \n",
              "\n",
              "       exact _name new from diff Oceans_Southern Ocean  \\\n",
              "0                                                  0.0   \n",
              "1                                                  0.0   \n",
              "2                                                  0.0   \n",
              "3                                                  0.0   \n",
              "4                                                  0.0   \n",
              "...                                                ...   \n",
              "33139                                              0.0   \n",
              "33140                                              0.0   \n",
              "33141                                              0.0   \n",
              "33142                                              0.0   \n",
              "33143                                              0.0   \n",
              "\n",
              "       exact _name new from diff Oceans_Tasman Sea  \\\n",
              "0                                              0.0   \n",
              "1                                              0.0   \n",
              "2                                              0.0   \n",
              "3                                              0.0   \n",
              "4                                              0.0   \n",
              "...                                            ...   \n",
              "33139                                          0.0   \n",
              "33140                                          0.0   \n",
              "33141                                          0.0   \n",
              "33142                                          0.0   \n",
              "33143                                          0.0   \n",
              "\n",
              "       exact _name new from diff Oceans_Timor Sea  \\\n",
              "0                                             0.0   \n",
              "1                                             0.0   \n",
              "2                                             0.0   \n",
              "3                                             0.0   \n",
              "4                                             0.0   \n",
              "...                                           ...   \n",
              "33139                                         0.0   \n",
              "33140                                         0.0   \n",
              "33141                                         0.0   \n",
              "33142                                         0.0   \n",
              "33143                                         0.0   \n",
              "\n",
              "       ais_disable_time_division_Afternoon  ais_disable_time_division_Dawn  \\\n",
              "0                                      1.0                             0.0   \n",
              "1                                      0.0                             1.0   \n",
              "2                                      0.0                             0.0   \n",
              "3                                      0.0                             1.0   \n",
              "4                                      1.0                             0.0   \n",
              "...                                    ...                             ...   \n",
              "33139                                  0.0                             1.0   \n",
              "33140                                  0.0                             0.0   \n",
              "33141                                  1.0                             0.0   \n",
              "33142                                  0.0                             0.0   \n",
              "33143                                  0.0                             1.0   \n",
              "\n",
              "       ais_disable_time_division_Evening  ais_disable_time_division_Morning  \\\n",
              "0                                    0.0                                0.0   \n",
              "1                                    0.0                                0.0   \n",
              "2                                    0.0                                1.0   \n",
              "3                                    0.0                                0.0   \n",
              "4                                    0.0                                0.0   \n",
              "...                                  ...                                ...   \n",
              "33139                                0.0                                0.0   \n",
              "33140                                0.0                                1.0   \n",
              "33141                                0.0                                0.0   \n",
              "33142                                0.0                                0.0   \n",
              "33143                                0.0                                0.0   \n",
              "\n",
              "       ais_disable_time_division_Night  ais_disable_time_division_Twilight  \n",
              "0                                  0.0                                 0.0  \n",
              "1                                  0.0                                 0.0  \n",
              "2                                  0.0                                 0.0  \n",
              "3                                  0.0                                 0.0  \n",
              "4                                  0.0                                 0.0  \n",
              "...                                ...                                 ...  \n",
              "33139                              0.0                                 0.0  \n",
              "33140                              0.0                                 0.0  \n",
              "33141                              0.0                                 0.0  \n",
              "33142                              0.0                                 1.0  \n",
              "33143                              0.0                                 0.0  \n",
              "\n",
              "[33144 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b59c606-044a-4d83-a390-a9754f4542c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logreg_prediction</th>\n",
              "      <th>forest_prediction</th>\n",
              "      <th>xgboost_prediction</th>\n",
              "      <th>xtrees_prediction</th>\n",
              "      <th>ann_prediction</th>\n",
              "      <th>gap_hours</th>\n",
              "      <th>spherical_distances</th>\n",
              "      <th>eez_check</th>\n",
              "      <th>score</th>\n",
              "      <th>speed</th>\n",
              "      <th>...</th>\n",
              "      <th>exact _name new from diff Oceans_South Pacific Ocean</th>\n",
              "      <th>exact _name new from diff Oceans_Southern Ocean</th>\n",
              "      <th>exact _name new from diff Oceans_Tasman Sea</th>\n",
              "      <th>exact _name new from diff Oceans_Timor Sea</th>\n",
              "      <th>ais_disable_time_division_Afternoon</th>\n",
              "      <th>ais_disable_time_division_Dawn</th>\n",
              "      <th>ais_disable_time_division_Evening</th>\n",
              "      <th>ais_disable_time_division_Morning</th>\n",
              "      <th>ais_disable_time_division_Night</th>\n",
              "      <th>ais_disable_time_division_Twilight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.012245</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.016238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.276869e-09</td>\n",
              "      <td>461.750000</td>\n",
              "      <td>308.923179</td>\n",
              "      <td>1.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.669027</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.011749</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.056839</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.017744e-03</td>\n",
              "      <td>13.716667</td>\n",
              "      <td>2.480992</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0.180874</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.030018</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.132713e-14</td>\n",
              "      <td>98.700000</td>\n",
              "      <td>783.791911</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>7.941154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000278</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.296512e-04</td>\n",
              "      <td>12.850000</td>\n",
              "      <td>28.226168</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>2.196589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000289</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.331431e-05</td>\n",
              "      <td>12.983333</td>\n",
              "      <td>58.975136</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>4.542372</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33139</th>\n",
              "      <td>0.003355</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.003381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.022181e-32</td>\n",
              "      <td>489.183333</td>\n",
              "      <td>708.782853</td>\n",
              "      <td>1.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>1.448910</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33140</th>\n",
              "      <td>0.001533</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.422381e-04</td>\n",
              "      <td>13.133333</td>\n",
              "      <td>43.714577</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>3.328521</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33141</th>\n",
              "      <td>0.001336</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000358</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.882824e-04</td>\n",
              "      <td>12.616667</td>\n",
              "      <td>60.341627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>4.782692</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33142</th>\n",
              "      <td>0.000402</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.286237e-04</td>\n",
              "      <td>16.100000</td>\n",
              "      <td>59.259190</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>3.680695</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33143</th>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.640129e-05</td>\n",
              "      <td>23.033333</td>\n",
              "      <td>123.774836</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>5.373727</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33144 rows  69 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b59c606-044a-4d83-a390-a9754f4542c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b59c606-044a-4d83-a390-a9754f4542c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b59c606-044a-4d83-a390-a9754f4542c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_explain_sklearn = pd.DataFrame()\n",
        "\n",
        "for name, classifier in level_0_classifiers.items():\n",
        "    classifier_ = cp.deepcopy(classifier)\n",
        "    classifier_.fit(X_train, y_train)\n",
        "    \n",
        "    y_predict_proba = classifier_.predict_proba(X_train)[:, 1]\n",
        "    df_explain_sklearn = pd.concat([df_explain_sklearn, pd.DataFrame(y_predict_proba, columns=[f\"{name}_prediction\"])], axis=1)\n",
        "\n",
        "df_explain_sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "Uh1MPrsMwkSX",
        "outputId": "a34af8b4-a910-4a1f-a3b1-edff5e97673f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       logreg_prediction  forest_prediction  xgboost_prediction  \\\n",
              "0               0.012245               0.00            0.016238   \n",
              "1               0.011749               0.01            0.056839   \n",
              "2               0.030018               0.00            0.011423   \n",
              "3               0.000279               0.00            0.000278   \n",
              "4               0.000289               0.00            0.000463   \n",
              "...                  ...                ...                 ...   \n",
              "33139           0.003355               0.00            0.003381   \n",
              "33140           0.001533               0.00            0.000408   \n",
              "33141           0.001336               0.00            0.000358   \n",
              "33142           0.000402               0.00            0.000402   \n",
              "33143           0.000184               0.00            0.000206   \n",
              "\n",
              "       xtrees_prediction  ann_prediction  \n",
              "0                    0.0    1.106922e-01  \n",
              "1                    0.0    1.857508e-02  \n",
              "2                    0.0    1.291440e-06  \n",
              "3                    0.0    5.442139e-03  \n",
              "4                    0.0    2.582180e-03  \n",
              "...                  ...             ...  \n",
              "33139                0.0    5.979902e-08  \n",
              "33140                0.0    5.700632e-03  \n",
              "33141                0.0    4.304196e-03  \n",
              "33142                0.0    2.972181e-03  \n",
              "33143                0.0    7.812816e-04  \n",
              "\n",
              "[33144 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76104e2d-c6df-41cd-a30a-0ba482049fd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logreg_prediction</th>\n",
              "      <th>forest_prediction</th>\n",
              "      <th>xgboost_prediction</th>\n",
              "      <th>xtrees_prediction</th>\n",
              "      <th>ann_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.012245</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.016238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.106922e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.011749</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.056839</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.857508e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.030018</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.291440e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000278</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.442139e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000289</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.582180e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33139</th>\n",
              "      <td>0.003355</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.003381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.979902e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33140</th>\n",
              "      <td>0.001533</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.700632e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33141</th>\n",
              "      <td>0.001336</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000358</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.304196e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33142</th>\n",
              "      <td>0.000402</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.972181e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33143</th>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.812816e-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33144 rows  5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76104e2d-c6df-41cd-a30a-0ba482049fd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76104e2d-c6df-41cd-a30a-0ba482049fd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76104e2d-c6df-41cd-a30a-0ba482049fd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(stacking_model.transform(X_test), columns=level_0_columns + list(X_train.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "3mYYeWfuwkNz",
        "outputId": "9184c9d4-7b89-45b5-c589-81245cc81610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       logreg_prediction  forest_prediction  xgboost_prediction  \\\n",
              "0               0.005299               0.01            0.006812   \n",
              "1               0.015085               0.00            0.034142   \n",
              "2               0.000593               0.00            0.000248   \n",
              "3               0.002141               0.00            0.000937   \n",
              "4               0.003090               0.04            0.001855   \n",
              "...                  ...                ...                 ...   \n",
              "22092           0.000450               0.00            0.000199   \n",
              "22093           0.001618               0.00            0.001864   \n",
              "22094           0.000210               0.00            0.000266   \n",
              "22095           0.007150               0.00            0.010592   \n",
              "22096           0.000242               0.00            0.000229   \n",
              "\n",
              "       xtrees_prediction  ann_prediction    gap_hours  spherical_distances  \\\n",
              "0                   0.00    1.556109e-15   203.266667           509.004605   \n",
              "1                   0.01    0.000000e+00  1316.066667          2494.276343   \n",
              "2                   0.00    1.737492e-05    21.433333           135.912913   \n",
              "3                   0.00    4.784448e-11    49.850000           649.387351   \n",
              "4                   0.18    4.689996e-04    21.400000            55.797219   \n",
              "...                  ...             ...          ...                  ...   \n",
              "22092               0.00    2.900815e-04    13.283333             6.685679   \n",
              "22093               0.00    4.239138e-04    12.850000            16.522841   \n",
              "22094               0.00    1.388838e-09    67.566667           381.437143   \n",
              "22095               0.00    0.000000e+00   498.350000          1500.626299   \n",
              "22096               0.00    1.315829e-09    43.266667           499.088933   \n",
              "\n",
              "       eez_check  score      speed  ...  \\\n",
              "0            1.0   98.0   2.504122  ...   \n",
              "1            0.0   98.0   1.895251  ...   \n",
              "2            0.0   88.0   6.341193  ...   \n",
              "3            1.0   94.0  13.026828  ...   \n",
              "4            0.0   91.0   2.607347  ...   \n",
              "...          ...    ...        ...  ...   \n",
              "22092        0.0   94.0   0.503313  ...   \n",
              "22093        0.0   85.0   1.285824  ...   \n",
              "22094        0.0   98.0   5.645345  ...   \n",
              "22095        1.0   94.0   3.011190  ...   \n",
              "22096        0.0   91.0  11.535183  ...   \n",
              "\n",
              "       exact _name new from diff Oceans_South Pacific Ocean  \\\n",
              "0                                                    0.0      \n",
              "1                                                    1.0      \n",
              "2                                                    1.0      \n",
              "3                                                    0.0      \n",
              "4                                                    0.0      \n",
              "...                                                  ...      \n",
              "22092                                                0.0      \n",
              "22093                                                0.0      \n",
              "22094                                                0.0      \n",
              "22095                                                1.0      \n",
              "22096                                                0.0      \n",
              "\n",
              "       exact _name new from diff Oceans_Southern Ocean  \\\n",
              "0                                                  0.0   \n",
              "1                                                  0.0   \n",
              "2                                                  0.0   \n",
              "3                                                  0.0   \n",
              "4                                                  0.0   \n",
              "...                                                ...   \n",
              "22092                                              0.0   \n",
              "22093                                              0.0   \n",
              "22094                                              0.0   \n",
              "22095                                              0.0   \n",
              "22096                                              0.0   \n",
              "\n",
              "       exact _name new from diff Oceans_Tasman Sea  \\\n",
              "0                                              0.0   \n",
              "1                                              0.0   \n",
              "2                                              0.0   \n",
              "3                                              0.0   \n",
              "4                                              0.0   \n",
              "...                                            ...   \n",
              "22092                                          0.0   \n",
              "22093                                          0.0   \n",
              "22094                                          0.0   \n",
              "22095                                          0.0   \n",
              "22096                                          0.0   \n",
              "\n",
              "       exact _name new from diff Oceans_Timor Sea  \\\n",
              "0                                             0.0   \n",
              "1                                             0.0   \n",
              "2                                             0.0   \n",
              "3                                             0.0   \n",
              "4                                             0.0   \n",
              "...                                           ...   \n",
              "22092                                         0.0   \n",
              "22093                                         0.0   \n",
              "22094                                         0.0   \n",
              "22095                                         0.0   \n",
              "22096                                         0.0   \n",
              "\n",
              "       ais_disable_time_division_Afternoon  ais_disable_time_division_Dawn  \\\n",
              "0                                      0.0                             0.0   \n",
              "1                                      0.0                             0.0   \n",
              "2                                      0.0                             1.0   \n",
              "3                                      0.0                             0.0   \n",
              "4                                      0.0                             0.0   \n",
              "...                                    ...                             ...   \n",
              "22092                                  0.0                             0.0   \n",
              "22093                                  0.0                             0.0   \n",
              "22094                                  0.0                             0.0   \n",
              "22095                                  1.0                             0.0   \n",
              "22096                                  0.0                             1.0   \n",
              "\n",
              "       ais_disable_time_division_Evening  ais_disable_time_division_Morning  \\\n",
              "0                                    0.0                                0.0   \n",
              "1                                    1.0                                0.0   \n",
              "2                                    0.0                                0.0   \n",
              "3                                    0.0                                0.0   \n",
              "4                                    0.0                                1.0   \n",
              "...                                  ...                                ...   \n",
              "22092                                0.0                                0.0   \n",
              "22093                                0.0                                0.0   \n",
              "22094                                0.0                                0.0   \n",
              "22095                                0.0                                0.0   \n",
              "22096                                0.0                                0.0   \n",
              "\n",
              "       ais_disable_time_division_Night  ais_disable_time_division_Twilight  \n",
              "0                                  0.0                                 1.0  \n",
              "1                                  0.0                                 0.0  \n",
              "2                                  0.0                                 0.0  \n",
              "3                                  1.0                                 0.0  \n",
              "4                                  0.0                                 0.0  \n",
              "...                                ...                                 ...  \n",
              "22092                              1.0                                 0.0  \n",
              "22093                              0.0                                 1.0  \n",
              "22094                              0.0                                 1.0  \n",
              "22095                              0.0                                 0.0  \n",
              "22096                              0.0                                 0.0  \n",
              "\n",
              "[22097 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-565e73e5-6ab3-496a-bdf5-2066b38a4572\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logreg_prediction</th>\n",
              "      <th>forest_prediction</th>\n",
              "      <th>xgboost_prediction</th>\n",
              "      <th>xtrees_prediction</th>\n",
              "      <th>ann_prediction</th>\n",
              "      <th>gap_hours</th>\n",
              "      <th>spherical_distances</th>\n",
              "      <th>eez_check</th>\n",
              "      <th>score</th>\n",
              "      <th>speed</th>\n",
              "      <th>...</th>\n",
              "      <th>exact _name new from diff Oceans_South Pacific Ocean</th>\n",
              "      <th>exact _name new from diff Oceans_Southern Ocean</th>\n",
              "      <th>exact _name new from diff Oceans_Tasman Sea</th>\n",
              "      <th>exact _name new from diff Oceans_Timor Sea</th>\n",
              "      <th>ais_disable_time_division_Afternoon</th>\n",
              "      <th>ais_disable_time_division_Dawn</th>\n",
              "      <th>ais_disable_time_division_Evening</th>\n",
              "      <th>ais_disable_time_division_Morning</th>\n",
              "      <th>ais_disable_time_division_Night</th>\n",
              "      <th>ais_disable_time_division_Twilight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.005299</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.006812</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.556109e-15</td>\n",
              "      <td>203.266667</td>\n",
              "      <td>509.004605</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>2.504122</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.015085</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.034142</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1316.066667</td>\n",
              "      <td>2494.276343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>1.895251</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000593</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.737492e-05</td>\n",
              "      <td>21.433333</td>\n",
              "      <td>135.912913</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>6.341193</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.002141</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000937</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.784448e-11</td>\n",
              "      <td>49.850000</td>\n",
              "      <td>649.387351</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>13.026828</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.003090</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>0.18</td>\n",
              "      <td>4.689996e-04</td>\n",
              "      <td>21.400000</td>\n",
              "      <td>55.797219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.607347</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22092</th>\n",
              "      <td>0.000450</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.900815e-04</td>\n",
              "      <td>13.283333</td>\n",
              "      <td>6.685679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.503313</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22093</th>\n",
              "      <td>0.001618</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.001864</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.239138e-04</td>\n",
              "      <td>12.850000</td>\n",
              "      <td>16.522841</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>1.285824</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22094</th>\n",
              "      <td>0.000210</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.388838e-09</td>\n",
              "      <td>67.566667</td>\n",
              "      <td>381.437143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>5.645345</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22095</th>\n",
              "      <td>0.007150</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.010592</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>498.350000</td>\n",
              "      <td>1500.626299</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>3.011190</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22096</th>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.315829e-09</td>\n",
              "      <td>43.266667</td>\n",
              "      <td>499.088933</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>11.535183</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22097 rows  69 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-565e73e5-6ab3-496a-bdf5-2066b38a4572')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-565e73e5-6ab3-496a-bdf5-2066b38a4572 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-565e73e5-6ab3-496a-bdf5-2066b38a4572');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = stacking_model.predict(X_test)\n",
        "y_val_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Tn4zx-w0ky",
        "outputId": "8f1392e1-124e-445f-d8fd-97a256ad4691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# print(classification_report(y_test, y_pred_rounded))\n",
        "\n",
        "\n",
        "print(f\"Accuracy of scikit-learn stacking classifier: {classification_report(y_test, y_val_pred)}\")\n",
        "\n",
        "for name, classifier in level_0_classifiers.items():\n",
        "    classifier_ = cp.deepcopy(classifier)\n",
        "    classifier_.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Accuracy of standalone {name} classifier: {classification_report(y_test, classifier_.predict(X_test))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvhsBxPvxkhW",
        "outputId": "cdefc00c-6c23-4e46-9331-8a2af5056dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of scikit-learn stacking classifier:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       0.75      0.12      0.21        96\n",
            "\n",
            "    accuracy                           1.00     22097\n",
            "   macro avg       0.87      0.56      0.61     22097\n",
            "weighted avg       1.00      1.00      0.99     22097\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of standalone logreg classifier:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       0.00      0.00      0.00        96\n",
            "\n",
            "    accuracy                           1.00     22097\n",
            "   macro avg       0.50      0.50      0.50     22097\n",
            "weighted avg       0.99      1.00      0.99     22097\n",
            "\n",
            "Accuracy of standalone forest classifier:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       0.83      0.10      0.19        96\n",
            "\n",
            "    accuracy                           1.00     22097\n",
            "   macro avg       0.91      0.55      0.59     22097\n",
            "weighted avg       1.00      1.00      0.99     22097\n",
            "\n",
            "Accuracy of standalone xgboost classifier:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       1.00      0.09      0.17        96\n",
            "\n",
            "    accuracy                           1.00     22097\n",
            "   macro avg       1.00      0.55      0.58     22097\n",
            "weighted avg       1.00      1.00      0.99     22097\n",
            "\n",
            "Accuracy of standalone xtrees classifier:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       0.15      0.04      0.07        96\n",
            "\n",
            "    accuracy                           0.99     22097\n",
            "   macro avg       0.57      0.52      0.53     22097\n",
            "weighted avg       0.99      0.99      0.99     22097\n",
            "\n",
            "Accuracy of standalone ann classifier:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       0.00      0.00      0.00        96\n",
            "\n",
            "    accuracy                           1.00     22097\n",
            "   macro avg       0.50      0.50      0.50     22097\n",
            "weighted avg       0.99      1.00      0.99     22097\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def power_set(items: Iterable, min_length : int = 0) -> list:\n",
        "    list_of_tuples = list(powerset(items))\n",
        "    list_of_lists = [list(elem) for elem in list_of_tuples]\n",
        "\n",
        "    return [list for list in list_of_lists if len(list)>=min_length]"
      ],
      "metadata": {
        "id": "J_K-ABZHxnPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "power_set(list(level_0_classifiers.keys()), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqn-kerjxpnO",
        "outputId": "98d5a257-f69b-4f5e-f369-9aa7efb89636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['logreg', 'forest'],\n",
              " ['logreg', 'xgboost'],\n",
              " ['logreg', 'xtrees'],\n",
              " ['forest', 'xgboost'],\n",
              " ['forest', 'xtrees'],\n",
              " ['xgboost', 'xtrees'],\n",
              " ['logreg', 'forest', 'xgboost'],\n",
              " ['logreg', 'forest', 'xtrees'],\n",
              " ['logreg', 'xgboost', 'xtrees'],\n",
              " ['forest', 'xgboost', 'xtrees'],\n",
              " ['logreg', 'forest', 'xgboost', 'xtrees']]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(level_0_classifiers.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdLXnPuIxrm-",
        "outputId": "0c503608-39c0-410e-8833-40e5d480c04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['logreg', 'forest', 'xgboost', 'xtrees']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = dict()\n",
        "param_grid[\"estimators\"] = power_set(list(level_0_classifiers.items()), 2)\n",
        "param_grid[\"final_estimator\"] = list(level_0_classifiers.values())\n",
        "param_grid[\"passthrough\"] = [True, False]\n",
        "param_grid[\"stack_method\"] = [\"predict\", \"predict_proba\"]\n",
        "\n",
        "pre_defined_split = PredefinedSplit(test_fold = [-1 if x in X_train.index else 0 for x in X.index])\n",
        "grid_search = GridSearchCV(estimator=stacking_model, param_grid=param_grid, scoring=\"recall\", cv=pre_defined_split, verbose=10)\n",
        "grid_search_results = grid_search.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NqPQxe2hxtag",
        "outputId": "0b53e112-fe14-4913-cde7-7bc724015cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 176 candidates, totalling 176 fits\n",
            "[CV 1/1; 1/176] START estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=LogisticRegression(random_state=42), passthrough=True, stack_method=predict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/1; 1/176] END estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=LogisticRegression(random_state=42), passthrough=True, stack_method=predict;, score=0.000 total time=  19.4s\n",
            "[CV 1/1; 2/176] START estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=LogisticRegression(random_state=42), passthrough=True, stack_method=predict_proba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/1; 2/176] END estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=LogisticRegression(random_state=42), passthrough=True, stack_method=predict_proba;, score=0.000 total time=  20.9s\n",
            "[CV 1/1; 3/176] START estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=LogisticRegression(random_state=42), passthrough=False, stack_method=predict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/1; 3/176] END estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=LogisticRegression(random_state=42), passthrough=False, stack_method=predict;, score=0.104 total time=  28.1s\n",
            "[CV 1/1; 4/176] START estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=LogisticRegression(random_state=42), passthrough=False, stack_method=predict_proba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/1; 4/176] END estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=LogisticRegression(random_state=42), passthrough=False, stack_method=predict_proba;, score=0.083 total time=  17.5s\n",
            "[CV 1/1; 5/176] START estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=RandomForestClassifier(random_state=42), passthrough=True, stack_method=predict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/1; 5/176] END estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=RandomForestClassifier(random_state=42), passthrough=True, stack_method=predict;, score=0.104 total time=  21.6s\n",
            "[CV 1/1; 6/176] START estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=RandomForestClassifier(random_state=42), passthrough=True, stack_method=predict_proba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/1; 6/176] END estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=RandomForestClassifier(random_state=42), passthrough=True, stack_method=predict_proba;, score=0.094 total time=  20.3s\n",
            "[CV 1/1; 7/176] START estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=RandomForestClassifier(random_state=42), passthrough=False, stack_method=predict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/1; 7/176] END estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=RandomForestClassifier(random_state=42), passthrough=False, stack_method=predict;, score=0.104 total time=  18.8s\n",
            "[CV 1/1; 8/176] START estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=RandomForestClassifier(random_state=42), passthrough=False, stack_method=predict_proba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/1; 8/176] END estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=RandomForestClassifier(random_state=42), passthrough=False, stack_method=predict_proba;, score=0.125 total time=  26.4s\n",
            "[CV 1/1; 9/176] START estimators=[('logreg', LogisticRegression(random_state=42)), ('forest', RandomForestClassifier(random_state=42))], final_estimator=XGBClassifier(eval_metric='logloss', random_state=42, use_label_encoder=False), passthrough=True, stack_method=predict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-19746625f41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpre_defined_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredefinedSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacking_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"recall\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_defined_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrid_search_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"final_estimator_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"sample_weight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         )\n\u001b[0;32m--> 193\u001b[0;31m         predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    194\u001b[0m             delayed(cross_val_predict)(\n\u001b[1;32m    195\u001b[0m                 \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m     predictions = parallel(\n\u001b[0m\u001b[1;32m    963\u001b[0m         delayed(_fit_and_predict)(\n\u001b[1;32m    964\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rint(\"Best accuracy score: \", grid_search_results.best_score_)\n",
        "print(\"Best estimators: \", list(dict(grid_search_results.best_params_[\"estimators\"]).keys()))\n",
        "print(\"Best final estimator: \", grid_search_results.best_params_[\"final_estimator\"])\n",
        "print(\"Best passthrough: \", grid_search_results.best_params_[\"passthrough\"])\n",
        "print(\"Best stack method: \", grid_search_results.best_params_[\"stack_method\"])"
      ],
      "metadata": {
        "id": "2vTPw-Plylr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking from scratch"
      ],
      "metadata": {
        "id": "BnYQoQCa5q0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icecream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sccBbrN6F7M",
        "outputId": "fb74e95a-68da-48c1-d806-5f7b1e0c3295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting icecream\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from icecream) (2.6.1)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.2.1 colorama-0.4.6 executing-1.2.0 icecream-2.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy as cp\n",
        "from icecream import ic\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict, train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "RANDOM_STATE : int = 42\n",
        "TARGET_NAME : str = \"target\""
      ],
      "metadata": {
        "id": "ZXK-doz86DVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_data(data_in):\n",
        "    data_out = cp.deepcopy(data_in)\n",
        "    try:\n",
        "        data_out.reset_index(drop=True, inplace=True)\n",
        "    except:\n",
        "        pass\n",
        "    return data_out\n",
        "\n",
        "class Level0Stacker(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self, level_0_classifiers : dict, stack_method : str = \"predict_proba\", passthrough : bool = False, save_x : bool=False): # no *args or **kargs\n",
        "        ic(\"Level0Stacker.init\")\n",
        "        self.level_0_classifiers = level_0_classifiers\n",
        "        self.stack_method = stack_method\n",
        "        self.passthrough = passthrough\n",
        "        self.save_x = save_x\n",
        "\n",
        "        self.X = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        ic(\"Level0Stacker.fit\")\n",
        "        X_copy = copy_data(X) \n",
        "\n",
        "        for classifier in self.level_0_classifiers.values():\n",
        "            classifier.fit(X_copy, y)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        ic(\"Level0Stacker.transform\")\n",
        "        X_copy = copy_data(X) \n",
        "\n",
        "        all_predictions = [None] * len(self.level_0_classifiers)\n",
        "\n",
        "        for i, classifier in enumerate(self.level_0_classifiers.values()):\n",
        "            if self.stack_method == \"predict_proba\":\n",
        "                all_predictions[i] = classifier.predict_proba(X_copy)[:, 1]\n",
        "            else:\n",
        "                all_predictions[i] = classifier.predict(X_copy)\n",
        "\n",
        "        df_stacking = pd.DataFrame(np.array(all_predictions).T, columns=[f\"{name}_prediction\" for name in self.level_0_classifiers.keys()])\n",
        "\n",
        "        X_copy = pd.concat([df_stacking, X_copy], axis=1) if self.passthrough == True else df_stacking\n",
        "\n",
        "        self.X = copy_data(X_copy) if self.save_x == True else None\n",
        "\n",
        "        return X_copy\n",
        "    \n",
        "class Level1Stacker(BaseEstimator, ClassifierMixin):\n",
        "\n",
        "    def __init__(self, model):\n",
        "        ic(\"Level1Stacker.init\")\n",
        "        self.model = model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        ic(\"Level1Stacker.fit\")\n",
        "        self.model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        ic(\"Level1Stacker.predict\")\n",
        "        return self.model.predict(X)\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        ic(\"Level1Stacker.predict_proba\")\n",
        "        return self.model.predict_proba(X)\n",
        "    \n",
        "    @property\n",
        "    def classes_(self):\n",
        "        return self.model.classes_"
      ],
      "metadata": {
        "id": "Fh5V8Wao5vfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "level_0 = Level0Stacker(cp.deepcopy(level_0_classifiers), passthrough=True, save_x=True)\n",
        "level_1 = Level1Stacker(ExtraTreesClassifier(random_state=RANDOM_STATE))\n",
        "\n",
        "scratch_stacking_model = Pipeline([\n",
        "                                   ('level_0', level_0), \n",
        "                                   ('level_1', level_1) \n",
        "                                  ])\n",
        "\n",
        "scratch_stacking_model.fit(X_train, y_train)\n",
        "level_0.X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "SZSm_MRF6N_y",
        "outputId": "0f0e9bd0-36d2-4430-899d-eda66eec8b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| 'Level0Stacker.init'\n",
            "ic| 'Level1Stacker.init'\n",
            "ic| 'Level0Stacker.fit'\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "ic| 'Level0Stacker.transform'\n",
            "ic| 'Level1Stacker.fit'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       logreg_prediction  forest_prediction  xgboost_prediction  \\\n",
              "0               0.012245               0.00            0.016238   \n",
              "1               0.011749               0.01            0.056839   \n",
              "2               0.030018               0.00            0.011423   \n",
              "3               0.000279               0.00            0.000278   \n",
              "4               0.000289               0.00            0.000463   \n",
              "...                  ...                ...                 ...   \n",
              "33139           0.003355               0.00            0.003381   \n",
              "33140           0.001533               0.00            0.000408   \n",
              "33141           0.001336               0.00            0.000358   \n",
              "33142           0.000402               0.00            0.000402   \n",
              "33143           0.000184               0.00            0.000206   \n",
              "\n",
              "       xtrees_prediction  ann_prediction   gap_hours  spherical_distances  \\\n",
              "0                    0.0    2.272566e-19  461.750000           308.923179   \n",
              "1                    0.0    4.553372e-04   13.716667             2.480992   \n",
              "2                    0.0    1.198309e-17   98.700000           783.791911   \n",
              "3                    0.0    1.383810e-03   12.850000            28.226168   \n",
              "4                    0.0    6.127773e-04   12.983333            58.975136   \n",
              "...                  ...             ...         ...                  ...   \n",
              "33139                0.0    3.797659e-15  489.183333           708.782853   \n",
              "33140                0.0    1.370764e-03   13.133333            43.714577   \n",
              "33141                0.0    1.280852e-03   12.616667            60.341627   \n",
              "33142                0.0    8.634223e-04   16.100000            59.259190   \n",
              "33143                0.0    1.404680e-06   23.033333           123.774836   \n",
              "\n",
              "       eez_check  score     speed  ...  \\\n",
              "0              1     91  0.669027  ...   \n",
              "1              0     89  0.180874  ...   \n",
              "2              0     94  7.941154  ...   \n",
              "3              0     89  2.196589  ...   \n",
              "4              1     98  4.542372  ...   \n",
              "...          ...    ...       ...  ...   \n",
              "33139          1     91  1.448910  ...   \n",
              "33140          0     91  3.328521  ...   \n",
              "33141          0     86  4.782692  ...   \n",
              "33142          0     89  3.680695  ...   \n",
              "33143          0     91  5.373727  ...   \n",
              "\n",
              "       exact _name new from diff Oceans_South Pacific Ocean  \\\n",
              "0                                                      0      \n",
              "1                                                      0      \n",
              "2                                                      0      \n",
              "3                                                      0      \n",
              "4                                                      1      \n",
              "...                                                  ...      \n",
              "33139                                                  1      \n",
              "33140                                                  1      \n",
              "33141                                                  1      \n",
              "33142                                                  0      \n",
              "33143                                                  0      \n",
              "\n",
              "       exact _name new from diff Oceans_Southern Ocean  \\\n",
              "0                                                    0   \n",
              "1                                                    0   \n",
              "2                                                    0   \n",
              "3                                                    0   \n",
              "4                                                    0   \n",
              "...                                                ...   \n",
              "33139                                                0   \n",
              "33140                                                0   \n",
              "33141                                                0   \n",
              "33142                                                0   \n",
              "33143                                                0   \n",
              "\n",
              "       exact _name new from diff Oceans_Tasman Sea  \\\n",
              "0                                                0   \n",
              "1                                                0   \n",
              "2                                                0   \n",
              "3                                                0   \n",
              "4                                                0   \n",
              "...                                            ...   \n",
              "33139                                            0   \n",
              "33140                                            0   \n",
              "33141                                            0   \n",
              "33142                                            0   \n",
              "33143                                            0   \n",
              "\n",
              "       exact _name new from diff Oceans_Timor Sea  \\\n",
              "0                                               0   \n",
              "1                                               0   \n",
              "2                                               0   \n",
              "3                                               0   \n",
              "4                                               0   \n",
              "...                                           ...   \n",
              "33139                                           0   \n",
              "33140                                           0   \n",
              "33141                                           0   \n",
              "33142                                           0   \n",
              "33143                                           0   \n",
              "\n",
              "       ais_disable_time_division_Afternoon  ais_disable_time_division_Dawn  \\\n",
              "0                                        1                               0   \n",
              "1                                        0                               1   \n",
              "2                                        0                               0   \n",
              "3                                        0                               1   \n",
              "4                                        1                               0   \n",
              "...                                    ...                             ...   \n",
              "33139                                    0                               1   \n",
              "33140                                    0                               0   \n",
              "33141                                    1                               0   \n",
              "33142                                    0                               0   \n",
              "33143                                    0                               1   \n",
              "\n",
              "       ais_disable_time_division_Evening  ais_disable_time_division_Morning  \\\n",
              "0                                      0                                  0   \n",
              "1                                      0                                  0   \n",
              "2                                      0                                  1   \n",
              "3                                      0                                  0   \n",
              "4                                      0                                  0   \n",
              "...                                  ...                                ...   \n",
              "33139                                  0                                  0   \n",
              "33140                                  0                                  1   \n",
              "33141                                  0                                  0   \n",
              "33142                                  0                                  0   \n",
              "33143                                  0                                  0   \n",
              "\n",
              "       ais_disable_time_division_Night  ais_disable_time_division_Twilight  \n",
              "0                                    0                                   0  \n",
              "1                                    0                                   0  \n",
              "2                                    0                                   0  \n",
              "3                                    0                                   0  \n",
              "4                                    0                                   0  \n",
              "...                                ...                                 ...  \n",
              "33139                                0                                   0  \n",
              "33140                                0                                   0  \n",
              "33141                                0                                   0  \n",
              "33142                                0                                   1  \n",
              "33143                                0                                   0  \n",
              "\n",
              "[33144 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a526b9ab-2e30-488f-a5df-6e1425166ed3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logreg_prediction</th>\n",
              "      <th>forest_prediction</th>\n",
              "      <th>xgboost_prediction</th>\n",
              "      <th>xtrees_prediction</th>\n",
              "      <th>ann_prediction</th>\n",
              "      <th>gap_hours</th>\n",
              "      <th>spherical_distances</th>\n",
              "      <th>eez_check</th>\n",
              "      <th>score</th>\n",
              "      <th>speed</th>\n",
              "      <th>...</th>\n",
              "      <th>exact _name new from diff Oceans_South Pacific Ocean</th>\n",
              "      <th>exact _name new from diff Oceans_Southern Ocean</th>\n",
              "      <th>exact _name new from diff Oceans_Tasman Sea</th>\n",
              "      <th>exact _name new from diff Oceans_Timor Sea</th>\n",
              "      <th>ais_disable_time_division_Afternoon</th>\n",
              "      <th>ais_disable_time_division_Dawn</th>\n",
              "      <th>ais_disable_time_division_Evening</th>\n",
              "      <th>ais_disable_time_division_Morning</th>\n",
              "      <th>ais_disable_time_division_Night</th>\n",
              "      <th>ais_disable_time_division_Twilight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.012245</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.016238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.272566e-19</td>\n",
              "      <td>461.750000</td>\n",
              "      <td>308.923179</td>\n",
              "      <td>1</td>\n",
              "      <td>91</td>\n",
              "      <td>0.669027</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.011749</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.056839</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.553372e-04</td>\n",
              "      <td>13.716667</td>\n",
              "      <td>2.480992</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>0.180874</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.030018</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.011423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.198309e-17</td>\n",
              "      <td>98.700000</td>\n",
              "      <td>783.791911</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>7.941154</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000278</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.383810e-03</td>\n",
              "      <td>12.850000</td>\n",
              "      <td>28.226168</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>2.196589</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000289</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.127773e-04</td>\n",
              "      <td>12.983333</td>\n",
              "      <td>58.975136</td>\n",
              "      <td>1</td>\n",
              "      <td>98</td>\n",
              "      <td>4.542372</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33139</th>\n",
              "      <td>0.003355</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.003381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.797659e-15</td>\n",
              "      <td>489.183333</td>\n",
              "      <td>708.782853</td>\n",
              "      <td>1</td>\n",
              "      <td>91</td>\n",
              "      <td>1.448910</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33140</th>\n",
              "      <td>0.001533</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.370764e-03</td>\n",
              "      <td>13.133333</td>\n",
              "      <td>43.714577</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>3.328521</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33141</th>\n",
              "      <td>0.001336</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000358</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.280852e-03</td>\n",
              "      <td>12.616667</td>\n",
              "      <td>60.341627</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>4.782692</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33142</th>\n",
              "      <td>0.000402</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.634223e-04</td>\n",
              "      <td>16.100000</td>\n",
              "      <td>59.259190</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>3.680695</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33143</th>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.404680e-06</td>\n",
              "      <td>23.033333</td>\n",
              "      <td>123.774836</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>5.373727</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33144 rows  69 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a526b9ab-2e30-488f-a5df-6e1425166ed3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a526b9ab-2e30-488f-a5df-6e1425166ed3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a526b9ab-2e30-488f-a5df-6e1425166ed3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred_scratch = scratch_stacking_model.predict(X_test)\n",
        "y_val_pred_scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGQw_YGU6kMW",
        "outputId": "d1812cff-c411-4240-91d0-ea65d587248e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| 'Level0Stacker.transform'\n",
            "ic| 'Level1Stacker.predict'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# print(classification_report(y_test, y_val_pred_scratch))\n",
        "\n",
        "print(f\"Accuracy of scikit-learn stacking classifier: {classification_report(y_test, y_val_pred_scratch)}\")\n",
        "print(f\"Accuracy of scratch built stacking classifier: {classification_report(y_test, y_val_pred_scratch)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MefkpUD6oRB",
        "outputId": "7275c8de-fc09-460f-ac80-5d0333f19e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of scikit-learn stacking classifier:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       0.38      0.11      0.18        96\n",
            "\n",
            "    accuracy                           1.00     22097\n",
            "   macro avg       0.69      0.56      0.59     22097\n",
            "weighted avg       0.99      1.00      0.99     22097\n",
            "\n",
            "Accuracy of scratch built stacking classifier:               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     22001\n",
            "           1       0.38      0.11      0.18        96\n",
            "\n",
            "    accuracy                           1.00     22097\n",
            "   macro avg       0.69      0.56      0.59     22097\n",
            "weighted avg       0.99      1.00      0.99     22097\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble"
      ],
      "metadata": {
        "id": "kJovV2Ux7RWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "model10 = KerasClassifier(model, verbose=0)\n",
        "\n",
        "# Define the models\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the ensemble model\n",
        "ensemble = VotingClassifier(estimators=[('xgb', xgb), ('rf', rf), ('ann',model10)], voting='soft')\n",
        "\n",
        "# Fit the ensemble model on the training data\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the ensemble model on the test data\n",
        "score = ensemble.score(X_test, y_test)\n",
        "\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "8FF24vUt7TqF",
        "outputId": "18c05607-99a9-49fe-ba4a-9209d8caa41c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEmpty\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-a39b20f1ed14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Fit the ensemble model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Evaluate the ensemble model on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m     75\u001b[0m             delayed(_fit_single_estimator)(\n\u001b[1;32m     76\u001b[0m                 \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[1;32m     75\u001b[0m             delayed(_fit_single_estimator)(\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_params\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scikeras/_saving_utils.py\u001b[0m in \u001b[0;36mdeepcopy_model\u001b[0;34m(model, memo)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeepcopy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_bytes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scikeras/_saving_utils.py\u001b[0m in \u001b[0;36munpack_keras_model\u001b[0;34m(packed_keras_model)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    874\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;34m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptimizerV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# Needed to avoid infinite recursion with __setattr__.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'build'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get the predictions for the test set\n",
        "y_pred_ensemble = ensemble.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred_ensemble))"
      ],
      "metadata": {
        "id": "PetQiIFJ7WnO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "j3dKmFb1fDL-",
        "UgjboMmxy12d",
        "v6R_6hPIXQSm",
        "Tk4ZOzw-O7oS",
        "F9UmHIQvf6YG",
        "aSzzkMktlI7r",
        "6P--HzJX4cNY",
        "_z59aOcTAEhK",
        "6pbIG57lOYmm",
        "8iB41mW-dNvN",
        "uYLkAobc1_QZ",
        "h_evFk86tfqX",
        "BnYQoQCa5q0T",
        "kJovV2Ux7RWZ"
      ]
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}