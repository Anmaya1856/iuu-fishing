# -*- coding: utf-8 -*-
"""SMOTE_DataNew.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_2h57IdIs06qB_FOqQQ-ovruLHQeHA9j

# Importing Dataset and pre processing
"""

import pandas as pd
df=pd.read_csv('ais_disabling_events_final.csv')
df = df.drop('score', axis=1)
df.head()

df.shape

df['iuu_caught'].value_counts()

import seaborn as sns

sns.lmplot(x='gap_hours', y='spherical_distances', hue='iuu_caught', 
           markers=['x', 'o'],
           fit_reg=False, data=df)

index_names = df[df['gap_hours'] >= 5000].index
df.drop(index_names, inplace = True)

index_names = df[df['spherical_distances'] >= 7000].index
df.drop(index_names, inplace = True)

import seaborn as sns

sns.lmplot(x='gap_hours', y='spherical_distances', hue='iuu_caught', 
           markers=['x', 'o'],
           fit_reg=False, data=df)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# run correlation matrix and plot
f, ax = plt.subplots(figsize=(10, 8))
corr = df.corr()
sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool),
            cmap=sns.diverging_palette(220, 10, as_cmap=True),
            square=True, ax=ax)


matrix = df.corr()
print("Correlation matrix is : ")
print(matrix)

"""## One Hot Encoding

"""

print(df['gear type'].unique())
print(df['exact _name new from diff Oceans'].unique())
print(df['ais_disable_time_division'].unique())

print(df['gear type'].value_counts())
print(df['exact _name new from diff Oceans'].value_counts())
print(df['ais_disable_time_division'].value_counts())

one_hot_encoded_data = pd.get_dummies(df, columns = ['gear type', 'exact _name new from diff Oceans','ais_disable_time_division'])
print(one_hot_encoded_data.head())

import seaborn as sns

sns.lmplot(x='gap_hours', y='exact _name new from diff Oceans_South Atlantic Ocean', hue='iuu_caught', 
           markers=['x', 'o'],
           fit_reg=False, data=one_hot_encoded_data)

"""## Test Train Split after One Hot Encoding"""

#### Independent and Dependent Features
X=one_hot_encoded_data.drop("iuu_caught",axis=1)
y=one_hot_encoded_data.iuu_caught

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=15, stratify=y)

y_train.value_counts()

from imblearn.over_sampling import SMOTE, ADASYN

smote = SMOTE(sampling_strategy='minority')
# adasyn = ADASYN(sampling_strategy='minority')
X_train, y_train = smote.fit_resample(X_train,y_train)

# y_sm.value_counts()

y_train.value_counts()

y_test.value_counts()

"""# Normal ANN"""

print(len(X.columns))
n_inputs=len(X.columns)

# define model and set random seed as 42

import tensorflow as tf
import numpy as np
from tensorflow import keras
from sklearn.metrics import confusion_matrix , classification_report
import numpy as np
import tensorflow as tf

np.random.seed(42)
tf.random.set_seed(42)

model_normal = keras.Sequential([
        keras.layers.Dense(50, input_dim=n_inputs, activation='relu', kernel_initializer='he_uniform'),
        keras.layers.Dense(15, activation='relu'),
        keras.layers.Dense(1, activation='sigmoid')
    ])

# define loss and optimizer
model_normal.compile(loss='binary_crossentropy', optimizer='adam')
model_normal.fit(X_train,y_train,epochs=50)

# predict the y_test and find the roc_auc score

from sklearn.metrics import roc_auc_score
y_pred1=model_normal.predict(X_test)

print(roc_auc_score(y_test,y_pred1))

# print y_pred1 which gives the probabilities of the likliehood of IUU fishing 

print(y_pred1)

# plot the ROC-AUC curve, find the nearest point to the top left of the graph that would be the optimal thereshold for y_pred1

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Compute false positive rate (FPR) and true positive rate (TPR)
fpr, tpr, thresholds = roc_curve(y_test, y_pred1)

# Compute the area under the curve (AUC)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()


import numpy as np

# Find the index of the threshold that minimizes the Euclidean distance from (0,1)
idx = np.argmin((1-tpr)**2 + fpr**2)

# Retrieve the optimal threshold
optimal_threshold1 = thresholds[idx]

print(optimal_threshold1)

# find y_pred_rounded by using the threshold obtained above and then print the classification report and confusion matrix

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

y_pred1_rounded = np.where(y_pred1 > optimal_threshold1, 1, 0)
print(classification_report(y_test, y_pred1_rounded))

# Print the confusion matrix
cm = confusion_matrix(y_test, y_pred1_rounded)
print(cm)

"""# XGBoost"""

# fit balanced xgboost on an imbalanced classification dataset
from numpy import mean
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from xgboost import XGBClassifier
# define model
# xgb = XGBClassifier(scale_pos_weight=1000)
# xgb = XGBClassifier(reg_lambda=20)
xgb = XGBClassifier(gamma=3000, max_depth=1)
# define evaluation procedure
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(xgb, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)
# summarize performance
print('Mean ROC AUC: %.5f' % mean(scores))

from numpy import mean
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from xgboost import XGBClassifier
# xgb = XGBClassifier(reg_lambda=15000)
# xgb = XGBClassifier(gamma=3000, max_depth=1)
# Fitting the classifier on training data
xgb.fit(X_train, y_train)

# Making predictions on test data
y_pred_xgb = xgb.predict(X_test)

# plot the ROC-AUC curve, find the nearest point to the top left of the graph that would be the optimal thereshold for y_pred1

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Compute false positive rate (FPR) and true positive rate (TPR)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_xgb)

# Compute the area under the curve (AUC)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()


import numpy as np

# Find the index of the threshold that minimizes the Euclidean distance from (0,1)
idx = np.argmin((1-tpr)**2 + fpr**2)

# Retrieve the optimal threshold
optimal_threshold1 = thresholds[idx]

print(optimal_threshold1)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_xgb))

from sklearn.metrics import confusion_matrix

# Print the confusion matrix
cm = confusion_matrix(y_test, y_pred_xgb)
print(cm)

"""# Logistic Regression"""

# weighted logistic regression for class imbalance with heuristic weights
from numpy import mean
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.linear_model import LogisticRegression
# define model
weights_assigned_lr={0:1,1:230}
# model_lr = LogisticRegression(solver='lbfgs', class_weight=weights_assigned_lr)
model_lr = LogisticRegression(solver='lbfgs')
# define evaluation procedure
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(model_lr, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)
# summarize performance
print('Mean ROC AUC: %.3f' % mean(scores))

# Fitting the classifier on training data
model_lr.fit(X_train, y_train)

# Making predictions on test data
y_pred_lr = model_lr.predict(X_test)

# plot the ROC-AUC curve, find the nearest point to the top left of the graph that would be the optimal thereshold for y_pred1

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Compute false positive rate (FPR) and true positive rate (TPR)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_lr)

# Compute the area under the curve (AUC)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()




from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_lr))

from sklearn.metrics import confusion_matrix

# Print the confusion matrix
cm = confusion_matrix(y_test, y_pred_lr)
print(cm)

"""# Ensemble with LR and XGboost"""

from sklearn.ensemble import VotingClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier

# Define the ensemble model
ensemble = VotingClassifier(estimators=[('xgb', xgb), ('lr', model_lr)], voting='soft')

# Fit the ensemble model on the training data
ensemble.fit(X_train, y_train)

# Making predictions on test data
y_pred_ensemble = ensemble.predict(X_test)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_ensemble))

from sklearn.metrics import confusion_matrix

# Print the confusion matrix
cm = confusion_matrix(y_test, y_pred_ensemble)
print(cm)

"""# Stacking base models - cost ANN, LR ; meta model - XGBoost

#### Prepare the dataset for the meta model

First we find the predicted values for X_train and X_test of the base models Cost sensitive ANN and LR. After that, we add them as atttributes to the X_train and X_test datasets which will then be used to train the meta model XGBoost
"""

y_pred_ann_stacking=model_normal.predict(X_train)
y_pred_ann_stacking_rounded = np.where(y_pred_ann_stacking > optimal_threshold1, 1, 0)

y_pred_lr_stacking = model_lr.predict(X_train)

print(y_pred_ann_stacking_rounded)
import numpy as np

y_pred_ann_stacking_rounded = y_pred_ann_stacking_rounded.flatten()
print(y_pred_ann_stacking_rounded)

print(y_pred_lr_stacking)

X_train_stacking = X_train.copy()

X_train_stacking['ann_train'] = y_pred_ann_stacking_rounded.tolist()
X_train_stacking['lr_train'] = y_pred_lr_stacking.tolist()

print(X_train_stacking)

y_pred_ann_stacking_test=model_normal.predict(X_test)
y_pred_ann_stacking_rounded_test = np.where(y_pred_ann_stacking_test > optimal_threshold1, 1, 0)

y_pred_lr_stacking_test = model_lr.predict(X_test)

print(y_pred_ann_stacking_rounded_test)
import numpy as np

y_pred_ann_stacking_rounded_test = y_pred_ann_stacking_rounded_test.flatten()
print(y_pred_ann_stacking_rounded_test)

print(y_pred_lr_stacking_test)

X_test_stacking = X_test.copy()

X_test_stacking['ann_train'] = y_pred_ann_stacking_rounded_test.tolist()
X_test_stacking['lr_train'] = y_pred_lr_stacking_test.tolist()

print(X_test_stacking)

"""#### Train the meta model"""

# fit balanced xgboost on an imbalanced classification dataset
from numpy import mean
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from xgboost import XGBClassifier
# define model
# xgb_stacking = XGBClassifier(scale_pos_weight=1000)
xgb_stacking = XGBClassifier(gamma=3000, max_depth=1)
# define evaluation procedure
cv_stacking = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores_stacking = cross_val_score(xgb_stacking, X_train_stacking, y_train, scoring='roc_auc', cv=cv_stacking, n_jobs=-1)
# summarize performance
print('Mean ROC AUC: %.5f' % mean(scores_stacking))

# Fitting the classifier on training data
xgb_stacking.fit(X_train_stacking, y_train)

# Making predictions on test data
y_pred_xgb_stacking = xgb_stacking.predict(X_test_stacking)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_xgb_stacking))

from sklearn.metrics import confusion_matrix

# Print the confusion matrix
cm = confusion_matrix(y_test, y_pred_xgb_stacking)
print(cm)

"""# Random Forest very bad"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

weights_assigned1={0:1,1:2}
# Initializing Random Forest classifier with class weights
clf = RandomForestClassifier(class_weight='balanced')

# Fitting the classifier on training data
clf.fit(X_train, y_train)

# Making predictions on test data
y_pred_clf = clf.predict(X_test)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_clf))

from sklearn.metrics import confusion_matrix

# Print the confusion matrix
cm = confusion_matrix(y_test, y_pred_clf)
print(cm)

"""# Weighted SVM very bad"""

# svm with class weight on an imbalanced classification dataset
from numpy import mean
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.svm import SVC
# define model
model_svm = SVC(gamma='scale', class_weight='balanced')
# define evaluation procedure
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(model_svm, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)
# summarize performance
print('Mean ROC AUC: %.3f' % mean(scores))

# svm with class weight on an imbalanced classification dataset
from numpy import mean
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.svm import SVC
# define model
weights_assigned_svm={0:1,1:230}
model_svm = SVC(gamma='scale', class_weight=weights_assigned_svm)

# Fitting the classifier on training data
model_svm.fit(X_train, y_train)

# Making predictions on test data
y_pred_svm = model_svm.predict(X_test)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_svm))

from sklearn.metrics import confusion_matrix

# Print the confusion matrix
cm = confusion_matrix(y_test, y_pred_svm)
print(cm)

"""# Decision Trees very bad"""

# decision tree with class weight on an imbalanced classification dataset
from numpy import mean
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.tree import DecisionTreeClassifier
# define model
weights_assigned_dt={0:1,1:300}
model_dt = DecisionTreeClassifier(class_weight=weights_assigned_dt)
# define evaluation procedure
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(model_dt, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)
# summarize performance
print('Mean ROC AUC: %.3f' % mean(scores))

# Fitting the classifier on training data
model_dt.fit(X_train, y_train)

# Making predictions on test data
y_pred_dt = model_dt.predict(X_test)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_dt))

from sklearn.metrics import confusion_matrix

# Print the confusion matrix
cm = confusion_matrix(y_test, y_pred_dt)
print(cm)