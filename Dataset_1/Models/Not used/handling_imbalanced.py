# -*- coding: utf-8 -*-
"""handling-imbalanced.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LlPm3oPfaQK6hIo37aS5hLCvK_rdjPXl

#### Handling Imbalanced Dataset with Machine Learning
"""

import pandas as pd
df=pd.read_csv('ais_disabling_events_main_only_imp_col_csv.csv')
df.head()

df.shape

df['iuu_caught'].value_counts()

#### Independent and Dependent Features
X=df.drop("iuu_caught",axis=1)
y=df.iuu_caught

"""### One Hot Encoding"""

print(df['vessel_class'].unique())
print(df['Ocean List New whose false were in OG'].unique())

print(df['vessel_class'].value_counts())
print(df['Ocean List New whose false were in OG'].value_counts())

one_hot_encoded_data = pd.get_dummies(df, columns = ['vessel_class', 'Ocean List New whose false were in OG'])
print(one_hot_encoded_data.head())

#### Independent and Dependent Features
X=one_hot_encoded_data.drop("iuu_caught",axis=1)
y=one_hot_encoded_data.iuu_caught

"""#### Cross Validation Like KFOLD and Hyperpaqrameter Tuning"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
from sklearn.model_selection import KFold
import numpy as np
from sklearn.model_selection import GridSearchCV

10.0 **np.arange(-2,3)

log_class=LogisticRegression()
grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}
cv=KFold(n_splits=5,random_state=None,shuffle=False)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7)

clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1,scoring='f1_macro')
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

y_train.value_counts()

class_weight=dict({0:1,1:100})

from sklearn.ensemble import RandomForestClassifier
classifier=RandomForestClassifier(class_weight=class_weight)
classifier.fit(X_train,y_train)

"""y_pred=classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))
"""

y_pred=classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

"""#### Under Sampling"""

from collections import Counter
Counter(y_train)

from collections import Counter
from imblearn.under_sampling import NearMiss
ns=NearMiss(0.8)
X_train_ns,y_train_ns=ns.fit_sample(X_train,y_train)
print("The number of classes before fit {}".format(Counter(y_train)))
print("The number of classes after fit {}".format(Counter(y_train_ns)))

from sklearn.ensemble import RandomForestClassifier
classifier=RandomForestClassifier()
classifier.fit(X_train_ns,y_train_ns)

y_pred=classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

"""##### Over Sampling"""

from imblearn.over_sampling import RandomOverSampler

os=RandomOverSampler(0.75)
X_train_ns,y_train_ns=os.fit_sample(X_train,y_train)
print("The number of classes before fit {}".format(Counter(y_train)))
print("The number of classes after fit {}".format(Counter(y_train_ns)))

from sklearn.ensemble import RandomForestClassifier
classifier=RandomForestClassifier()
classifier.fit(X_train_ns,y_train_ns)

y_pred=classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

"""#### SMOTETomek"""

from imblearn.combine import SMOTETomek

from collections import Counter

os=SMOTETomek(0.75)

X_train_ns,y_train_ns=os.fit_resample(X_train,y_train)
print("The number of classes before fit {}".format(Counter(y_train)))
print("The number of classes after fit {}".format(Counter(y_train_ns)))

from sklearn.ensemble import RandomForestClassifier
classifier=RandomForestClassifier()
classifier.fit(X_train_ns,y_train_ns)

y_pred=classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))

"""# Neural Networks using TF"""

import tensorflow as tf
import keras

model = tf.keras.Sequential([
    tf.keras.layers.Dense(units = 100, input_shape = (16, ), activation = 'relu'),
])

model.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'mean_absolute_error')

model.summary()

model.fit(X_train_ns, y_train_ns, epochs = 50)

X_test.head()

y_pred = model.predict(X_test)

y_pred

y_test

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

"""#### Ensemble Techniques"""

from imblearn.ensemble import EasyEnsembleClassifier

easy=EasyEnsembleClassifier()
easy(X_train,y_train)

y_pred=easy.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
print(classification_report(y_test,y_pred))