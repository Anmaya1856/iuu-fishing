# -*- coding: utf-8 -*-
"""Undersampling_Random_Forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MMEkXrzWvBf97zaLTGyhmzIelsjJIk40

#### Handling Imbalanced Dataset with Machine Learning
"""

import pandas as pd
df=pd.read_csv('ais_disabling_events_main_only_imp_col_csv.csv')
df.head()

df.shape

df['iuu_caught'].value_counts()

#### Independent and Dependent Features
X=df.drop("iuu_caught",axis=1)
y=df.iuu_caught

"""### One Hot Encoding"""

print(df['vessel_class'].unique())
print(df['Ocean List New whose false were in OG'].unique())

print(df['vessel_class'].value_counts())
print(df['Ocean List New whose false were in OG'].value_counts())

one_hot_encoded_data = pd.get_dummies(df, columns = ['vessel_class', 'Ocean List New whose false were in OG'])
print(one_hot_encoded_data.head())

#### Independent and Dependent Features
X=one_hot_encoded_data.drop("iuu_caught",axis=1)
y=one_hot_encoded_data.iuu_caught

"""#### SMOTETomek"""

y.value_counts()

# data wrangling
import pandas as pd
import numpy as np
# inputs data preparation
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
# modeling
from sklearn.linear_model import LogisticRegression
# model validation
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

# split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

from imblearn.under_sampling import RandomUnderSampler

# Instantiate the undersampler
under_sampler = RandomUnderSampler()

# Fit and transform the training data
X_train_undersampled, y_train_undersampled = under_sampler.fit_resample(X_train, y_train)

# number of fraud cases
frauds = len(df[df.iuu_caught == 1])
# selecting the indices of the non-fraud classes
fraud_indices = df[df.iuu_caught == 1].index
nonfraud_indices = df[df.iuu_caught == 0].index
# from all non-fraud observations, randomly select observations equal to number of fraud observations
random_nonfraud_indices = np.random.choice(nonfraud_indices, frauds, replace = False)
random_nonfraud_indices = np.array(random_nonfraud_indices)
# appending the 2 indices
under_sample_indices = np.concatenate([fraud_indices,random_nonfraud_indices])
# undersample dataset
under_sample_data = one_hot_encoded_data.iloc[under_sample_indices,:]
# now split X, y variables from the under sample data
X_undersample = under_sample_data.loc[:, under_sample_data.columns != 'iuu_caught']
y_undersample = under_sample_data.loc[:, under_sample_data.columns == 'iuu_caught']
print(X_undersample.value_counts())

print(X_train_undersampled.value_counts())
print(y_train_undersampled.value_counts())
print(X_test.value_counts())
print(y_test.value_counts())

#Importing essential libraries
import matplotlib.pyplot as plt
from statistics import mean
from matplotlib import pyplot
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_validate
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.metrics import plot_confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE

#Build SMOTE SRF model
SMOTE_SRF = RandomForestClassifier(n_estimators=150, random_state=0)
#Create Stratified K-fold cross validation
# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# scoring = ('f1', 'recall', 'precision')
#Evaluate SMOTE SRF model
# scores = cross_validate(SMOTE_SRF, X_sm, y_sm, scoring=scoring, cv=cv)
#Get average evaluation metrics
# print('Mean f1: %.3f' % mean(scores['test_f1']))
# print('Mean recall: %.3f' % mean(scores['test_recall']))
# print('Mean precision: %.3f' % mean(scores['test_precision']))

#Randomly spilt dataset to test and train set
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)
#Train SMOTE SRF
SMOTE_SRF.fit(X_train_undersampled, y_train_undersampled)
#SMOTE SRF prediction result
y_pred = SMOTE_SRF.predict(X_test)
#Create confusion matrix
fig = plot_confusion_matrix(SMOTE_SRF, X_test, y_test, display_labels=['No IUU', 'IUU'], cmap='Greens')
plt.title('SMOTE + Standard Random Forest Confusion Matrix')
plt.show()

from sklearn.metrics import confusion_matrix , classification_report

classification_report = classification_report(y_test, y_pred)
confusion_matrix = confusion_matrix(y_test, y_pred)
print("CLASSIFICATION REPORT")
print(classification_report)
print("CONFUSION MATRIX") 
print(confusion_matrix)