# -*- coding: utf-8 -*-
"""Undersampling_Linear_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DrAcBUgwxwYa3tOS-TXD4vwkpHPqkxUR

#### Handling Imbalanced Dataset with Machine Learning
"""

import pandas as pd
df=pd.read_csv('ais_disabling_events_main_only_imp_col_csv.csv')
df.head()

df.shape

df['iuu_caught'].value_counts()

#### Independent and Dependent Features
X=df.drop("iuu_caught",axis=1)
y=df.iuu_caught

"""### One Hot Encoding"""

print(df['vessel_class'].unique())
print(df['Ocean List New whose false were in OG'].unique())

print(df['vessel_class'].value_counts())
print(df['Ocean List New whose false were in OG'].value_counts())

one_hot_encoded_data = pd.get_dummies(df, columns = ['vessel_class', 'Ocean List New whose false were in OG'])
print(one_hot_encoded_data.head())

#### Independent and Dependent Features
X=one_hot_encoded_data.drop("iuu_caught",axis=1)
y=one_hot_encoded_data.iuu_caught

"""#### SMOTETomek"""

y.value_counts()

# data wrangling
import pandas as pd
import numpy as np
# inputs data preparation
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
# modeling
from sklearn.linear_model import LogisticRegression
# model validation
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

# number of fraud cases
frauds = len(df[df.iuu_caught == 1])
# selecting the indices of the non-fraud classes
fraud_indices = df[df.iuu_caught == 1].index
nonfraud_indices = df[df.iuu_caught == 0].index
# from all non-fraud observations, randomly select observations equal to number of fraud observations
random_nonfraud_indices = np.random.choice(nonfraud_indices, frauds, replace = False)
random_nonfraud_indices = np.array(random_nonfraud_indices)
# appending the 2 indices
under_sample_indices = np.concatenate([fraud_indices,random_nonfraud_indices])
# undersample dataset
under_sample_data = one_hot_encoded_data.iloc[under_sample_indices,:]
# now split X, y variables from the under sample data
X_undersample = under_sample_data.loc[:, under_sample_data.columns != 'iuu_caught']
y_undersample = under_sample_data.loc[:, under_sample_data.columns == 'iuu_caught']
print(X_undersample.value_counts())

# split dataset
X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample, y_undersample, test_size = 0.3, random_state = 0)

print(X_train_undersample.value_counts())
print(y_train_undersample.value_counts())
print(X_test_undersample.value_counts())
print(y_test_undersample.value_counts())

# instantiate model
model = LogisticRegression()
# fit 
model.fit(X_train_undersample, y_train_undersample)
# predict
y_pred = model.predict(X_test_undersample)

classification_report = classification_report(y_test_undersample, y_pred)
confusion_matrix = confusion_matrix(y_test_undersample, y_pred)
print("CLASSIFICATION REPORT")
print(classification_report)
print("CONFUSION MATRIX") 
print(confusion_matrix)